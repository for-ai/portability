from datasets import load_dataset
from functools import partial
import json
import function_lists
import re
from tqdm import tqdm
import code_tokenize as ctok

import_keyword = {
    "torch": "Name: torch",
    "tensorflow": "Name: tensorflow",
    "jax": "Name: jax"
}

pytorch_set = set(function_lists.pytorch_functions)
tensorflow_set = set(function_lists.tensorflow_functions)

error_files = []
false_negatives = []


def all_imports(node):
    for subscope in node.iter_funcdefs():
        yield from all_imports(subscope)
    for subscope in node.iter_classdefs():
        yield from all_imports(subscope)
    yield from node.iter_imports()


def contains_framework(framework, item):
    code_content = item['content']
    import_regex = r"(from.*" + re.escape(framework) + \
        r"|import.*" + re.escape(framework) + r")"
    matches = re.findall(import_regex, code_content)
    if len(matches) > 0:
        return True
    elif framework in code_content:
        false_negatives.append(item["content"])


def build_dictionary(set):
    dictionary = {}
    for item in set:
        dictionary[item] = 0
    return dictionary


def get_name_frequencies(dict, set, i, debug=False):
    string = i["content"]
    dict = dict.copy()
    try:
        for word in ctok.tokenize(string, lang="python"):
            if word.type == "identifier" and word.text in set:
                word = word.text
                # if word not in dict:
                #     dict[word] = 0

                dict[word] += 1
    except SyntaxError as e:
        error_files.append((i["repo_name"], i["path"]))
        pass
    if debug:
        with open("example.py", "w") as f:
            f.write(string)
        print(dict)
        import code
        code.interact(local=locals())
    return {"frequencies": dict}


def main():
    ds = load_dataset("codeparrot/codeparrot-clean",
                      streaming=False, split="train")
    framework = "tensorflow"
    # filters for files only containing framework imports
    ds = ds.filter(partial(contains_framework, framework))
    # tokenizes and gets frequencies of tokens
    if framework == "torch":
        set = pytorch_set
    else:
        set = tensorflow_set

    starting_dict = build_dictionary(set)

    ds = ds.map(partial(get_name_frequencies, starting_dict, set, debug=False), batched=False, remove_columns=[
                "alpha_frac", "autogenerated", "content", 'copies', 'hash', 'license', 'line_max', 'line_mean', 'size'])
    counts = build_dictionary(framework)

    counts = []
    for result in tqdm(ds):
        counts.append(result)
    for item in counts:
        new_item = {}
        for key, value in item["frequencies"].items():
            if value > 0:
                new_item[key] = value
        item["frequencies"] = new_item

    print(error_files)
    f = open(framework + "_frequencies.json", "w")
    f.write(json.dumps(counts, indent=4, sort_keys=True))
    f.close()
    f = open("false_negatives.txt", "w")
    for item in false_negatives:
        f.write(item)
    f.close()


main()
