{
    "created": 1682974146.790635,
    "duration": 1838.6985754966736,
    "exitcode": 1,
    "root": "/home/frasermince/portability",
    "environment": {
        "Python": "3.8.10",
        "Platform": "Linux-5.13.0-1033-gcp-x86_64-with-glibc2.29",
        "Packages": {
            "pytest": "7.2.0",
            "pluggy": "1.0.0"
        },
        "Plugins": {
            "hypothesis": "6.61.0",
            "json-report": "1.5.0",
            "json": "0.4.0",
            "timeout": "2.1.0",
            "metadata": "2.0.4"
        }
    },
    "summary": {
        "passed": 414,
        "skipped": 64,
        "failed": 84,
        "total": 562,
        "collected": 562
    },
    "collectors": [
        {
            "nodeid": "",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/__init__.py",
                    "type": "Package"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestOptimCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestOptimCPU::test_adamax_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 228
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestOptimXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestOptimXLA::test_adamax_xla",
                    "type": "TestCaseFunction",
                    "lineno": 228
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Adamax_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestOptimCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestOptimXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_depthwise_naive_groups_cpu_float16",
                    "type": "TestCaseFunction",
                    "lineno": 197
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_depthwise_naive_groups_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 197
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_depthwise_naive_groups_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 197
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_groups_nobias_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 130
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_groups_wbias_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 159
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_module_same_padding_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 59
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv3d_64bit_indexing_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 322
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_cudnn_ndhwc_cpu_float16",
                    "type": "TestCaseFunction",
                    "lineno": 271
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_cudnn_ndhwc_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 271
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_empty_channel_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 243
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_empty_channel_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 243
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_modules_raise_error_on_incorrect_input_size_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 90
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_shapecheck_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_invalid_conv3d_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 45
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_depthwise_naive_groups_xla_float16",
                    "type": "TestCaseFunction",
                    "lineno": 197
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_depthwise_naive_groups_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 197
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_depthwise_naive_groups_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 197
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_groups_nobias_xla",
                    "type": "TestCaseFunction",
                    "lineno": 130
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_groups_wbias_xla",
                    "type": "TestCaseFunction",
                    "lineno": 159
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_module_same_padding_xla",
                    "type": "TestCaseFunction",
                    "lineno": 59
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv3d_64bit_indexing_xla",
                    "type": "TestCaseFunction",
                    "lineno": 322
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_cudnn_ndhwc_xla_float16",
                    "type": "TestCaseFunction",
                    "lineno": 271
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_cudnn_ndhwc_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 271
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_empty_channel_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 243
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_empty_channel_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 243
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_modules_raise_error_on_incorrect_input_size_xla",
                    "type": "TestCaseFunction",
                    "lineno": 90
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_shapecheck_xla",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_invalid_conv3d_xla",
                    "type": "TestCaseFunction",
                    "lineno": 45
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU::test_pin_memory_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 58
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU::test_pin_memory_device_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 64
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU::test_pin_memory_with_only_device_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 72
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU::test_sequential_batch_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 32
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA::test_pin_memory_device_xla",
                    "type": "TestCaseFunction",
                    "lineno": 64
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA::test_pin_memory_with_only_device_xla",
                    "type": "TestCaseFunction",
                    "lineno": 72
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA::test_pin_memory_xla",
                    "type": "TestCaseFunction",
                    "lineno": 58
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA::test_sequential_batch_xla",
                    "type": "TestCaseFunction",
                    "lineno": 32
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestOptimCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestOptimCPU::test_sgd_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 48
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestOptimXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestOptimXLA::test_sgd_xla",
                    "type": "TestCaseFunction",
                    "lineno": 48
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestOptimCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestOptimXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/GELU_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/GELU_test.py::TestNNDeviceTypeCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/GELU_test.py::TestNNDeviceTypeCPU::test_transformerencoderlayer_gelu_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 18
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/GELU_test.py::TestNNDeviceTypeXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/GELU_test.py::TestNNDeviceTypeXLA::test_transformerencoderlayer_gelu_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 18
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/GELU_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/GELU_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/GELU_test.py::TestNNDeviceTypeCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/GELU_test.py::TestNNDeviceTypeXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestOptimCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestOptimCPU::test_lbfgs_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 204
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestOptimXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestOptimXLA::test_lbfgs_xla",
                    "type": "TestCaseFunction",
                    "lineno": 204
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestOptimCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestOptimXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestOptimCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestOptimCPU::test_rprop_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 313
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestOptimXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestOptimXLA::test_rprop_xla",
                    "type": "TestCaseFunction",
                    "lineno": 313
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/RProp_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestOptimCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestOptimXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_append_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 149
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_delitem_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 131
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_getitem_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 66
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_setitem_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 96
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_setitem_named_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 112
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_append_xla",
                    "type": "TestCaseFunction",
                    "lineno": 149
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_delitem_xla",
                    "type": "TestCaseFunction",
                    "lineno": 131
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_getitem_xla",
                    "type": "TestCaseFunction",
                    "lineno": 66
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_setitem_named_xla",
                    "type": "TestCaseFunction",
                    "lineno": 112
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_setitem_xla",
                    "type": "TestCaseFunction",
                    "lineno": 96
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitCPU::test_slicing_of_subset_of_dataset_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 42
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitCPU::test_slicing_of_subset_of_subset_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 56
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitXLA::test_slicing_of_subset_of_dataset_xla",
                    "type": "TestCaseFunction",
                    "lineno": 42
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitXLA::test_slicing_of_subset_of_subset_xla",
                    "type": "TestCaseFunction",
                    "lineno": 56
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Subset_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestNNCPU::test_transformerencoder_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 73
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestNNXLA::test_transformerencoder_xla",
                    "type": "TestCaseFunction",
                    "lineno": 73
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestNNCPU::test_Transformer_cell_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 86
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestNNXLA::test_Transformer_cell_xla",
                    "type": "TestCaseFunction",
                    "lineno": 86
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Transformer_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU::test_adaptive_avg_pool3d_output_size_one_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 35
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU::test_adaptive_pool_invalid_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 52
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU::test_adaptive_pooling_zero_batch_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 19
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU::test_adaptive_pooling_zero_batch_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 19
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA::test_adaptive_avg_pool3d_output_size_one_xla",
                    "type": "TestCaseFunction",
                    "lineno": 35
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA::test_adaptive_pool_invalid_xla",
                    "type": "TestCaseFunction",
                    "lineno": 52
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA::test_adaptive_pooling_zero_batch_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 19
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA::test_adaptive_pooling_zero_batch_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 19
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_add_module_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 198
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_add_module_raises_error_if_attr_exists_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 177
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_named_children_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_named_modules_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 108
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_register_buffer_raises_error_if_attr_exists_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_register_parameter_raises_error_if_attr_exists_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 158
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_add_module_raises_error_if_attr_exists_xla",
                    "type": "TestCaseFunction",
                    "lineno": 177
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_add_module_xla",
                    "type": "TestCaseFunction",
                    "lineno": 198
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_named_children_xla",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_named_modules_xla",
                    "type": "TestCaseFunction",
                    "lineno": 108
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_register_buffer_raises_error_if_attr_exists_xla",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_register_parameter_raises_error_if_attr_exists_xla",
                    "type": "TestCaseFunction",
                    "lineno": 158
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_bool_cpu_bool",
                    "type": "TestCaseFunction",
                    "lineno": 112
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_bfloat16",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_float16",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_int16",
                    "type": "TestCaseFunction",
                    "lineno": 119
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_int32",
                    "type": "TestCaseFunction",
                    "lineno": 119
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 119
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_int8",
                    "type": "TestCaseFunction",
                    "lineno": 119
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_uint8",
                    "type": "TestCaseFunction",
                    "lineno": 119
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_bool_xla_bool",
                    "type": "TestCaseFunction",
                    "lineno": 112
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_bfloat16",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_float16",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 139
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_int16",
                    "type": "TestCaseFunction",
                    "lineno": 119
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_int32",
                    "type": "TestCaseFunction",
                    "lineno": 119
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 119
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_int8",
                    "type": "TestCaseFunction",
                    "lineno": 119
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_uint8",
                    "type": "TestCaseFunction",
                    "lineno": 119
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestTorchCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestTorchCPU::test_apply_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 75
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestTorchXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestTorchXLA::test_apply_xla",
                    "type": "TestCaseFunction",
                    "lineno": 75
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/apply_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestTorchCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestTorchXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestSortAndSelectCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestSortAndSelectCPU::test_sort_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 59
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestSortAndSelectXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestSortAndSelectXLA::test_sort_xla",
                    "type": "TestCaseFunction",
                    "lineno": 59
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/argsort_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestSortAndSelectCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestSortAndSelectXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_buffer_update_when_stats_are_not_tracked_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 322
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_cudnn_half_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 204
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_cudnn_nhwc_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 157
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_nhwc_cpu_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 92
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_nhwc_cuda_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 341
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_non_contig_cpu_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 136
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_nonaffine_cuda_half_input_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 228
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_bias_is_not_same_size_as_input_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 283
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_less_than_one_value_per_channel_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 241
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_running_mean_is_not_same_size_as_input_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 248
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_running_var_is_not_same_size_as_input_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 259
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_running_var_or_running_mean_have_forward_grad_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 296
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_weight_is_not_same_size_as_input_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 270
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_buffer_update_when_stats_are_not_tracked_xla",
                    "type": "TestCaseFunction",
                    "lineno": 322
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_cudnn_half_xla",
                    "type": "TestCaseFunction",
                    "lineno": 204
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_cudnn_nhwc_xla",
                    "type": "TestCaseFunction",
                    "lineno": 157
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_nhwc_cpu_xla",
                    "type": "TestCaseFunction",
                    "lineno": 92
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_nhwc_cuda_xla",
                    "type": "TestCaseFunction",
                    "lineno": 341
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_non_contig_cpu_xla",
                    "type": "TestCaseFunction",
                    "lineno": 136
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_nonaffine_cuda_half_input_xla",
                    "type": "TestCaseFunction",
                    "lineno": 228
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_bias_is_not_same_size_as_input_xla",
                    "type": "TestCaseFunction",
                    "lineno": 283
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_less_than_one_value_per_channel_xla",
                    "type": "TestCaseFunction",
                    "lineno": 241
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_running_mean_is_not_same_size_as_input_xla",
                    "type": "TestCaseFunction",
                    "lineno": 248
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_running_var_is_not_same_size_as_input_xla",
                    "type": "TestCaseFunction",
                    "lineno": 259
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_running_var_or_running_mean_have_forward_grad_xla",
                    "type": "TestCaseFunction",
                    "lineno": 296
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_weight_is_not_same_size_as_input_xla",
                    "type": "TestCaseFunction",
                    "lineno": 270
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_broadcasts_pos_weights_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 127
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_broadcasts_weights_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 94
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_gives_same_result_as_sigmoid_and_bce_loss_large_tensors_with_grad_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 51
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_has_correct_grad_at_zero_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 86
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_ones_in_pos_weights_are_the_same_as_none_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 118
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_stability_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 158
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_with_pos_weight_has_correct_grad_at_zero_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 146
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_broadcasts_pos_weights_xla",
                    "type": "TestCaseFunction",
                    "lineno": 127
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_broadcasts_weights_xla",
                    "type": "TestCaseFunction",
                    "lineno": 94
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_gives_same_result_as_sigmoid_and_bce_loss_large_tensors_with_grad_xla",
                    "type": "TestCaseFunction",
                    "lineno": 51
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_has_correct_grad_at_zero_xla",
                    "type": "TestCaseFunction",
                    "lineno": 86
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_ones_in_pos_weights_are_the_same_as_none_xla",
                    "type": "TestCaseFunction",
                    "lineno": 118
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_stability_xla",
                    "type": "TestCaseFunction",
                    "lineno": 158
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_with_pos_weight_has_correct_grad_at_zero_xla",
                    "type": "TestCaseFunction",
                    "lineno": 146
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestNamedTensorCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestNamedTensorCPU::test_bitwise_not_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 22
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestNamedTensorXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestNamedTensorXLA::test_bitwise_not_xla",
                    "type": "TestCaseFunction",
                    "lineno": 22
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestNamedTensorCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestNamedTensorXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsCPU::test_broadcast_shapes_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 41
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsCPU::test_broadcast_tensors_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 27
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsXLA::test_broadcast_shapes_xla",
                    "type": "TestCaseFunction",
                    "lineno": 41
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsXLA::test_broadcast_tensors_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 27
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat2_cpu_float16",
                    "type": "TestCaseFunction",
                    "lineno": 289
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat2_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 289
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat2_cpu_int32",
                    "type": "TestCaseFunction",
                    "lineno": 289
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_all_dtypes_and_devices_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 28
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_big_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 275
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 250
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_empty_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 60
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_empty_legacy_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 44
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_in_channels_last_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 123
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_mem_overlap_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 21
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_out_channels_last_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 113
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_out_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 74
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_out_memory_format_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 174
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_preserve_channels_last_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 151
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_stack_cross_devices_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 235
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat2_xla_float16",
                    "type": "TestCaseFunction",
                    "lineno": 289
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat2_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 289
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat2_xla_int32",
                    "type": "TestCaseFunction",
                    "lineno": 289
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_all_dtypes_and_devices_xla",
                    "type": "TestCaseFunction",
                    "lineno": 28
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_big_xla",
                    "type": "TestCaseFunction",
                    "lineno": 275
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_empty_legacy_xla",
                    "type": "TestCaseFunction",
                    "lineno": 44
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_empty_xla",
                    "type": "TestCaseFunction",
                    "lineno": 60
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_in_channels_last_xla",
                    "type": "TestCaseFunction",
                    "lineno": 123
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_mem_overlap_xla",
                    "type": "TestCaseFunction",
                    "lineno": 21
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_out_channels_last_xla",
                    "type": "TestCaseFunction",
                    "lineno": 113
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_out_memory_format_xla",
                    "type": "TestCaseFunction",
                    "lineno": 174
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_out_xla",
                    "type": "TestCaseFunction",
                    "lineno": 74
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_preserve_channels_last_xla",
                    "type": "TestCaseFunction",
                    "lineno": 151
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_stack_cross_devices_xla",
                    "type": "TestCaseFunction",
                    "lineno": 235
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_xla",
                    "type": "TestCaseFunction",
                    "lineno": 250
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_add_dataset_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 158
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_concat_raises_index_error_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 150
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_concat_two_non_singletons_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 132
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_concat_two_non_singletons_with_empty_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 140
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_concat_two_singletons_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 125
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_iterable_dataset_err_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 168
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_add_dataset_xla",
                    "type": "TestCaseFunction",
                    "lineno": 158
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_concat_raises_index_error_xla",
                    "type": "TestCaseFunction",
                    "lineno": 150
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_concat_two_non_singletons_with_empty_xla",
                    "type": "TestCaseFunction",
                    "lineno": 140
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_concat_two_non_singletons_xla",
                    "type": "TestCaseFunction",
                    "lineno": 132
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_concat_two_singletons_xla",
                    "type": "TestCaseFunction",
                    "lineno": 125
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_iterable_dataset_err_xla",
                    "type": "TestCaseFunction",
                    "lineno": 168
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_backward_depthwise_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 499
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_backward_depthwise_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 499
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_depthwise_naive_groups_cpu_float16",
                    "type": "TestCaseFunction",
                    "lineno": 391
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_depthwise_naive_groups_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 391
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_depthwise_naive_groups_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 391
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_deterministic_cudnn_cpu_float16",
                    "type": "TestCaseFunction",
                    "lineno": 296
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_deterministic_cudnn_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 296
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_deterministic_cudnn_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 296
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_large_workspace_cpu_float16",
                    "type": "TestCaseFunction",
                    "lineno": 319
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_large_workspace_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 319
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_large_workspace_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 319
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_naive_groups_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 460
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_size_1_kernel_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 439
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_backward_depthwise_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 499
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_backward_depthwise_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 499
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_depthwise_naive_groups_xla_float16",
                    "type": "TestCaseFunction",
                    "lineno": 391
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_depthwise_naive_groups_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 391
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_depthwise_naive_groups_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 391
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_deterministic_cudnn_xla_float16",
                    "type": "TestCaseFunction",
                    "lineno": 296
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_deterministic_cudnn_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 296
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_deterministic_cudnn_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 296
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_large_workspace_xla_float16",
                    "type": "TestCaseFunction",
                    "lineno": 319
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_large_workspace_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 319
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_large_workspace_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 319
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_naive_groups_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 460
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_size_1_kernel_xla",
                    "type": "TestCaseFunction",
                    "lineno": 439
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_1x1_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 110
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_OneDNN_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 121
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_backward_twice_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 176
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_groups_nobias_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 189
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_groups_nobias_v2_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 232
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_inconsistent_types_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_inconsistent_types_on_GPU_with_cudnn_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 157
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_inconsistent_types_on_GPU_without_cudnn_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 94
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_missing_argument_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 172
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_module_same_padding_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 46
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_1x1_xla",
                    "type": "TestCaseFunction",
                    "lineno": 110
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_OneDNN_xla",
                    "type": "TestCaseFunction",
                    "lineno": 121
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_backward_twice_xla",
                    "type": "TestCaseFunction",
                    "lineno": 176
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_groups_nobias_v2_xla",
                    "type": "TestCaseFunction",
                    "lineno": 232
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_groups_nobias_xla",
                    "type": "TestCaseFunction",
                    "lineno": 189
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_inconsistent_types_on_GPU_with_cudnn_xla",
                    "type": "TestCaseFunction",
                    "lineno": 157
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_inconsistent_types_on_GPU_without_cudnn_xla",
                    "type": "TestCaseFunction",
                    "lineno": 94
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_inconsistent_types_xla",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_missing_argument_xla",
                    "type": "TestCaseFunction",
                    "lineno": 172
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_module_same_padding_xla",
                    "type": "TestCaseFunction",
                    "lineno": 46
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestTorchCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestTorchCPU::test_device_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 65
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestTorchXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestTorchXLA::test_device_xla",
                    "type": "TestCaseFunction",
                    "lineno": 65
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cuda_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestTorchCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestTorchXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestTorchCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestTorchCPU::test_to_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 66
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestTorchXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestTorchXLA::test_to_xla",
                    "type": "TestCaseFunction",
                    "lineno": 66
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestTorchCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestTorchXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsCPU::test_diag_cpu_bool",
                    "type": "TestCaseFunction",
                    "lineno": 23
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsCPU::test_diag_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 23
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsXLA::test_diag_xla_bool",
                    "type": "TestCaseFunction",
                    "lineno": 23
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsXLA::test_diag_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 23
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/diag_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNDeviceTypeCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNDeviceTypeCPU::test_Dropout3d_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 124
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNDeviceTypeXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNDeviceTypeXLA::test_Dropout3d_xla",
                    "type": "TestCaseFunction",
                    "lineno": 124
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNCPU::test_invalid_dropout_p_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 19
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNXLA::test_invalid_dropout_p_xla",
                    "type": "TestCaseFunction",
                    "lineno": 19
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNDeviceTypeCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNDeviceTypeXLA",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNDeviceTypeCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNDeviceTypeCPU::test_empty_dropout_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 166
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNDeviceTypeXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNDeviceTypeXLA::test_empty_dropout_xla",
                    "type": "TestCaseFunction",
                    "lineno": 166
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNCPU::test_invalid_dropout_p_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNCPU::test_native_dropout_corner_case_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 34
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNXLA::test_invalid_dropout_p_xla",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNXLA::test_native_dropout_corner_case_xla",
                    "type": "TestCaseFunction",
                    "lineno": 34
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNDeviceTypeCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNDeviceTypeXLA",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 68
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 68
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 68
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_invalid_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 72
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_invalid_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 72
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_invalid_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 72
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_flipud_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 80
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_flipud_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 80
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_flipud_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 80
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_invalid_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 72
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_invalid_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 72
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_invalid_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 72
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 68
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 68
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 68
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_flipud_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 80
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_flipud_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 80
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_flipud_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 80
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestQuantizedOpsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestQuantizedOpsCPU::test_group_norm_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 138
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestQuantizedOpsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestQuantizedOpsXLA::test_group_norm_xla",
                    "type": "TestCaseFunction",
                    "lineno": 138
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/group_norm_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestQuantizedOpsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestQuantizedOpsXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestTorchCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestTorchCPU::test_is_same_size_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 69
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestTorchXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestTorchXLA::test_is_same_size_xla",
                    "type": "TestCaseFunction",
                    "lineno": 69
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestTorchCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestTorchXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jacobian_match_vjp_jvp_base_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 328
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jacobian_match_vjp_jvp_logging_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 328
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_create_graph_base_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 283
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_create_graph_logging_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 283
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_err_check_base_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 127
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_err_check_logging_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 127
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_err_check_strict_base_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 156
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_err_check_strict_logging_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 156
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_no_grad_base_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 193
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_no_grad_logging_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 193
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_output_base_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 216
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_output_logging_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 216
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_scalar_base_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 256
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_scalar_logging_tensor_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 256
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jacobian_match_vjp_jvp_base_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 328
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jacobian_match_vjp_jvp_logging_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 328
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_create_graph_base_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 283
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_create_graph_logging_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 283
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_err_check_base_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 127
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_err_check_logging_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 127
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_err_check_strict_base_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 156
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_err_check_strict_logging_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 156
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_no_grad_base_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 193
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_no_grad_logging_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 193
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_output_base_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 216
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_output_logging_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 216
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_scalar_base_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 256
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_scalar_logging_tensor_xla",
                    "type": "TestCaseFunction",
                    "lineno": 256
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNCPU::test_KLDivLoss_batch_mean_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 90
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNCPU::test_KLDivLoss_batch_mean_log_target_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 105
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNXLA::test_KLDivLoss_batch_mean_log_target_xla",
                    "type": "TestCaseFunction",
                    "lineno": 105
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNXLA::test_KLDivLoss_batch_mean_xla",
                    "type": "TestCaseFunction",
                    "lineno": 90
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/linear_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestNNCPU::test_to_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 67
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestNNXLA::test_to_xla",
                    "type": "TestCaseFunction",
                    "lineno": 67
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/linear_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/linear_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseBase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_int16",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_int32",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_int8",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_uint8",
                    "type": "TestCaseFunction",
                    "lineno": 84
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_int16",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_int32",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_int8",
                    "type": "TestCaseFunction",
                    "lineno": 84
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_uint8",
                    "type": "TestCaseFunction",
                    "lineno": 84
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseBase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgCPU::test_det_logdet_slogdet_batched_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgCPU::test_det_logdet_slogdet_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 68
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgXLA::test_det_logdet_slogdet_batched_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgXLA::test_det_logdet_slogdet_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 68
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/logdet_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNDeviceTypeCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNDeviceTypeCPU::test_lstmcell_backward_only_one_output_grad_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 161
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNDeviceTypeXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNDeviceTypeXLA::test_lstmcell_backward_only_one_output_grad_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 161
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU::test_LSTM_cell_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 120
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU::test_LSTM_cell_forward_hidden_size_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 146
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU::test_LSTM_cell_forward_input_size_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 136
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU::test_RNN_cell_no_broadcasting_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 91
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA::test_LSTM_cell_forward_hidden_size_xla",
                    "type": "TestCaseFunction",
                    "lineno": 146
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA::test_LSTM_cell_forward_input_size_xla",
                    "type": "TestCaseFunction",
                    "lineno": 136
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA::test_LSTM_cell_xla",
                    "type": "TestCaseFunction",
                    "lineno": 120
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA::test_RNN_cell_no_broadcasting_xla",
                    "type": "TestCaseFunction",
                    "lineno": 91
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNDeviceTypeCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNDeviceTypeXLA",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossCPU::test_lt_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 46
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossCPU::test_lt_scalar_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 61
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossXLA::test_lt_scalar_xla",
                    "type": "TestCaseFunction",
                    "lineno": 61
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossXLA::test_lt_xla",
                    "type": "TestCaseFunction",
                    "lineno": 46
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_rtol_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 138
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_basic_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_basic_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_basic_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_basic_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_empty_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 168
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_empty_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 168
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_empty_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 168
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_empty_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 168
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_out_errors_and_warnings_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 219
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_out_errors_and_warnings_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 219
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_out_errors_and_warnings_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 219
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_out_errors_and_warnings_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 219
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_rtol_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 138
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 107
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_basic_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_basic_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_basic_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_basic_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 247
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_empty_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 168
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_empty_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 168
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_empty_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 168
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_empty_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 168
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_out_errors_and_warnings_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 219
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_out_errors_and_warnings_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 219
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_out_errors_and_warnings_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 219
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_out_errors_and_warnings_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 219
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 47
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 47
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 88
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 88
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 88
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_invalid_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 59
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_invalid_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 59
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_invalid_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 59
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_invalid_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 59
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_invalid_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 59
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_invalid_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 59
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 88
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 88
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 88
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::DistributionsTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestNumericalStabilityCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestNumericalStabilityCPU::test_multinomial_log_prob_with_logits_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 191
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestNumericalStabilityXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestNumericalStabilityXLA::test_multinomial_log_prob_with_logits_xla",
                    "type": "TestCaseFunction",
                    "lineno": 191
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsCPU::test_multinomial_1d_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 104
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsCPU::test_multinomial_1d_log_prob_and_entropy_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 122
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsCPU::test_multinomial_2d_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 144
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsXLA::test_multinomial_1d_log_prob_and_entropy_xla",
                    "type": "TestCaseFunction",
                    "lineno": 122
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsXLA::test_multinomial_1d_xla",
                    "type": "TestCaseFunction",
                    "lineno": 104
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsXLA::test_multinomial_2d_xla",
                    "type": "TestCaseFunction",
                    "lineno": 144
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionShapesCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionShapesCPU::test_multinomial_shape_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 171
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionShapesXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionShapesXLA::test_multinomial_shape_xla",
                    "type": "TestCaseFunction",
                    "lineno": 171
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::DistributionsTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestNumericalStabilityCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestNumericalStabilityXLA",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsXLA",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionShapesCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionShapesXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_errors_and_warnings_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 116
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_errors_and_warnings_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 116
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_errors_and_warnings_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 116
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_errors_and_warnings_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 116
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_errors_and_warnings_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 116
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_errors_and_warnings_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 116
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_errors_and_warnings_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 116
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_errors_and_warnings_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 116
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 67
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationCPU::test_randperm_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 81
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationCPU::test_randperm_device_compatibility_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 151
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationXLA::test_randperm_device_compatibility_xla",
                    "type": "TestCaseFunction",
                    "lineno": 151
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationXLA::test_randperm_xla",
                    "type": "TestCaseFunction",
                    "lineno": 81
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/randperm_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/range_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationCPU::test_range_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 35
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationCPU::test_range_warning_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 71
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationXLA::test_range_warning_xla",
                    "type": "TestCaseFunction",
                    "lineno": 71
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationXLA::test_range_xla",
                    "type": "TestCaseFunction",
                    "lineno": 35
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/range_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/range_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_add_module_raises_error_if_attr_exists_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 153
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_register_buffer_raises_error_if_attr_exists_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 89
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_register_parameter_allows_overwriting_with_same_name_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 136
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_register_parameter_raises_error_if_attr_exists_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 118
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_register_parameter_raises_error_if_name_is_not_string_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 108
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_add_module_raises_error_if_attr_exists_xla",
                    "type": "TestCaseFunction",
                    "lineno": 153
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_register_buffer_raises_error_if_attr_exists_xla",
                    "type": "TestCaseFunction",
                    "lineno": 89
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_register_parameter_allows_overwriting_with_same_name_xla",
                    "type": "TestCaseFunction",
                    "lineno": 136
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_register_parameter_raises_error_if_attr_exists_xla",
                    "type": "TestCaseFunction",
                    "lineno": 118
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_register_parameter_raises_error_if_name_is_not_string_xla",
                    "type": "TestCaseFunction",
                    "lineno": 108
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::DistributionsTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestConstraints",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestConstraints::test_params_constraints",
                    "type": "TestCaseFunction",
                    "lineno": 364
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU::test_argmax_relaxed_categorical_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 241
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU::test_mode_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 323
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU::test_relaxed_one_hot_categorical_1d_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 195
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU::test_relaxed_one_hot_categorical_2d_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 216
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA::test_argmax_relaxed_categorical_xla",
                    "type": "TestCaseFunction",
                    "lineno": 241
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA::test_mode_xla",
                    "type": "TestCaseFunction",
                    "lineno": 323
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA::test_relaxed_one_hot_categorical_1d_xla",
                    "type": "TestCaseFunction",
                    "lineno": 195
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA::test_relaxed_one_hot_categorical_2d_xla",
                    "type": "TestCaseFunction",
                    "lineno": 216
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::DistributionsTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestConstraints",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeCPU::test_batchnorm_simple_average_cpu_bfloat16",
                    "type": "TestCaseFunction",
                    "lineno": 120
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeCPU::test_batchnorm_simple_average_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 120
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeXLA::test_batchnorm_simple_average_xla_bfloat16",
                    "type": "TestCaseFunction",
                    "lineno": 120
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeXLA::test_batchnorm_simple_average_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 120
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/round_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/round_test.py::TestRoundCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/round_test.py::TestRoundCPU::test_rounding_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 65
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/round_test.py::TestRoundXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/round_test.py::TestRoundXLA::test_rounding_xla",
                    "type": "TestCaseFunction",
                    "lineno": 65
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/round_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/round_test.py::TestCase",
                    "type": "Class"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/round_test.py::TestRoundCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/round_test.py::TestRoundXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseBase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseCPU::test_saddmm_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 108
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseCPU::test_saddmm_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 108
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseXLA::test_saddmm_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 108
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseXLA::test_saddmm_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 108
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseBase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_int32",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 43
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_int32",
                    "type": "TestCaseFunction",
                    "lineno": 43
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 43
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeCPU::test_nn_scalars_reductions_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeCPU::test_smooth_l1_loss_bfloat16_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 188
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeCPU::test_smooth_l1_loss_vs_huber_loss_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 114
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeXLA::test_nn_scalars_reductions_xla",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeXLA::test_smooth_l1_loss_bfloat16_xla",
                    "type": "TestCaseFunction",
                    "lineno": 188
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeXLA::test_smooth_l1_loss_vs_huber_loss_xla",
                    "type": "TestCaseFunction",
                    "lineno": 114
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestNNCPU::test_state_dict_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 88
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestNNXLA::test_state_dict_xla",
                    "type": "TestCaseFunction",
                    "lineno": 88
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU::test_load_state_dict_module_pre_hook_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 195
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU::test_load_state_dict_post_hook_backward_compatibility_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 329
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU::test_load_state_dict_post_hook_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 264
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU::test_load_state_dict_pre_hook_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 162
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA::test_load_state_dict_module_pre_hook_xla",
                    "type": "TestCaseFunction",
                    "lineno": 195
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA::test_load_state_dict_post_hook_backward_compatibility_xla",
                    "type": "TestCaseFunction",
                    "lineno": 329
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA::test_load_state_dict_post_hook_xla",
                    "type": "TestCaseFunction",
                    "lineno": 264
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA::test_load_state_dict_pre_hook_xla",
                    "type": "TestCaseFunction",
                    "lineno": 162
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestSumCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestSumCPU::test_sum_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 32
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestSumXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestSumXLA::test_sum_xla",
                    "type": "TestCaseFunction",
                    "lineno": 32
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/sum_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestSumCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestSumXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/synchronize_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/synchronize_test.py::TestCuda",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/synchronize_test.py::TestCuda::test_copy_streams",
                    "type": "TestCaseFunction",
                    "lineno": 117
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/synchronize_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/synchronize_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/synchronize_test.py::TestCuda",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestTorchCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestTorchCPU::test_tensor_set_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 66
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestTorchXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestTorchXLA::test_tensor_set_xla",
                    "type": "TestCaseFunction",
                    "lineno": 66
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/tensor_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestTorchCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestTorchXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/to_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/to_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/to_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/to_test.py::TestNNCPU::test_to_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 75
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/to_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/to_test.py::TestNNXLA::test_to_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 75
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/to_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/to_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/to_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/to_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/to_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU::test_triangular_solve_cpu_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 81
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU::test_triangular_solve_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 81
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU::test_triangular_solve_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 81
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU::test_triangular_solve_cpu_float64",
                    "type": "TestCaseFunction",
                    "lineno": 81
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA::test_triangular_solve_xla_complex128",
                    "type": "TestCaseFunction",
                    "lineno": 81
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA::test_triangular_solve_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 81
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA::test_triangular_solve_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 81
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA::test_triangular_solve_xla_float64",
                    "type": "TestCaseFunction",
                    "lineno": 81
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestViewOpsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestViewOpsCPU::test_unbind_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 31
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestViewOpsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestViewOpsXLA::test_unbind_xla",
                    "type": "TestCaseFunction",
                    "lineno": 31
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unbind_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestViewOpsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestViewOpsXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestViewOpsCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestViewOpsCPU::test_unsqueeze_view_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 40
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestViewOpsXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestViewOpsXLA::test_unsqueeze_view_xla",
                    "type": "TestCaseFunction",
                    "lineno": 40
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestViewOpsCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestViewOpsXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_indexing_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_indexing_duplicates_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 151
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_inplace_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 198
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_pyscalar_conversions_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 345
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_reentrant_priority_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 400
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_simple_reentrant_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 319
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_type_conversions_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 263
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_indexing_duplicates_xla",
                    "type": "TestCaseFunction",
                    "lineno": 151
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_indexing_xla",
                    "type": "TestCaseFunction",
                    "lineno": 67
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_inplace_xla",
                    "type": "TestCaseFunction",
                    "lineno": 198
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_pyscalar_conversions_xla",
                    "type": "TestCaseFunction",
                    "lineno": 345
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_reentrant_priority_xla",
                    "type": "TestCaseFunction",
                    "lineno": 400
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_simple_reentrant_xla",
                    "type": "TestCaseFunction",
                    "lineno": 319
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_type_conversions_xla",
                    "type": "TestCaseFunction",
                    "lineno": 263
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::DistributionsTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesCPU::test_vonmises_shape_scalar_params_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 109
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesCPU::test_vonmises_shape_tensor_params_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 99
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesXLA::test_vonmises_shape_scalar_params_xla",
                    "type": "TestCaseFunction",
                    "lineno": 109
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesXLA::test_vonmises_shape_tensor_params_xla",
                    "type": "TestCaseFunction",
                    "lineno": 99
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::DistributionsTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitCPU::test_xavier_uniform_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 111
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitCPU::test_xavier_uniform_errors_on_inputs_smaller_than_2d_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 100
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitXLA::test_xavier_uniform_errors_on_inputs_smaller_than_2d_xla",
                    "type": "TestCaseFunction",
                    "lineno": 100
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitXLA::test_xavier_uniform_xla",
                    "type": "TestCaseFunction",
                    "lineno": 111
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::NNTestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestNNCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestNNCPU::test_zero_grad_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 91
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestNNXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestNNXLA::test_zero_grad_xla",
                    "type": "TestCaseFunction",
                    "lineno": 91
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::NNTestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestNNCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestNNXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestCase",
            "outcome": "passed",
            "result": []
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 97
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_bool",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_float16",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_float32",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_int16",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_int64",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_uint8",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_out_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 134
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_bool",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_complex64",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_float16",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_float32",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_int16",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_int64",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_uint8",
                    "type": "TestCaseFunction",
                    "lineno": 87
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_out_xla",
                    "type": "TestCaseFunction",
                    "lineno": 134
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_xla",
                    "type": "TestCaseFunction",
                    "lineno": 97
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationCPU",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationCPU::test_zeros_like_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 175
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationCPU::test_zeros_like_multiple_device_cpu",
                    "type": "TestCaseFunction",
                    "lineno": 182
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationXLA",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationXLA::test_zeros_like_multiple_device_xla",
                    "type": "TestCaseFunction",
                    "lineno": 182
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationXLA::test_zeros_like_xla",
                    "type": "TestCaseFunction",
                    "lineno": 175
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestCase",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationCPU",
                    "type": "UnitTestCase"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationXLA",
                    "type": "UnitTestCase"
                }
            ]
        },
        {
            "nodeid": "src/pytorch_tests_reduced/__init__.py",
            "outcome": "passed",
            "result": [
                {
                    "nodeid": "src/pytorch_tests_reduced/Adamax_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Dataset_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/GELU_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/RProp_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Sequential_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Subset_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/Transformer_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/add_module_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/addr_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/apply_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/argsort_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cat_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/conv2d_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/cuda_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/diag_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/dropout_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/fliplr_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/group_norm_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/jvp_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/linear_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/log1p_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/logdet_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/lt_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/multinomial_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/ormqr_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/randperm_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/range_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/round_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/saddmm_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/size_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/state_dict_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/sum_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/synchronize_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/tensor_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/to_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/unbind_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/variable_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/vonmises_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py",
                    "type": "Module"
                },
                {
                    "nodeid": "src/pytorch_tests_reduced/zeros_test.py",
                    "type": "Module"
                }
            ]
        }
    ],
    "tests": [
        {
            "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestOptimCPU::test_adamax_cpu",
            "lineno": 228,
            "outcome": "passed",
            "setup": {
                "duration": 0.0008794889999990119,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.0835220589997334,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00021221499991952442,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Adamax_test.py::TestOptimXLA::test_adamax_xla",
            "lineno": 228,
            "outcome": "passed",
            "setup": {
                "duration": 0.01239118299963593,
                "outcome": "passed"
            },
            "call": {
                "duration": 298.0318611949997,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0005368570000428008,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_depthwise_naive_groups_cpu_float16",
            "lineno": 197,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0007799380000506062,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0016011300003810902,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 198, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.00015364400042017223,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_depthwise_naive_groups_cpu_float32",
            "lineno": 197,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003417449997868971,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006009150001773378,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 198, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.00011937999988731463,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_depthwise_naive_groups_cpu_float64",
            "lineno": 197,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00028551299965329235,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006038150004314957,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 198, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.00013931800003774697,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_groups_nobias_cpu",
            "lineno": 130,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033762299972295295,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.08072103599988623,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019941899972764077,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_groups_wbias_cpu",
            "lineno": 159,
            "outcome": "passed",
            "setup": {
                "duration": 0.00041991399939433904,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.024063388999820745,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022648000049230177,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_Conv3d_module_same_padding_cpu",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.00038873399989824975,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.005829566000102204,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016281299940601457,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv3d_64bit_indexing_cpu",
            "lineno": 322,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00039872300021670526,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001321447000009357,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 323, 'Skipped: Need psutil to determine if memory is sufficient')"
            },
            "teardown": {
                "duration": 0.0001625260001674178,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_cudnn_ndhwc_cpu_float16",
            "lineno": 271,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00035871700038114795,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009839150006882846,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 272, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.00016776699976617238,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_cudnn_ndhwc_cpu_float32",
            "lineno": 271,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003719649994309293,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009047600005942513,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 272, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.00016941000012593577,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_empty_channel_cpu_complex64",
            "lineno": 243,
            "outcome": "passed",
            "setup": {
                "duration": 0.00037539000004471745,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.016585984999437642,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013343000046006637,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_empty_channel_cpu_float32",
            "lineno": 243,
            "outcome": "passed",
            "setup": {
                "duration": 0.00031150199993135175,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.011463554999863845,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011416500001359964,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_modules_raise_error_on_incorrect_input_size_cpu",
            "lineno": 90,
            "outcome": "passed",
            "setup": {
                "duration": 0.00029178200020396616,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.13554389699947933,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011930700020457152,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_conv_shapecheck_cpu",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028212099914526334,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0662884049997956,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017028300044330535,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNCPU::test_invalid_conv3d_cpu",
            "lineno": 45,
            "outcome": "passed",
            "setup": {
                "duration": 0.00043561300026340177,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.10094181900058175,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002472969999871566,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_depthwise_naive_groups_xla_float16",
            "lineno": 197,
            "outcome": "skipped",
            "setup": {
                "duration": 0.003635383000073489,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006777159997000126,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 198, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.0001316799998676288,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_depthwise_naive_groups_xla_float32",
            "lineno": 197,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00036415700014913455,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006300750001173583,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 198, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.00014070799988985527,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_depthwise_naive_groups_xla_float64",
            "lineno": 197,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003712269999596174,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005432349998955033,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 198, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.00011881299997185124,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_groups_nobias_xla",
            "lineno": 130,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002798980003717588,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0175418280005033,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019059499936702196,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_groups_wbias_xla",
            "lineno": 159,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034554499961814145,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.022468625000328757,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016375799987145,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_Conv3d_module_same_padding_xla",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.000395777999983693,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.003990471000179241,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001649229998292867,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv3d_64bit_indexing_xla",
            "lineno": 322,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00037304000034055207,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009369259996674373,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 323, 'Skipped: Unknown device type')"
            },
            "teardown": {
                "duration": 0.00016212300033657812,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_cudnn_ndhwc_xla_float16",
            "lineno": 271,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00039080500027921516,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0011674280003717286,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 272, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.00017062399911083048,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_cudnn_ndhwc_xla_float32",
            "lineno": 271,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00037496200002351543,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009053099993252545,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py', 272, 'Skipped: Only runs on cuda')"
            },
            "teardown": {
                "duration": 0.0001757910004016594,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_empty_channel_xla_complex64",
            "lineno": 243,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003979580005761818,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.19211816699953488,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/common_nn.py",
                    "lineno": 6473,
                    "message": "RuntimeError: Comparing\n\nTensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64),\n    expected=tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64),\n    rtol=1.3e-06,\n    atol=1e-05,\n    equal_nan=True,\n    check_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\nresulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/Conv3d_test.py",
                        "lineno": 265,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/common_nn.py",
                        "lineno": 6473,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "actual = tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64)\nexpected = tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64)\npair_types = (<class 'torch.testing._comparison.NonePair'>, <class 'torch.testing._internal.common_utils.RelaxedBooleanPair'>, <cla...<class 'torch.testing._internal.common_utils.StringPair'>, <class 'torch.testing._internal.common_utils.SetPair'>, ...)\nsequence_types = (<class 'collections.abc.Sequence'>, <class 'torch.storage._TypedStorage'>, <class 'torch.nn.modules.container.Sequent...nn.modules.container.ModuleList'>, <class 'torch.nn.modules.container.ParameterList'>, <class 'torch.ScriptList'>, ...)\nmapping_types = (<class 'collections.abc.Mapping'>, <class 'torch.nn.modules.container.ModuleDict'>, <class 'torch.nn.modules.container.ParameterDict'>, <class 'torch.ScriptDict'>)\nmsg = None, options = {'atol': None, 'atol_override': 0, 'check_device': False, 'check_dtype': True, ...}, __tracebackhide__ = True\npairs = [TensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64),\n  ...ck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)]\n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n>               pair.compare()\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1075: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64),\n   ...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\n    def compare(self) -> None:\n        actual, expected = self.actual, self.expected\n    \n        self._compare_attributes(actual, expected)\n        if any(input.device.type == \"meta\" for input in (actual, expected)):\n            return\n    \n        actual, expected = self._equalize_attributes(actual, expected)\n>       self._compare_values(actual, expected)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:620: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64),\n   ...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64)\nexpected = tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64)\n\n    def _compare_values(self, actual: torch.Tensor, expected: torch.Tensor) -> None:\n        if actual.is_quantized:\n            compare_fn = self._compare_quantized_values\n        elif actual.is_sparse:\n            compare_fn = self._compare_sparse_coo_values\n        elif actual.layout in {torch.sparse_csr, torch.sparse_csc, torch.sparse_bsr, torch.sparse_bsc}:\n            compare_fn = self._compare_sparse_compressed_values\n        else:\n            compare_fn = self._compare_regular_values_close\n    \n>       compare_fn(actual, expected, rtol=self.rtol, atol=self.atol, equal_nan=self.equal_nan)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:714: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64),\n   ...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex128)\nexpected = tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex128)\n\n    def _compare_regular_values_close(\n        self,\n        actual: torch.Tensor,\n        expected: torch.Tensor,\n        *,\n        rtol: float,\n        atol: float,\n        equal_nan: bool,\n        identifier: Optional[Union[str, Callable[[str], str]]] = None,\n    ) -> None:\n        \"\"\"Checks if the values of two tensors are close up to a desired tolerance.\"\"\"\n        actual, expected = self._promote_for_comparison(actual, expected)\n>       matches = torch.isclose(actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan)\nE       RuntimeError: unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:846: RuntimeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <src.pytorch_tests_reduced.Conv3d_test.TestConvolutionNNXLA testMethod=test_conv_empty_channel_xla_complex64>, device = 'xla:1'\ndtype = torch.complex64\n\n    @dtypes(torch.float, torch.cfloat)\n    def test_conv_empty_channel(self, device, dtype):\n        in_channels = 0\n        # mod = torch.nn.Conv1d(in_channels, 8, 2, stride=2, dtype=dtype).to(device)\n        # inp = torch.randn(2, 0, 15, device=device, dtype=dtype)\n        # _test_module_empty_input(self, mod, inp, check_size=False)\n    \n        # with self.assertRaisesRegex(RuntimeError, \"Given groups=1, weight\"):\n        #     inp = torch.randn(2, 1, 0, device=device, dtype=dtype)\n        #     mod(inp)\n    \n        # mod = torch.nn.Conv2d(in_channels, 33, 3, stride=2, dtype=dtype).to(device)\n        # inp = torch.randn(2, 0, 50, 100, device=device, dtype=dtype)\n        # _test_module_empty_input(self, mod, inp, check_size=False)\n    \n        # with self.assertRaisesRegex(RuntimeError, \"Given groups=1, weight\"):\n        #     inp = torch.randn(2, 1, 40, 0, device=device, dtype=dtype)\n        #     mod(inp)\n        with pytorch_op_timer():\n            mod = torch.nn.Conv3d(in_channels, 33, 3, stride=2, dtype=dtype).to(device)\n        inp = torch.randn(2, 0, 50, 20, 40, device=device, dtype=dtype)\n>       _test_module_empty_input(self, mod, inp, check_size=False)\n\nsrc/pytorch_tests_reduced/Conv3d_test.py:265: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntest_case = <src.pytorch_tests_reduced.Conv3d_test.TestConvolutionNNXLA testMethod=test_conv_empty_channel_xla_complex64>\nmodule = Conv3d(0, 33, kernel_size=(3, 3, 3), stride=(2, 2, 2))\ninp = tensor([], device='xla:1', size=(2, 0, 50, 20, 40), dtype=torch.complex64,\n       requires_grad=True), check_size = False, inference = False\n\n    def _test_module_empty_input(test_case, module, inp, check_size=True, inference=False):\n        if not inference:\n            inp.requires_grad_(True)\n        out = module(inp)\n        if not inference:\n            gO = torch.rand_like(out)\n            out.backward(gO)\n        if check_size:\n            test_case.assertEqual(out.size(), inp.size())\n        if not inference:\n            for p in module.parameters():\n                if p.requires_grad:\n                    print(\"***GRAD\", p.grad, torch.zeros_like(p.grad))\n>                   test_case.assertEqual(p.grad, torch.zeros_like(p.grad))\nE                   RuntimeError: Comparing\nE                   \nE                   TensorOrArrayPair(\nE                       id=(),\nE                       actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64),\nE                       expected=tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.complex64),\nE                       rtol=1.3e-06,\nE                       atol=1e-05,\nE                       equal_nan=True,\nE                       check_device=False,\nE                       check_dtype=True,\nE                       check_layout=False,\nE                       check_stride=False,\nE                       check_is_coalesced=False,\nE                   )\nE                   \nE                   resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.\n\nsrc/pytorch_tests_reduced/common_nn.py:6473: RuntimeError"
            },
            "teardown": {
                "duration": 0.00021688000015274156,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_empty_channel_xla_float32",
            "lineno": 243,
            "outcome": "failed",
            "setup": {
                "duration": 0.00040953200004878454,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0652929560001212,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/common_nn.py",
                    "lineno": 6473,
                    "message": "RuntimeError: Comparing\n\nTensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3)),\n    expected=tensor([], device='xla:1', size=(33, 0, 3, 3, 3)),\n    rtol=1.3e-06,\n    atol=1e-05,\n    equal_nan=True,\n    check_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\nresulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/Conv3d_test.py",
                        "lineno": 265,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/common_nn.py",
                        "lineno": 6473,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "actual = tensor([], device='xla:1', size=(33, 0, 3, 3, 3)), expected = tensor([], device='xla:1', size=(33, 0, 3, 3, 3))\npair_types = (<class 'torch.testing._comparison.NonePair'>, <class 'torch.testing._internal.common_utils.RelaxedBooleanPair'>, <cla...<class 'torch.testing._internal.common_utils.StringPair'>, <class 'torch.testing._internal.common_utils.SetPair'>, ...)\nsequence_types = (<class 'collections.abc.Sequence'>, <class 'torch.storage._TypedStorage'>, <class 'torch.nn.modules.container.Sequent...nn.modules.container.ModuleList'>, <class 'torch.nn.modules.container.ParameterList'>, <class 'torch.ScriptList'>, ...)\nmapping_types = (<class 'collections.abc.Mapping'>, <class 'torch.nn.modules.container.ModuleDict'>, <class 'torch.nn.modules.container.ParameterDict'>, <class 'torch.ScriptDict'>)\nmsg = None, options = {'atol': None, 'atol_override': 0, 'check_device': False, 'check_dtype': True, ...}, __tracebackhide__ = True\npairs = [TensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3)),\n    expected=tensor([], d...ck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)]\n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n>               pair.compare()\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1075: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3)),\n    expected=tensor([], de...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\n    def compare(self) -> None:\n        actual, expected = self.actual, self.expected\n    \n        self._compare_attributes(actual, expected)\n        if any(input.device.type == \"meta\" for input in (actual, expected)):\n            return\n    \n        actual, expected = self._equalize_attributes(actual, expected)\n>       self._compare_values(actual, expected)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:620: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3)),\n    expected=tensor([], de...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([], device='xla:1', size=(33, 0, 3, 3, 3)), expected = tensor([], device='xla:1', size=(33, 0, 3, 3, 3))\n\n    def _compare_values(self, actual: torch.Tensor, expected: torch.Tensor) -> None:\n        if actual.is_quantized:\n            compare_fn = self._compare_quantized_values\n        elif actual.is_sparse:\n            compare_fn = self._compare_sparse_coo_values\n        elif actual.layout in {torch.sparse_csr, torch.sparse_csc, torch.sparse_bsr, torch.sparse_bsc}:\n            compare_fn = self._compare_sparse_compressed_values\n        else:\n            compare_fn = self._compare_regular_values_close\n    \n>       compare_fn(actual, expected, rtol=self.rtol, atol=self.atol, equal_nan=self.equal_nan)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:714: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3)),\n    expected=tensor([], de...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.float64)\nexpected = tensor([], device='xla:1', size=(33, 0, 3, 3, 3), dtype=torch.float64)\n\n    def _compare_regular_values_close(\n        self,\n        actual: torch.Tensor,\n        expected: torch.Tensor,\n        *,\n        rtol: float,\n        atol: float,\n        equal_nan: bool,\n        identifier: Optional[Union[str, Callable[[str], str]]] = None,\n    ) -> None:\n        \"\"\"Checks if the values of two tensors are close up to a desired tolerance.\"\"\"\n        actual, expected = self._promote_for_comparison(actual, expected)\n>       matches = torch.isclose(actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan)\nE       RuntimeError: unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:846: RuntimeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <src.pytorch_tests_reduced.Conv3d_test.TestConvolutionNNXLA testMethod=test_conv_empty_channel_xla_float32>, device = 'xla:1'\ndtype = torch.float32\n\n    @dtypes(torch.float, torch.cfloat)\n    def test_conv_empty_channel(self, device, dtype):\n        in_channels = 0\n        # mod = torch.nn.Conv1d(in_channels, 8, 2, stride=2, dtype=dtype).to(device)\n        # inp = torch.randn(2, 0, 15, device=device, dtype=dtype)\n        # _test_module_empty_input(self, mod, inp, check_size=False)\n    \n        # with self.assertRaisesRegex(RuntimeError, \"Given groups=1, weight\"):\n        #     inp = torch.randn(2, 1, 0, device=device, dtype=dtype)\n        #     mod(inp)\n    \n        # mod = torch.nn.Conv2d(in_channels, 33, 3, stride=2, dtype=dtype).to(device)\n        # inp = torch.randn(2, 0, 50, 100, device=device, dtype=dtype)\n        # _test_module_empty_input(self, mod, inp, check_size=False)\n    \n        # with self.assertRaisesRegex(RuntimeError, \"Given groups=1, weight\"):\n        #     inp = torch.randn(2, 1, 40, 0, device=device, dtype=dtype)\n        #     mod(inp)\n        with pytorch_op_timer():\n            mod = torch.nn.Conv3d(in_channels, 33, 3, stride=2, dtype=dtype).to(device)\n        inp = torch.randn(2, 0, 50, 20, 40, device=device, dtype=dtype)\n>       _test_module_empty_input(self, mod, inp, check_size=False)\n\nsrc/pytorch_tests_reduced/Conv3d_test.py:265: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntest_case = <src.pytorch_tests_reduced.Conv3d_test.TestConvolutionNNXLA testMethod=test_conv_empty_channel_xla_float32>\nmodule = Conv3d(0, 33, kernel_size=(3, 3, 3), stride=(2, 2, 2)), inp = tensor([], device='xla:1', size=(2, 0, 50, 20, 40), requires_grad=True)\ncheck_size = False, inference = False\n\n    def _test_module_empty_input(test_case, module, inp, check_size=True, inference=False):\n        if not inference:\n            inp.requires_grad_(True)\n        out = module(inp)\n        if not inference:\n            gO = torch.rand_like(out)\n            out.backward(gO)\n        if check_size:\n            test_case.assertEqual(out.size(), inp.size())\n        if not inference:\n            for p in module.parameters():\n                if p.requires_grad:\n                    print(\"***GRAD\", p.grad, torch.zeros_like(p.grad))\n>                   test_case.assertEqual(p.grad, torch.zeros_like(p.grad))\nE                   RuntimeError: Comparing\nE                   \nE                   TensorOrArrayPair(\nE                       id=(),\nE                       actual=tensor([], device='xla:1', size=(33, 0, 3, 3, 3)),\nE                       expected=tensor([], device='xla:1', size=(33, 0, 3, 3, 3)),\nE                       rtol=1.3e-06,\nE                       atol=1e-05,\nE                       equal_nan=True,\nE                       check_device=False,\nE                       check_dtype=True,\nE                       check_layout=False,\nE                       check_stride=False,\nE                       check_is_coalesced=False,\nE                   )\nE                   \nE                   resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.\n\nsrc/pytorch_tests_reduced/common_nn.py:6473: RuntimeError"
            },
            "teardown": {
                "duration": 0.0002517749999242369,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_modules_raise_error_on_incorrect_input_size_xla",
            "lineno": 90,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003613740000218968,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.15060926300066058,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001475549997849157,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_conv_shapecheck_xla",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033504200018796837,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06878790800055867,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019086700012849178,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Conv3d_test.py::TestConvolutionNNXLA::test_invalid_conv3d_xla",
            "lineno": 45,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004898239994872711,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.09817364199989242,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002720770007726969,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU::test_pin_memory_cpu",
            "lineno": 58,
            "outcome": "failed",
            "setup": {
                "duration": 0.00034700200012593996,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0010007249993577716,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/Dataset_test.py",
                    "lineno": 62,
                    "message": "AssertionError: False is not true"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/Dataset_test.py",
                        "lineno": 62,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.Dataset_test.TestDictDataLoaderCPU testMethod=test_pin_memory_cpu>, device = 'cpu'\n\n    def test_pin_memory(self, device):\n        loader = DataLoader(self.dataset, batch_size=2, pin_memory=True)\n        for sample in loader:\n>           self.assertTrue(sample['a_tensor'].is_pinned())\nE           AssertionError: False is not true\n\nsrc/pytorch_tests_reduced/Dataset_test.py:62: AssertionError"
            },
            "teardown": {
                "duration": 0.0001406600003974745,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU::test_pin_memory_device_cpu",
            "lineno": 64,
            "outcome": "failed",
            "setup": {
                "duration": 0.00028040699999110075,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.009454363999793713,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py",
                    "lineno": 50,
                    "message": "NotImplementedError: Could not run 'aten::_pin_memory' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_pin_memory' is only available for these backends: [FPGA, Vulkan, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:51977 [kernel]\nXLA: registered at torch_xla/csrc/aten_cpu_fallback.cpp:44 [backend fallback]\nBackendSelect: registered at aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:13506 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/Dataset_test.py",
                        "lineno": 68,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py",
                        "lineno": 652,
                        "message": "in __next__"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py",
                        "lineno": 694,
                        "message": "in _next_data"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py",
                        "lineno": 55,
                        "message": "in pin_memory"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py",
                        "lineno": 55,
                        "message": "in <dictcomp>"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py",
                        "lineno": 50,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.Dataset_test.TestDictDataLoaderCPU testMethod=test_pin_memory_device_cpu>, device = 'cpu'\n\n    def test_pin_memory_device(self, device):\n        loader = DataLoader(self.dataset, batch_size=2,\n                            pin_memory=True, pin_memory_device=device)\n>       for sample in loader:\n\nsrc/pytorch_tests_reduced/Dataset_test.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:652: in __next__\n    data = self._next_data()\n/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:694: in _next_data\n    data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py:55: in pin_memory\n    return type(data)({k: pin_memory(sample, device) for k, sample in data.items()})  # type: ignore[call-arg]\n/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py:55: in <dictcomp>\n    return type(data)({k: pin_memory(sample, device) for k, sample in data.items()})  # type: ignore[call-arg]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndata = tensor([[[0., 0.],\n         [0., 0.],\n         [0., 0.],\n         [0., 0.]],\n\n        [[1., 1.],\n         [1., 1.],\n         [1., 1.],\n         [1., 1.]]])\ndevice = 'cpu'\n\n    def pin_memory(data, device=None):\n        if isinstance(data, torch.Tensor):\n>           return data.pin_memory(device)\nE           NotImplementedError: Could not run 'aten::_pin_memory' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_pin_memory' is only available for these backends: [FPGA, Vulkan, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\nE           \nE           CUDA: registered at aten/src/ATen/RegisterCUDA.cpp:51977 [kernel]\nE           XLA: registered at torch_xla/csrc/aten_cpu_fallback.cpp:44 [backend fallback]\nE           BackendSelect: registered at aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nE           Python: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nE           Named: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nE           Conjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nE           Negative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nE           ZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nE           ADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nE           AutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           UNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           UNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           Tracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:13506 [kernel]\nE           AutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nE           Autocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nE           Batched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nE           VmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nE           Functionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nE           PythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n\n/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py:50: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00015982600052666385,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU::test_pin_memory_with_only_device_cpu",
            "lineno": 72,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003236739994463278,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007685789996685344,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011567399997147731,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderCPU::test_sequential_batch_cpu",
            "lineno": 32,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002859450005416875,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.34755393199975515,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0004692430002251058,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA::test_pin_memory_device_xla",
            "lineno": 64,
            "outcome": "failed",
            "setup": {
                "duration": 0.0036860529999103164,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.011364061000676884,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py",
                    "lineno": 50,
                    "message": "NotImplementedError: Could not run 'aten::_pin_memory' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_pin_memory' is only available for these backends: [FPGA, Vulkan, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:51977 [kernel]\nXLA: registered at torch_xla/csrc/aten_cpu_fallback.cpp:44 [backend fallback]\nBackendSelect: registered at aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:13506 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/Dataset_test.py",
                        "lineno": 68,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py",
                        "lineno": 652,
                        "message": "in __next__"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py",
                        "lineno": 694,
                        "message": "in _next_data"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py",
                        "lineno": 55,
                        "message": "in pin_memory"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py",
                        "lineno": 55,
                        "message": "in <dictcomp>"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py",
                        "lineno": 50,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.Dataset_test.TestDictDataLoaderXLA testMethod=test_pin_memory_device_xla>, device = 'xla:1'\n\n    def test_pin_memory_device(self, device):\n        loader = DataLoader(self.dataset, batch_size=2,\n                            pin_memory=True, pin_memory_device=device)\n>       for sample in loader:\n\nsrc/pytorch_tests_reduced/Dataset_test.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:652: in __next__\n    data = self._next_data()\n/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:694: in _next_data\n    data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py:55: in pin_memory\n    return type(data)({k: pin_memory(sample, device) for k, sample in data.items()})  # type: ignore[call-arg]\n/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py:55: in <dictcomp>\n    return type(data)({k: pin_memory(sample, device) for k, sample in data.items()})  # type: ignore[call-arg]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndata = tensor([[[0., 0.],\n         [0., 0.],\n         [0., 0.],\n         [0., 0.]],\n\n        [[1., 1.],\n         [1., 1.],\n         [1., 1.],\n         [1., 1.]]])\ndevice = 'xla:1'\n\n    def pin_memory(data, device=None):\n        if isinstance(data, torch.Tensor):\n>           return data.pin_memory(device)\nE           NotImplementedError: Could not run 'aten::_pin_memory' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_pin_memory' is only available for these backends: [FPGA, Vulkan, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\nE           \nE           CUDA: registered at aten/src/ATen/RegisterCUDA.cpp:51977 [kernel]\nE           XLA: registered at torch_xla/csrc/aten_cpu_fallback.cpp:44 [backend fallback]\nE           BackendSelect: registered at aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nE           Python: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nE           Named: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nE           Conjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nE           Negative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nE           ZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nE           ADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nE           AutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           UNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           UNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           AutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:11935 [autograd kernel]\nE           Tracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:13506 [kernel]\nE           AutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nE           Autocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nE           Batched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nE           VmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nE           Functionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nE           PythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n\n/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/pin_memory.py:50: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00019143500048812712,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA::test_pin_memory_with_only_device_xla",
            "lineno": 72,
            "outcome": "passed",
            "setup": {
                "duration": 0.00037030200019216863,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009481460001552477,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001217459994222736,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA::test_pin_memory_xla",
            "lineno": 58,
            "outcome": "failed",
            "setup": {
                "duration": 0.00030091100052231923,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005821900003866176,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/Dataset_test.py",
                    "lineno": 62,
                    "message": "AssertionError: False is not true"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/Dataset_test.py",
                        "lineno": 62,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.Dataset_test.TestDictDataLoaderXLA testMethod=test_pin_memory_xla>, device = 'xla:1'\n\n    def test_pin_memory(self, device):\n        loader = DataLoader(self.dataset, batch_size=2, pin_memory=True)\n        for sample in loader:\n>           self.assertTrue(sample['a_tensor'].is_pinned())\nE           AssertionError: False is not true\n\nsrc/pytorch_tests_reduced/Dataset_test.py:62: AssertionError"
            },
            "teardown": {
                "duration": 0.00012650899952859618,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Dataset_test.py::TestDictDataLoaderXLA::test_sequential_batch_xla",
            "lineno": 32,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028224899961060146,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.32334951299981185,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000476042999252968,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestOptimCPU::test_sgd_cpu",
            "lineno": 48,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005706310003006365,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.7419014550005159,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001896149997264729,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ExponentialLR_test.py::TestOptimXLA::test_sgd_xla",
            "lineno": 48,
            "outcome": "passed",
            "setup": {
                "duration": 0.0031058670001584687,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.7510774069996842,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002218370000264258,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/GELU_test.py::TestNNDeviceTypeCPU::test_transformerencoderlayer_gelu_cpu_float32",
            "lineno": 18,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005308989993864088,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03673735300071712,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018933599949377822,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/GELU_test.py::TestNNDeviceTypeXLA::test_transformerencoderlayer_gelu_xla_float32",
            "lineno": 18,
            "outcome": "passed",
            "setup": {
                "duration": 0.0026765349994093413,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.2214541049997933,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002302940001754905,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestOptimCPU::test_lbfgs_cpu",
            "lineno": 204,
            "outcome": "passed",
            "setup": {
                "duration": 0.0006874410000818898,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.5364616679999017,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018243999966216506,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/LBFGS_test.py::TestOptimXLA::test_lbfgs_xla",
            "lineno": 204,
            "outcome": "passed",
            "setup": {
                "duration": 0.002124808999724337,
                "outcome": "passed"
            },
            "call": {
                "duration": 54.27452460999939,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0004287409992684843,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestOptimCPU::test_rprop_cpu",
            "lineno": 313,
            "outcome": "passed",
            "setup": {
                "duration": 0.0007152590005716775,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.3663501270002598,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020006100021419115,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/RProp_test.py::TestOptimXLA::test_rprop_xla",
            "lineno": 313,
            "outcome": "failed",
            "setup": {
                "duration": 0.00234542100042745,
                "outcome": "passed"
            },
            "call": {
                "duration": 1020.5607444810003,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/optim/rprop.py",
                    "lineno": 184,
                    "message": "Failed: Timeout >1020.0s"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/RProp_test.py",
                        "lineno": 316,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/RProp_test.py",
                        "lineno": 269,
                        "message": "in _test_basic_cases"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/RProp_test.py",
                        "lineno": 104,
                        "message": "in _test_basic_cases_template"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py",
                        "lineno": 109,
                        "message": "in wrapper"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py",
                        "lineno": 27,
                        "message": "in decorate_context"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/optim/rprop.py",
                        "lineno": 115,
                        "message": "in step"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/optim/rprop.py",
                        "lineno": 157,
                        "message": "in rprop"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/optim/rprop.py",
                        "lineno": 184,
                        "message": "Failed"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.RProp_test.TestOptimXLA testMethod=test_rprop_xla>, device = 'xla:1'\n\n    def test_rprop(self, device):\n        for optimizer in [optim.Rprop, optim_mt.Rprop]:\n>           self._test_basic_cases(\n                lambda weight, bias: optimizer([weight, bias], lr=1e-3), device=device\n            )\n\nsrc/pytorch_tests_reduced/RProp_test.py:316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/RProp_test.py:269: in _test_basic_cases\n    self._test_basic_cases_template(\nsrc/pytorch_tests_reduced/RProp_test.py:104: in _test_basic_cases_template\n    optimizer.step(fn)\n/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:109: in wrapper\n    return func(*args, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py:27: in decorate_context\n    return func(*args, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/optim/rprop.py:115: in step\n    rprop(params,\n/usr/local/lib/python3.8/dist-packages/torch/optim/rprop.py:157: in rprop\n    func(params,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nparams = [Parameter containing:\ntensor([[ 0.1646,  0.1179,  0.9611,  1.9591, -1.4386],\n        [-0.4016, -1.5158, -2.6121, -1.7...,  0.4142,  1.2948, -1.1080,  1.4272, -1.3883,  0.6468,\n        -0.9144, -0.5716], device='xla:1', requires_grad=True)]\ngrads = [tensor([[ 1.0641e-02,  4.7469e-02, -1.3636e-01,  1.4085e-02, -8.6811e-02],\n        [-4.6098e-04, -2.0564e-03,  5.9072...or([ 0.1181, -0.0051,  0.0325, -0.0201, -0.0495,  1.7197,  1.3070,  0.0617,\n        -0.0099, -0.0204], device='xla:1')]\nprevs = [tensor([[ 3.1525e-02,  1.4063e-01, -4.0398e-01,  4.1728e-02, -2.5718e-01],\n        [ 0.0000e+00,  0.0000e+00,  0.0000...or([ 0.3500,  0.0000,  0.0000, -0.0480,  0.0000,  2.3875,  1.9748, -0.1701,\n         0.0181, -0.0483], device='xla:1')]\nstep_sizes = [tensor([[0.0331, 0.0331, 0.0331, 0.0331, 0.0331],\n        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n        [0.0048, ...:1'), tensor([0.0331, 0.0006, 0.0048, 0.0040, 0.0138, 0.0954, 0.0954, 0.0331, 0.0040,\n        0.0040], device='xla:1')]\n\n    def _single_tensor_rprop(params: List[Tensor],\n                             grads: List[Tensor],\n                             prevs: List[Tensor],\n                             step_sizes: List[Tensor],\n                             *,\n                             step_size_min: float,\n                             step_size_max: float,\n                             etaminus: float,\n                             etaplus: float):\n    \n        for i, param in enumerate(params):\n            grad = grads[i]\n            prev = prevs[i]\n            step_size = step_sizes[i]\n    \n            sign = grad.mul(prev).sign()\n            sign[sign.gt(0)] = etaplus\n>           sign[sign.lt(0)] = etaminus\nE           Failed: Timeout >1020.0s\n\n/usr/local/lib/python3.8/dist-packages/torch/optim/rprop.py:184: Failed"
            },
            "teardown": {
                "duration": 0.0005027120005252073,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_append_cpu",
            "lineno": 149,
            "outcome": "passed",
            "setup": {
                "duration": 0.0007108270001481287,
                "outcome": "passed"
            },
            "call": {
                "duration": 2.826838009000312,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017879100050777197,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_delitem_cpu",
            "lineno": 131,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004053370003020973,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0022780700001021614,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011959199946431909,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_getitem_cpu",
            "lineno": 66,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028796700007660547,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0028721890002998407,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011111799994978355,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_setitem_cpu",
            "lineno": 96,
            "outcome": "passed",
            "setup": {
                "duration": 0.000278395999885106,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0011924729997190298,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00029055999948468525,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNCPU::test_Sequential_setitem_named_cpu",
            "lineno": 112,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002720080001381575,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001465711000491865,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002062779994957964,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_append_xla",
            "lineno": 149,
            "outcome": "passed",
            "setup": {
                "duration": 0.0019313210004838766,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.10967803899984574,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015100800010259263,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_delitem_xla",
            "lineno": 131,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003626990001066588,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.04118693400050688,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015636599982826738,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_getitem_xla",
            "lineno": 66,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034422800035827095,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.07735556799980259,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001662579998082947,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_setitem_named_xla",
            "lineno": 112,
            "outcome": "passed",
            "setup": {
                "duration": 0.00042527299956418574,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0091729010000563,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014466500033449847,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Sequential_test.py::TestNNXLA::test_Sequential_setitem_xla",
            "lineno": 96,
            "outcome": "passed",
            "setup": {
                "duration": 0.00032590000046184286,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.022062820000428474,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022534100025950465,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitCPU::test_slicing_of_subset_of_dataset_cpu",
            "lineno": 42,
            "outcome": "passed",
            "setup": {
                "duration": 0.000400867999815091,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0021393429997260682,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001298709994443925,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitCPU::test_slicing_of_subset_of_subset_cpu",
            "lineno": 56,
            "outcome": "passed",
            "setup": {
                "duration": 0.00032071100031316746,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0013901410002290504,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001594440000189934,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitXLA::test_slicing_of_subset_of_dataset_xla",
            "lineno": 42,
            "outcome": "passed",
            "setup": {
                "duration": 0.00219248399935168,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.26483810900026583,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018877799993788358,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Subset_test.py::TestDatasetRandomSplitXLA::test_slicing_of_subset_of_subset_xla",
            "lineno": 56,
            "outcome": "passed",
            "setup": {
                "duration": 0.00041646200043032877,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06052183900010277,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002068980002150056,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestNNCPU::test_transformerencoder_cpu",
            "lineno": 73,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004676099997595884,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.13733546799994656,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001956570004040259,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py::TestNNXLA::test_transformerencoder_xla",
            "lineno": 73,
            "outcome": "failed",
            "setup": {
                "duration": 0.001610712000001513,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.8840459140001258,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/TransformerEncoderLayer_test.py",
                    "lineno": 145,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 36 / 40 (90.0%)\nGreatest absolute difference: 0.0008821487426757812 at index (1, 1, 0) (up to 1e-05 allowed)\nGreatest relative difference: 0.010683939792215824 at index (1, 1, 1) (up to 1e-07 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py",
                        "lineno": 269,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/TransformerEncoderLayer_test.py",
                        "lineno": 145,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.TransformerEncoderLayer_test.TestNNXLA testMethod=test_transformerencoder_xla>, device = 'xla:1'\n\n    def test_transformerencoder(self, device):\n        torch.set_default_dtype(torch.double)\n        def get_a_test_layer( activation, batch_first=False):\n            d_model = 4\n            nhead = 2\n            dim_feedforward = 16\n            dropout = 0.0\n            # device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    \n            # with pytorch_op_timer()\n            with pytorch_op_timer():\n                layer = nn.TransformerEncoderLayer(\n                d_model,\n                nhead,\n                dim_feedforward=dim_feedforward,\n                dropout=dropout,\n                activation=activation,\n                batch_first=batch_first).to(device)\n    \n            with torch.no_grad():\n                # set constant weights of the model\n                for idx, p in enumerate(layer.parameters()):\n                    x = p.data\n                    sz = x.view(-1).size(0)\n                    shape = x.shape\n                    x = torch.cos(torch.arange(0, sz).float().view(shape))\n                    p.data.copy_(x)\n    \n            return layer\n    \n        # this is a deterministic test for TransformerEncoder\n        activation = F.relu\n        # use_cuda = torch.cuda.is_available()\n        # device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    \n        def _test(batch_first, training):\n            def perm_fn(x):\n                return x.transpose(1, 0) if batch_first else x\n    \n            encoder_layer = get_a_test_layer( activation=activation,\n                                             batch_first=batch_first)\n            with pytorch_op_timer():\n                model = nn.TransformerEncoder(encoder_layer, 1).to(device)\n            if not training:\n                model = model.eval()\n    \n            # deterministic input\n            encoder_input = perm_fn(torch.tensor([[[0.7462, 0.6653, 0.5679, 0.4891],\n                                                   [0.5387, 0.1655, 0.3565, 0.0471]],\n                                                  [[0.8335, 0.2799, 0.5031, 0.2947],\n                                                   [0.1402, 0.0318, 0.7636, 0.1346]],\n                                                  [[0.6333, 0.9344, 0.1376, 0.9938],\n                                                   [0.8924, 0.2872, 0.6692, 0.2944]],\n                                                  [[0.9897, 0.6915, 0.3154, 0.1733],\n                                                   [0.8645, 0.3513, 0.3064, 0.0767]],\n                                                  [[0.8117, 0.2366, 0.4838, 0.7881],\n                                                   [0.3718, 0.4945, 0.9511, 0.0864]]]\n                                                 )).to(device)\n            result = model(encoder_input)\n            ref_output = perm_fn(torch.tensor([[[2.428589, 0.020835, -0.602055, -0.085249],\n                                                [2.427987, 0.021213, -0.602496, -0.084103]],\n                                               [[2.424689, 0.019155, -0.604793, -0.085672],\n                                                [2.413863, 0.022211, -0.612486, -0.072490]],\n                                               [[2.433774, 0.021598, -0.598343, -0.087548],\n                                                [2.425104, 0.019748, -0.604515, -0.084839]],\n                                               [[2.436185, 0.022682, -0.596625, -0.087261],\n                                                [2.433556, 0.021891, -0.598509, -0.086832]],\n                                               [[2.416246, 0.017512, -0.610712, -0.082961],\n                                                [2.422901, 0.024187, -0.606178, -0.074929]]]\n                                              )).to(device)\n            self.assertEqual(tuple(result.shape), tuple(ref_output.shape))\n            torch.testing.assert_close(\n                result, ref_output, rtol=1e-7, atol=1e-5)\n    \n            # all 0\n            mask = torch.zeros([2, 5]).to(device) == 1\n            result = model(encoder_input, src_key_padding_mask=mask)\n            self.assertEqual(tuple(result.shape), tuple(ref_output.shape))\n            torch.testing.assert_close(\n                result, ref_output, rtol=1e-7, atol=1e-5)\n            mask[0, 1] = 1\n            mask[1, 3] = 1\n            mask[1, 4] = 1\n            # If mask is not left aligned\n            # We disable nested tensor\n            model.enable_nested_tensor = False\n            result = model(encoder_input, src_key_padding_mask=mask)\n            ref_output = perm_fn(torch.tensor([[[2.429026, 0.020793, -0.601741, -0.085642],\n                                                [2.428811, 0.021445, -0.601912, -0.084252]],\n                                               [[2.425009, 0.019155, -0.604566, -0.085899],\n                                                [2.415408, 0.02249, -0.611415, -0.073]],\n                                               [[2.434199, 0.021682, -0.598039, -0.087699],\n                                                [2.42598, 0.019941, -0.603896, -0.085091]],\n                                               [[2.436457, 0.022736, -0.59643, -0.08736],\n                                                [2.434021, 0.022093, -0.598179, -0.08679]],\n                                               [[2.416531, 0.017498, -0.610513, -0.083181],\n                                                [2.4242, 0.024653, -0.605266, -0.074959]]]\n                                              )).to(device)\n            self.assertEqual(tuple(result.shape), tuple(ref_output.shape))\n            torch.testing.assert_close(\n                result, ref_output, rtol=1e-7, atol=1e-5)\n    \n            # test case 2, multiple layers no norm\n            with pytorch_op_timer():\n                model = nn.TransformerEncoder(\n                encoder_layer, 2, enable_nested_tensor=False).to(device)\n            if not training:\n                model = model.eval()\n            result = model(encoder_input, src_key_padding_mask=mask)\n            ref_output = perm_fn(torch.tensor([[[2.419051, 0.017446, -0.608738, -0.085003],\n                                                [2.419102, 0.017452, -0.608703, -0.085026]],\n                                               [[2.419043, 0.017445, -0.608744, -0.084999],\n                                                [2.419052, 0.017446, -0.608738, -0.085004]],\n                                               [[2.419067, 0.017448, -0.608727, -0.085010],\n                                                [2.419098, 0.017452, -0.608706, -0.085024]],\n                                               [[2.419072, 0.017449, -0.608724, -0.085012],\n                                                [2.419119, 0.017455, -0.608691, -0.085034]],\n                                               [[2.419019, 0.017442, -0.608761, -0.084989],\n                                                [2.419075, 0.017449, -0.608722, -0.085014]]]\n                                              )).to(device)\n            self.assertEqual(tuple(result.shape), tuple(ref_output.shape))\n            torch.testing.assert_close(\n                result, ref_output, rtol=1e-7, atol=1e-5)\n            with pytorch_op_timer():\n                model = nn.TransformerEncoder(\n                encoder_layer, 6, enable_nested_tensor=False).to(device)\n            if not training:\n                model = model.eval()\n            result = model(encoder_input, src_key_padding_mask=mask)\n            ref_output = perm_fn(torch.tensor([[[2.419101, 0.017453, -0.608703, -0.085025],\n                                                [2.419101, 0.017453, -0.608704, -0.085025]],\n                                               [[2.419101, 0.017453, -0.608703, -0.085025],\n                                                [2.419101, 0.017453, -0.608704, -0.085025]],\n                                               [[2.419101, 0.017453, -0.608703, -0.085025],\n                                                [2.419101, 0.017453, -0.608704, -0.085025]],\n                                               [[2.419101, 0.017453, -0.608703, -0.085025],\n                                                [2.419101, 0.017453, -0.608704, -0.085025]],\n                                               [[2.419101, 0.017453, -0.608703, -0.085025],\n                                                [2.419101, 0.017453, -0.608704, -0.085025]]]\n                                              )).to(device)\n            self.assertEqual(tuple(result.shape), tuple(ref_output.shape))\n            torch.testing.assert_close(\n                result, ref_output, rtol=1e-7, atol=1e-5)\n    \n            # test case 3, multiple layers with norm\n            # d_model = 4\n            norm = nn.LayerNorm(4)\n            with pytorch_op_timer():\n                model = nn.TransformerEncoder(\n                encoder_layer, 2, norm=norm, enable_nested_tensor=False).to(device)\n            if not training:\n                model = model.eval()\n            result = model(encoder_input, src_key_padding_mask=mask)\n            ref_output = perm_fn(torch.tensor([[[1.695949, -0.357635, -0.893077, -0.445238],\n                                                [1.695955, -0.357639, -0.893050, -0.445266]],\n                                               [[1.695948, -0.357634, -0.893082, -0.445233],\n                                                [1.695950, -0.357635, -0.893077, -0.445238]],\n                                               [[1.695951, -0.357636, -0.893069, -0.445246],\n                                                [1.695955, -0.357639, -0.893052, -0.445264]],\n                                               [[1.695952, -0.357636, -0.893066, -0.445249],\n                                                [1.695957, -0.357641, -0.893041, -0.445276]],\n                                               [[1.695946, -0.357632, -0.893095, -0.445220],\n                                                [1.695952, -0.357637, -0.893065, -0.445251]]]\n                                              )).to(device)\n            self.assertEqual(tuple(result.shape), tuple(ref_output.shape))\n            torch.testing.assert_close(\n                result, ref_output, rtol=1e-7, atol=1e-5)\n            with pytorch_op_timer():\n                model = nn.TransformerEncoder(\n                encoder_layer, 6, norm=norm, enable_nested_tensor=False).to(device)\n            if not training:\n                model = model.eval()\n            result = model(encoder_input, src_key_padding_mask=mask)\n            ref_output = perm_fn(torch.tensor([[[1.695955, -0.357639, -0.893051, -0.445265],\n                                                [1.695955, -0.357639, -0.893051, -0.445265]],\n                                               [[1.695955, -0.357639, -0.893051, -0.445265],\n                                                [1.695955, -0.357639, -0.893051, -0.445265]],\n                                               [[1.695955, -0.357639, -0.893051, -0.445265],\n                                                [1.695955, -0.357639, -0.893051, -0.445265]],\n                                               [[1.695955, -0.357639, -0.893051, -0.445265],\n                                                [1.695955, -0.357639, -0.893051, -0.445265]],\n                                               [[1.695955, -0.357639, -0.893051, -0.445265],\n                                                [1.695955, -0.357639, -0.893051, -0.445265]]]\n                                              )).to(device)\n            self.assertEqual(tuple(result.shape), tuple(ref_output.shape))\n            torch.testing.assert_close(\n                result, ref_output, rtol=1e-7, atol=1e-5)\n        for batch_first in (True, False):\n            for training in (True, False):\n                # Fast path requires inference mode.\n                if training:\n                    cm = contextlib.nullcontext()\n                else:\n                    cm = torch.no_grad()\n                with cm:\n>                   _test(batch_first, training)\n\nsrc/pytorch_tests_reduced/TransformerEncoderLayer_test.py:269: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nbatch_first = True, training = True\n\n    def _test(batch_first, training):\n        def perm_fn(x):\n            return x.transpose(1, 0) if batch_first else x\n    \n        encoder_layer = get_a_test_layer( activation=activation,\n                                         batch_first=batch_first)\n        with pytorch_op_timer():\n            model = nn.TransformerEncoder(encoder_layer, 1).to(device)\n        if not training:\n            model = model.eval()\n    \n        # deterministic input\n        encoder_input = perm_fn(torch.tensor([[[0.7462, 0.6653, 0.5679, 0.4891],\n                                               [0.5387, 0.1655, 0.3565, 0.0471]],\n                                              [[0.8335, 0.2799, 0.5031, 0.2947],\n                                               [0.1402, 0.0318, 0.7636, 0.1346]],\n                                              [[0.6333, 0.9344, 0.1376, 0.9938],\n                                               [0.8924, 0.2872, 0.6692, 0.2944]],\n                                              [[0.9897, 0.6915, 0.3154, 0.1733],\n                                               [0.8645, 0.3513, 0.3064, 0.0767]],\n                                              [[0.8117, 0.2366, 0.4838, 0.7881],\n                                               [0.3718, 0.4945, 0.9511, 0.0864]]]\n                                             )).to(device)\n        result = model(encoder_input)\n        ref_output = perm_fn(torch.tensor([[[2.428589, 0.020835, -0.602055, -0.085249],\n                                            [2.427987, 0.021213, -0.602496, -0.084103]],\n                                           [[2.424689, 0.019155, -0.604793, -0.085672],\n                                            [2.413863, 0.022211, -0.612486, -0.072490]],\n                                           [[2.433774, 0.021598, -0.598343, -0.087548],\n                                            [2.425104, 0.019748, -0.604515, -0.084839]],\n                                           [[2.436185, 0.022682, -0.596625, -0.087261],\n                                            [2.433556, 0.021891, -0.598509, -0.086832]],\n                                           [[2.416246, 0.017512, -0.610712, -0.082961],\n                                            [2.422901, 0.024187, -0.606178, -0.074929]]]\n                                          )).to(device)\n        self.assertEqual(tuple(result.shape), tuple(ref_output.shape))\n>       torch.testing.assert_close(\n            result, ref_output, rtol=1e-7, atol=1e-5)\nE       AssertionError: Tensor-likes are not close!\nE       \nE       Mismatched elements: 36 / 40 (90.0%)\nE       Greatest absolute difference: 0.0008821487426757812 at index (1, 1, 0) (up to 1e-05 allowed)\nE       Greatest relative difference: 0.010683939792215824 at index (1, 1, 1) (up to 1e-07 allowed)\n\nsrc/pytorch_tests_reduced/TransformerEncoderLayer_test.py:145: AssertionError"
            },
            "teardown": {
                "duration": 0.0002495830003681476,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestNNCPU::test_Transformer_cell_cpu",
            "lineno": 86,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004990500001440523,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.8131144320004751,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002783130003081169,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/Transformer_test.py::TestNNXLA::test_Transformer_cell_xla",
            "lineno": 86,
            "outcome": "passed",
            "setup": {
                "duration": 0.002421573999527027,
                "outcome": "passed"
            },
            "call": {
                "duration": 6.706862117999663,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003273289994467632,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU::test_adaptive_avg_pool3d_output_size_one_cpu",
            "lineno": 35,
            "outcome": "passed",
            "setup": {
                "duration": 0.0007597070007250295,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0026637629998731427,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013650599976244848,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU::test_adaptive_pool_invalid_cpu",
            "lineno": 52,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003726980003193603,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.013638369000545936,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015530000018770806,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU::test_adaptive_pooling_zero_batch_cpu_float32",
            "lineno": 19,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028243900032975944,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0020850549999522627,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012213799982419005,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeCPU::test_adaptive_pooling_zero_batch_cpu_float64",
            "lineno": 19,
            "outcome": "passed",
            "setup": {
                "duration": 0.00029672999971808167,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0017254409995075548,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00033475999953225255,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA::test_adaptive_avg_pool3d_output_size_one_xla",
            "lineno": 35,
            "outcome": "passed",
            "setup": {
                "duration": 0.002656099999512662,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.18015220899997075,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019121500008623116,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA::test_adaptive_pool_invalid_xla",
            "lineno": 52,
            "outcome": "passed",
            "setup": {
                "duration": 0.00037346699991758214,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.015306541999962064,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001562609995744424,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA::test_adaptive_pooling_zero_batch_xla_float32",
            "lineno": 19,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036521299989544787,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.09066046299994923,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018899400038208114,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/adaptiveavgpool3d_test.py::TestPoolingNNDeviceTypeXLA::test_adaptive_pooling_zero_batch_xla_float64",
            "lineno": 19,
            "outcome": "passed",
            "setup": {
                "duration": 0.000478320000183885,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.07174457800010714,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022206899939192226,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_add_module_cpu",
            "lineno": 198,
            "outcome": "skipped",
            "setup": {
                "duration": 0.000608237999585981,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007476990003851824,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/add_module_test.py', 199, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00020244699953764211,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_add_module_raises_error_if_attr_exists_cpu",
            "lineno": 177,
            "outcome": "skipped",
            "setup": {
                "duration": 0.000319069000397576,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006493920000139042,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/add_module_test.py', 178, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00022739799987903098,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_named_children_cpu",
            "lineno": 87,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003407120002520969,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007694919995628879,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/add_module_test.py', 88, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00020220399983372772,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_named_modules_cpu",
            "lineno": 108,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003620990000854363,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0008970789995146333,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/add_module_test.py', 109, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00019080800029769307,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_register_buffer_raises_error_if_attr_exists_cpu",
            "lineno": 139,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003263949993197457,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006371300005412195,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/add_module_test.py', 140, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00019100600002275314,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNCPU::test_register_parameter_raises_error_if_attr_exists_cpu",
            "lineno": 158,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002928339999925811,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006140149998827837,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/add_module_test.py', 159, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00030796400005783653,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_add_module_raises_error_if_attr_exists_xla",
            "lineno": 177,
            "outcome": "passed",
            "setup": {
                "duration": 0.0017959839997274685,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0011201019997315598,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011605000054260017,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_add_module_xla",
            "lineno": 198,
            "outcome": "passed",
            "setup": {
                "duration": 0.000328078999700665,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.006507841000711778,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017932900027517462,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_named_children_xla",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033484499999758555,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.004453769000065222,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016283700006169965,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_named_modules_xla",
            "lineno": 108,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004271790003258502,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.003744832000847964,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015653999980713706,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_register_buffer_raises_error_if_attr_exists_xla",
            "lineno": 139,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034902199968200875,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009865059992080205,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016850000065460335,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/add_module_test.py::TestNNXLA::test_register_parameter_raises_error_if_attr_exists_xla",
            "lineno": 158,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028754499999195104,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009174750002785004,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00029608299973915564,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_bool_cpu_bool",
            "lineno": 112,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005083259993625688,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.2156782590000148,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002213079997090972,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_bfloat16",
            "lineno": 139,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003915879997293814,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.023277452000002086,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011923300007765647,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_complex128",
            "lineno": 139,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003214839998690877,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.028819834999922023,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011641799937933683,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_complex64",
            "lineno": 139,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003182860000379151,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02785214300001826,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012328499997238396,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_float16",
            "lineno": 139,
            "outcome": "passed",
            "setup": {
                "duration": 0.000320090000059281,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02329873899998347,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011742000060621649,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_float32",
            "lineno": 139,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003402459997232654,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.021588689000054728,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012365699967631372,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_float_and_complex_cpu_float64",
            "lineno": 139,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003983289998359396,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.021296150000125635,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001254540002264548,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_int16",
            "lineno": 119,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002926980005213409,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.030172445000061998,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011769299999286886,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_int32",
            "lineno": 119,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003454099996815785,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.030610578999585414,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012644900016312022,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_int64",
            "lineno": 119,
            "outcome": "passed",
            "setup": {
                "duration": 0.000298766999549116,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.029332557000088855,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012766700001520803,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_int8",
            "lineno": 119,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003103950002696365,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02973219799969229,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012511299973994028,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgCPU::test_addr_integral_cpu_uint8",
            "lineno": 119,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002903989998230827,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.029521774999921035,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002595310006654472,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_bool_xla_bool",
            "lineno": 112,
            "outcome": "passed",
            "setup": {
                "duration": 0.0018178359996454674,
                "outcome": "passed"
            },
            "call": {
                "duration": 7.8097464889997354,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001962059996003518,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_bfloat16",
            "lineno": 139,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003999379996457719,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.48591313999986596,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/addr_test.py",
                    "lineno": 145,
                    "message": "AssertionError: RuntimeError not raised"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 145,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_float_and_complex_xla_bfloat16>, device = 'xla:1'\ndtype = torch.bfloat16\n\n    @precisionOverride({torch.bfloat16: 1e-1})\n    @dtypes(*floating_and_complex_types_and(torch.half, torch.bfloat16))\n    def test_addr_float_and_complex(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'Boolean beta only supported for Boolean results.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=True, alpha=1)\nE           AssertionError: RuntimeError not raised\n\nsrc/pytorch_tests_reduced/addr_test.py:145: AssertionError"
            },
            "teardown": {
                "duration": 0.0002127009993273532,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_complex128",
            "lineno": 139,
            "outcome": "failed",
            "setup": {
                "duration": 0.00036223200004315004,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.37756645799981925,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                    "lineno": 1095,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 3 / 2500 (0.1%)\nGreatest absolute difference: 2.1406499950546562e-07 at index (32, 19) (up to 1e-07 allowed)\nGreatest relative difference: 5.932270615714046e-07 at index (29, 48) (up to 1e-07 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 145,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 94,
                        "message": "in _test_addr_vs_numpy"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 78,
                        "message": "in check"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2219,
                        "message": "in assertEqual"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                        "lineno": 1095,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_float_and_complex_xla_complex128>, device = 'xla:1'\ndtype = torch.complex128\n\n    @precisionOverride({torch.bfloat16: 1e-1})\n    @dtypes(*floating_and_complex_types_and(torch.half, torch.bfloat16))\n    def test_addr_float_and_complex(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'Boolean beta only supported for Boolean results.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=True, alpha=1)\n\nsrc/pytorch_tests_reduced/addr_test.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/addr_test.py:94: in _test_addr_vs_numpy\n    check(m_transpose, a, b, beta, alpha)\nsrc/pytorch_tests_reduced/addr_test.py:78: in check\n    self.assertEqual(res, expected, exact_dtype=exact_dtype)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2219: in assertEqual\n    assert_equal(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n                pair.compare()\n            except ErrorMeta as error_meta:\n                error_metas.append(error_meta)\n            # Raising any exception besides `ErrorMeta` while comparing is unexpected and will give some extra information\n            # about what happened. If applicable, the exception should be expected in the future.\n            except Exception as error:\n                raise RuntimeError(\n                    f\"Comparing\\n\\n\"\n                    f\"{pair}\\n\\n\"\n                    f\"resulted in the unexpected exception above. \"\n                    f\"If you are a user and see this message during normal operation \"\n                    \"please file an issue at https://github.com/pytorch/pytorch/issues. \"\n                    \"If you are a developer and working on the comparison functions, \"\n                    \"please except the previous error and raise an expressive `ErrorMeta` instead.\"\n                ) from error\n    \n        if not error_metas:\n            return\n    \n        # TODO: compose all metas into one AssertionError\n>       raise error_metas[0].to_error(msg)\nE       AssertionError: Tensor-likes are not close!\nE       \nE       Mismatched elements: 3 / 2500 (0.1%)\nE       Greatest absolute difference: 2.1406499950546562e-07 at index (32, 19) (up to 1e-07 allowed)\nE       Greatest relative difference: 5.932270615714046e-07 at index (29, 48) (up to 1e-07 allowed)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1095: AssertionError"
            },
            "teardown": {
                "duration": 0.00023647400030313293,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_complex64",
            "lineno": 139,
            "outcome": "failed",
            "setup": {
                "duration": 0.00039651200040680123,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.30739010799970856,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/addr_test.py",
                    "lineno": 145,
                    "message": "AssertionError: RuntimeError not raised"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 145,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_float_and_complex_xla_complex64>, device = 'xla:1'\ndtype = torch.complex64\n\n    @precisionOverride({torch.bfloat16: 1e-1})\n    @dtypes(*floating_and_complex_types_and(torch.half, torch.bfloat16))\n    def test_addr_float_and_complex(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'Boolean beta only supported for Boolean results.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=True, alpha=1)\nE           AssertionError: RuntimeError not raised\n\nsrc/pytorch_tests_reduced/addr_test.py:145: AssertionError"
            },
            "teardown": {
                "duration": 0.00019927499943150906,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_float16",
            "lineno": 139,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003612549999161274,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.16921440199985227,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                    "lineno": 1095,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 117 / 2500 (4.7%)\nGreatest absolute difference: 0.0009765625 at index (2, 46) (up to 1e-05 allowed)\nGreatest relative difference: 0.25 at index (22, 17) (up to 0.001 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 145,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 90,
                        "message": "in _test_addr_vs_numpy"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 78,
                        "message": "in check"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2219,
                        "message": "in assertEqual"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                        "lineno": 1095,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_float_and_complex_xla_float16>, device = 'xla:1', dtype = torch.float16\n\n    @precisionOverride({torch.bfloat16: 1e-1})\n    @dtypes(*floating_and_complex_types_and(torch.half, torch.bfloat16))\n    def test_addr_float_and_complex(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'Boolean beta only supported for Boolean results.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=True, alpha=1)\n\nsrc/pytorch_tests_reduced/addr_test.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/addr_test.py:90: in _test_addr_vs_numpy\n    check(m, a, b, beta, alpha)\nsrc/pytorch_tests_reduced/addr_test.py:78: in check\n    self.assertEqual(res, expected, exact_dtype=exact_dtype)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2219: in assertEqual\n    assert_equal(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n                pair.compare()\n            except ErrorMeta as error_meta:\n                error_metas.append(error_meta)\n            # Raising any exception besides `ErrorMeta` while comparing is unexpected and will give some extra information\n            # about what happened. If applicable, the exception should be expected in the future.\n            except Exception as error:\n                raise RuntimeError(\n                    f\"Comparing\\n\\n\"\n                    f\"{pair}\\n\\n\"\n                    f\"resulted in the unexpected exception above. \"\n                    f\"If you are a user and see this message during normal operation \"\n                    \"please file an issue at https://github.com/pytorch/pytorch/issues. \"\n                    \"If you are a developer and working on the comparison functions, \"\n                    \"please except the previous error and raise an expressive `ErrorMeta` instead.\"\n                ) from error\n    \n        if not error_metas:\n            return\n    \n        # TODO: compose all metas into one AssertionError\n>       raise error_metas[0].to_error(msg)\nE       AssertionError: Tensor-likes are not close!\nE       \nE       Mismatched elements: 117 / 2500 (4.7%)\nE       Greatest absolute difference: 0.0009765625 at index (2, 46) (up to 1e-05 allowed)\nE       Greatest relative difference: 0.25 at index (22, 17) (up to 0.001 allowed)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1095: AssertionError"
            },
            "teardown": {
                "duration": 0.0001979059998120647,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_float32",
            "lineno": 139,
            "outcome": "failed",
            "setup": {
                "duration": 0.00035727200065593934,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.32280788400021265,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/addr_test.py",
                    "lineno": 145,
                    "message": "AssertionError: RuntimeError not raised"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 145,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_float_and_complex_xla_float32>, device = 'xla:1', dtype = torch.float32\n\n    @precisionOverride({torch.bfloat16: 1e-1})\n    @dtypes(*floating_and_complex_types_and(torch.half, torch.bfloat16))\n    def test_addr_float_and_complex(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'Boolean beta only supported for Boolean results.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=True, alpha=1)\nE           AssertionError: RuntimeError not raised\n\nsrc/pytorch_tests_reduced/addr_test.py:145: AssertionError"
            },
            "teardown": {
                "duration": 0.00019703999987541465,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_float_and_complex_xla_float64",
            "lineno": 139,
            "outcome": "failed",
            "setup": {
                "duration": 0.00034908500038000057,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03391814499991597,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                    "lineno": 1095,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 1 / 2500 (0.0%)\nGreatest absolute difference: 1.1347492545610294e-07 at index (48, 24) (up to 1e-07 allowed)\nGreatest relative difference: 1.1864522973285214e-06 at index (48, 24) (up to 1e-07 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 145,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 99,
                        "message": "in _test_addr_vs_numpy"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 78,
                        "message": "in check"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2219,
                        "message": "in assertEqual"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                        "lineno": 1095,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_float_and_complex_xla_float64>, device = 'xla:1', dtype = torch.float64\n\n    @precisionOverride({torch.bfloat16: 1e-1})\n    @dtypes(*floating_and_complex_types_and(torch.half, torch.bfloat16))\n    def test_addr_float_and_complex(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'Boolean beta only supported for Boolean results.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=True, alpha=1)\n\nsrc/pytorch_tests_reduced/addr_test.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/addr_test.py:99: in _test_addr_vs_numpy\n    check(m, zero_strided, b, beta, alpha)\nsrc/pytorch_tests_reduced/addr_test.py:78: in check\n    self.assertEqual(res, expected, exact_dtype=exact_dtype)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2219: in assertEqual\n    assert_equal(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n                pair.compare()\n            except ErrorMeta as error_meta:\n                error_metas.append(error_meta)\n            # Raising any exception besides `ErrorMeta` while comparing is unexpected and will give some extra information\n            # about what happened. If applicable, the exception should be expected in the future.\n            except Exception as error:\n                raise RuntimeError(\n                    f\"Comparing\\n\\n\"\n                    f\"{pair}\\n\\n\"\n                    f\"resulted in the unexpected exception above. \"\n                    f\"If you are a user and see this message during normal operation \"\n                    \"please file an issue at https://github.com/pytorch/pytorch/issues. \"\n                    \"If you are a developer and working on the comparison functions, \"\n                    \"please except the previous error and raise an expressive `ErrorMeta` instead.\"\n                ) from error\n    \n        if not error_metas:\n            return\n    \n        # TODO: compose all metas into one AssertionError\n>       raise error_metas[0].to_error(msg)\nE       AssertionError: Tensor-likes are not close!\nE       \nE       Mismatched elements: 1 / 2500 (0.0%)\nE       Greatest absolute difference: 1.1347492545610294e-07 at index (48, 24) (up to 1e-07 allowed)\nE       Greatest relative difference: 1.1864522973285214e-06 at index (48, 24) (up to 1e-07 allowed)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1095: AssertionError"
            },
            "teardown": {
                "duration": 0.000166198999977496,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_int16",
            "lineno": 119,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003255480005464051,
                "outcome": "passed"
            },
            "call": {
                "duration": 3.2337856049998663,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                    "lineno": 1095,
                    "message": "AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 124,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 90,
                        "message": "in _test_addr_vs_numpy"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 78,
                        "message": "in check"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2219,
                        "message": "in assertEqual"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                        "lineno": 1095,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_integral_xla_int16>, device = 'xla:1', dtype = torch.int16\n\n    @dtypes(*integral_types())\n    def test_addr_integral(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'argument beta must not be a floating point number.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=2., alpha=1)\n\nsrc/pytorch_tests_reduced/addr_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/addr_test.py:90: in _test_addr_vs_numpy\n    check(m, a, b, beta, alpha)\nsrc/pytorch_tests_reduced/addr_test.py:78: in check\n    self.assertEqual(res, expected, exact_dtype=exact_dtype)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2219: in assertEqual\n    assert_equal(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n                pair.compare()\n            except ErrorMeta as error_meta:\n                error_metas.append(error_meta)\n            # Raising any exception besides `ErrorMeta` while comparing is unexpected and will give some extra information\n            # about what happened. If applicable, the exception should be expected in the future.\n            except Exception as error:\n                raise RuntimeError(\n                    f\"Comparing\\n\\n\"\n                    f\"{pair}\\n\\n\"\n                    f\"resulted in the unexpected exception above. \"\n                    f\"If you are a user and see this message during normal operation \"\n                    \"please file an issue at https://github.com/pytorch/pytorch/issues. \"\n                    \"If you are a developer and working on the comparison functions, \"\n                    \"please except the previous error and raise an expressive `ErrorMeta` instead.\"\n                ) from error\n    \n        if not error_metas:\n            return\n    \n        # TODO: compose all metas into one AssertionError\n>       raise error_metas[0].to_error(msg)\nE       AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64.\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1095: AssertionError"
            },
            "teardown": {
                "duration": 0.00020226099968567723,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_int32",
            "lineno": 119,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003605800002333126,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0392905549997522,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                    "lineno": 1095,
                    "message": "AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 124,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 90,
                        "message": "in _test_addr_vs_numpy"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 78,
                        "message": "in check"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2219,
                        "message": "in assertEqual"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                        "lineno": 1095,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_integral_xla_int32>, device = 'xla:1', dtype = torch.int32\n\n    @dtypes(*integral_types())\n    def test_addr_integral(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'argument beta must not be a floating point number.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=2., alpha=1)\n\nsrc/pytorch_tests_reduced/addr_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/addr_test.py:90: in _test_addr_vs_numpy\n    check(m, a, b, beta, alpha)\nsrc/pytorch_tests_reduced/addr_test.py:78: in check\n    self.assertEqual(res, expected, exact_dtype=exact_dtype)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2219: in assertEqual\n    assert_equal(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n                pair.compare()\n            except ErrorMeta as error_meta:\n                error_metas.append(error_meta)\n            # Raising any exception besides `ErrorMeta` while comparing is unexpected and will give some extra information\n            # about what happened. If applicable, the exception should be expected in the future.\n            except Exception as error:\n                raise RuntimeError(\n                    f\"Comparing\\n\\n\"\n                    f\"{pair}\\n\\n\"\n                    f\"resulted in the unexpected exception above. \"\n                    f\"If you are a user and see this message during normal operation \"\n                    \"please file an issue at https://github.com/pytorch/pytorch/issues. \"\n                    \"If you are a developer and working on the comparison functions, \"\n                    \"please except the previous error and raise an expressive `ErrorMeta` instead.\"\n                ) from error\n    \n        if not error_metas:\n            return\n    \n        # TODO: compose all metas into one AssertionError\n>       raise error_metas[0].to_error(msg)\nE       AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64.\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1095: AssertionError"
            },
            "teardown": {
                "duration": 0.0001750800001900643,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_int64",
            "lineno": 119,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003248590001021512,
                "outcome": "passed"
            },
            "call": {
                "duration": 8.73899307099964,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                    "lineno": 1095,
                    "message": "AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 124,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 90,
                        "message": "in _test_addr_vs_numpy"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 78,
                        "message": "in check"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2219,
                        "message": "in assertEqual"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                        "lineno": 1095,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_integral_xla_int64>, device = 'xla:1', dtype = torch.int64\n\n    @dtypes(*integral_types())\n    def test_addr_integral(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'argument beta must not be a floating point number.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=2., alpha=1)\n\nsrc/pytorch_tests_reduced/addr_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/addr_test.py:90: in _test_addr_vs_numpy\n    check(m, a, b, beta, alpha)\nsrc/pytorch_tests_reduced/addr_test.py:78: in check\n    self.assertEqual(res, expected, exact_dtype=exact_dtype)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2219: in assertEqual\n    assert_equal(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n                pair.compare()\n            except ErrorMeta as error_meta:\n                error_metas.append(error_meta)\n            # Raising any exception besides `ErrorMeta` while comparing is unexpected and will give some extra information\n            # about what happened. If applicable, the exception should be expected in the future.\n            except Exception as error:\n                raise RuntimeError(\n                    f\"Comparing\\n\\n\"\n                    f\"{pair}\\n\\n\"\n                    f\"resulted in the unexpected exception above. \"\n                    f\"If you are a user and see this message during normal operation \"\n                    \"please file an issue at https://github.com/pytorch/pytorch/issues. \"\n                    \"If you are a developer and working on the comparison functions, \"\n                    \"please except the previous error and raise an expressive `ErrorMeta` instead.\"\n                ) from error\n    \n        if not error_metas:\n            return\n    \n        # TODO: compose all metas into one AssertionError\n>       raise error_metas[0].to_error(msg)\nE       AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64.\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1095: AssertionError"
            },
            "teardown": {
                "duration": 0.00021978499989927514,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_int8",
            "lineno": 119,
            "outcome": "failed",
            "setup": {
                "duration": 0.00036329000067780726,
                "outcome": "passed"
            },
            "call": {
                "duration": 3.388145779000297,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                    "lineno": 1095,
                    "message": "AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 124,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 90,
                        "message": "in _test_addr_vs_numpy"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 78,
                        "message": "in check"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2219,
                        "message": "in assertEqual"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                        "lineno": 1095,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_integral_xla_int8>, device = 'xla:1', dtype = torch.int8\n\n    @dtypes(*integral_types())\n    def test_addr_integral(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'argument beta must not be a floating point number.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=2., alpha=1)\n\nsrc/pytorch_tests_reduced/addr_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/addr_test.py:90: in _test_addr_vs_numpy\n    check(m, a, b, beta, alpha)\nsrc/pytorch_tests_reduced/addr_test.py:78: in check\n    self.assertEqual(res, expected, exact_dtype=exact_dtype)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2219: in assertEqual\n    assert_equal(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n                pair.compare()\n            except ErrorMeta as error_meta:\n                error_metas.append(error_meta)\n            # Raising any exception besides `ErrorMeta` while comparing is unexpected and will give some extra information\n            # about what happened. If applicable, the exception should be expected in the future.\n            except Exception as error:\n                raise RuntimeError(\n                    f\"Comparing\\n\\n\"\n                    f\"{pair}\\n\\n\"\n                    f\"resulted in the unexpected exception above. \"\n                    f\"If you are a user and see this message during normal operation \"\n                    \"please file an issue at https://github.com/pytorch/pytorch/issues. \"\n                    \"If you are a developer and working on the comparison functions, \"\n                    \"please except the previous error and raise an expressive `ErrorMeta` instead.\"\n                ) from error\n    \n        if not error_metas:\n            return\n    \n        # TODO: compose all metas into one AssertionError\n>       raise error_metas[0].to_error(msg)\nE       AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64.\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1095: AssertionError"
            },
            "teardown": {
                "duration": 0.00025302999983978225,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/addr_test.py::TestLinalgXLA::test_addr_integral_xla_uint8",
            "lineno": 119,
            "outcome": "failed",
            "setup": {
                "duration": 0.0004095290005352581,
                "outcome": "passed"
            },
            "call": {
                "duration": 3.37604050399932,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                    "lineno": 1095,
                    "message": "AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 124,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 90,
                        "message": "in _test_addr_vs_numpy"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/addr_test.py",
                        "lineno": 78,
                        "message": "in check"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2219,
                        "message": "in assertEqual"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py",
                        "lineno": 1095,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.addr_test.TestLinalgXLA testMethod=test_addr_integral_xla_uint8>, device = 'xla:1', dtype = torch.uint8\n\n    @dtypes(*integral_types())\n    def test_addr_integral(self, device, dtype):\n        with self.assertRaisesRegex(RuntimeError,\n                                    'argument beta must not be a floating point number.'):\n>           self._test_addr_vs_numpy(device, dtype, beta=2., alpha=1)\n\nsrc/pytorch_tests_reduced/addr_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/addr_test.py:90: in _test_addr_vs_numpy\n    check(m, a, b, beta, alpha)\nsrc/pytorch_tests_reduced/addr_test.py:78: in check\n    self.assertEqual(res, expected, exact_dtype=exact_dtype)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2219: in assertEqual\n    assert_equal(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n                pair.compare()\n            except ErrorMeta as error_meta:\n                error_metas.append(error_meta)\n            # Raising any exception besides `ErrorMeta` while comparing is unexpected and will give some extra information\n            # about what happened. If applicable, the exception should be expected in the future.\n            except Exception as error:\n                raise RuntimeError(\n                    f\"Comparing\\n\\n\"\n                    f\"{pair}\\n\\n\"\n                    f\"resulted in the unexpected exception above. \"\n                    f\"If you are a user and see this message during normal operation \"\n                    \"please file an issue at https://github.com/pytorch/pytorch/issues. \"\n                    \"If you are a developer and working on the comparison functions, \"\n                    \"please except the previous error and raise an expressive `ErrorMeta` instead.\"\n                ) from error\n    \n        if not error_metas:\n            return\n    \n        # TODO: compose all metas into one AssertionError\n>       raise error_metas[0].to_error(msg)\nE       AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64.\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1095: AssertionError"
            },
            "teardown": {
                "duration": 0.00034523100021033315,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestTorchCPU::test_apply_cpu",
            "lineno": 75,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004233049994581961,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0015262300003087148,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016103100006148452,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/apply_test.py::TestTorchXLA::test_apply_xla",
            "lineno": 75,
            "outcome": "failed",
            "setup": {
                "duration": 0.002484734999598004,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002712616999815509,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/apply_test.py",
                    "lineno": 78,
                    "message": "TypeError: apply_ is only implemented on CPU tensors"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/apply_test.py",
                        "lineno": 78,
                        "message": "TypeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.apply_test.TestTorchXLA testMethod=test_apply_xla>, device = 'xla:1'\n\n    def test_apply(self, device):\n        x = torch.arange(1, 6, device=device)\n>       res = x.clone().apply_(lambda k: k + k)\nE       TypeError: apply_ is only implemented on CPU tensors\n\nsrc/pytorch_tests_reduced/apply_test.py:78: TypeError"
            },
            "teardown": {
                "duration": 0.00030085699927440146,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestSortAndSelectCPU::test_sort_cpu",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.0006490679998023552,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.029922508000709058,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001958800003194483,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/argsort_test.py::TestSortAndSelectXLA::test_sort_xla",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.0018497820001357468,
                "outcome": "passed"
            },
            "call": {
                "duration": 11.516264341999886,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00024441900040983455,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_buffer_update_when_stats_are_not_tracked_cpu",
            "lineno": 322,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005042410002715769,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0020765500003108173,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001608259999557049,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_cudnn_half_cpu",
            "lineno": 204,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0004201680003461661,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0002834430006259936,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/batch_norm_test.py', 205, 'Skipped: CUDA unavailable')"
            },
            "teardown": {
                "duration": 0.0001910600003611762,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_cudnn_nhwc_cpu",
            "lineno": 157,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0005292119994919631,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00028354999994917307,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/batch_norm_test.py', 158, 'Skipped: CUDA unavailable')"
            },
            "teardown": {
                "duration": 0.00015263100067386404,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_nhwc_cpu_cpu",
            "lineno": 92,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003809870004261029,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.023006211999927473,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018964599985338282,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_nhwc_cuda_cpu",
            "lineno": 341,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003853429998343927,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007594720000270172,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/batch_norm_test.py', 342, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00015325399999710498,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_non_contig_cpu_cpu",
            "lineno": 136,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036356300006445963,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0018230300001960131,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014939599986973917,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_nonaffine_cuda_half_input_cpu",
            "lineno": 228,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003721980001500924,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007100749999153777,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/batch_norm_test.py', 229, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.0001537890002509812,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_bias_is_not_same_size_as_input_cpu",
            "lineno": 283,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003669830002763774,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.014192994999575603,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014381399978447007,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_less_than_one_value_per_channel_cpu",
            "lineno": 241,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002771839999695658,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007695280000916682,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011176299994986039,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_running_mean_is_not_same_size_as_input_cpu",
            "lineno": 248,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028030000066792127,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.011424653999711154,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011533300039445749,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_running_var_is_not_same_size_as_input_cpu",
            "lineno": 259,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002778649995889282,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.011535216000083892,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012890099969808944,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_running_var_or_running_mean_have_forward_grad_cpu",
            "lineno": 296,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033490599980723346,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.000629865000519203,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011183700007677544,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNCPU::test_batchnorm_raises_error_if_weight_is_not_same_size_as_input_cpu",
            "lineno": 270,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002752109994617058,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.011220162999961758,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00023906600017653545,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_buffer_update_when_stats_are_not_tracked_xla",
            "lineno": 322,
            "outcome": "passed",
            "setup": {
                "duration": 0.0017971540000871755,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.093767912999283,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017461900006310316,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_cudnn_half_xla",
            "lineno": 204,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00040892400011216523,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0002329260005353717,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/batch_norm_test.py', 205, 'Skipped: CUDA unavailable')"
            },
            "teardown": {
                "duration": 0.0001219870000568335,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_cudnn_nhwc_xla",
            "lineno": 157,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002834249999068561,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00020118400061619468,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/batch_norm_test.py', 158, 'Skipped: CUDA unavailable')"
            },
            "teardown": {
                "duration": 0.00011948500014113961,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_nhwc_cpu_xla",
            "lineno": 92,
            "outcome": "passed",
            "setup": {
                "duration": 0.00047105800058488967,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02089185600016208,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015218099997582613,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_nhwc_cuda_xla",
            "lineno": 341,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036435800029721577,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.770592249999936,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00030847299967717845,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_non_contig_cpu_xla",
            "lineno": 136,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005002500001864973,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0024184290004996,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016511000012542354,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_nonaffine_cuda_half_input_xla",
            "lineno": 228,
            "outcome": "passed",
            "setup": {
                "duration": 0.00038389600013033487,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01735890300005849,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001427649995093816,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_bias_is_not_same_size_as_input_xla",
            "lineno": 283,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034670600052777445,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.012199233000501408,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022322500080917962,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_less_than_one_value_per_channel_xla",
            "lineno": 241,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028065199967386434,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009138510004049749,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011325500054226723,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_running_mean_is_not_same_size_as_input_xla",
            "lineno": 248,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002864680000129738,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.011336689000017941,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011744899984478252,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_running_var_is_not_same_size_as_input_xla",
            "lineno": 259,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027722799950424815,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.011469373999716481,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001317409996772767,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_running_var_or_running_mean_have_forward_grad_xla",
            "lineno": 296,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033059800080081914,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001781294000466005,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011269000060565304,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/batch_norm_test.py::TestNNXLA::test_batchnorm_raises_error_if_weight_is_not_same_size_as_input_xla",
            "lineno": 270,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027630000022327295,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.011547436000000744,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002404670003670617,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_broadcasts_pos_weights_cpu",
            "lineno": 127,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036354900021251524,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002137421000043105,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011789099971792893,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_broadcasts_weights_cpu",
            "lineno": 94,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003145810005662497,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0020689959992523654,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011675899986585137,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_gives_same_result_as_sigmoid_and_bce_loss_large_tensors_with_grad_cpu",
            "lineno": 51,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002756809999482357,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06784989099924132,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022042999989935197,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_has_correct_grad_at_zero_cpu",
            "lineno": 86,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004696569994848687,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0017475909999120631,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018625299981067656,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_ones_in_pos_weights_are_the_same_as_none_cpu",
            "lineno": 118,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005170140002519474,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0019545210006981506,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017983799989451654,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_stability_cpu",
            "lineno": 158,
            "outcome": "passed",
            "setup": {
                "duration": 0.00040267199983645696,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0018266520000906894,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017956200008484302,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossCPU::test_bce_with_logits_with_pos_weight_has_correct_grad_at_zero_cpu",
            "lineno": 146,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003891099995598779,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0016915919995881268,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003086619999521645,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_broadcasts_pos_weights_xla",
            "lineno": 127,
            "outcome": "passed",
            "setup": {
                "duration": 0.0020005490005132742,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.1619536620000872,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001813099997889367,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_broadcasts_weights_xla",
            "lineno": 94,
            "outcome": "passed",
            "setup": {
                "duration": 0.00041300500015495345,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.15854607799974474,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002679489998627105,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_gives_same_result_as_sigmoid_and_bce_loss_large_tensors_with_grad_xla",
            "lineno": 51,
            "outcome": "failed",
            "setup": {
                "duration": 0.00045996300013939617,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.7900686329994642,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/bcewithlogitsloss_test.py",
                    "lineno": 75,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 64450 / 262144 (24.6%)\nGreatest absolute difference: 7.11679458618164e-05 at index (598, 65) (up to 1e-05 allowed)\nGreatest relative difference: 0.00011570849892450497 at index (418, 63) (up to 1.3e-06 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py",
                        "lineno": 75,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.bcewithlogitsloss_test.TestNLLLossXLA testMethod=test_bce_with_logits_gives_same_result_as_sigmoid_and_bce_loss_large_tensors_with_grad_xla>\ndevice = 'xla:1'\n\n    def test_bce_with_logits_gives_same_result_as_sigmoid_and_bce_loss_large_tensors_with_grad(self, device):\n        x_size = 1024\n        y_size = 256\n        target = torch.rand(x_size, y_size, device=device)\n    \n        for reduction in ['none', 'mean', 'sum']:\n            output_sig = torch.rand(x_size, y_size, device=device) - 0.5\n            output_logits = output_sig.clone().detach()\n    \n            output_sig.requires_grad = True\n            output_logits.requires_grad = True\n            weight = torch.rand(y_size, device=device)\n    \n            loss_sig = nn.BCELoss(weight, reduction=reduction)(\n                torch.sigmoid(output_sig), target\n            )\n            with pytorch_op_timer():\n                loss_logits = nn.BCEWithLogitsLoss(weight, reduction=reduction)(\n                    output_logits, target\n                )\n    \n            # print(loss_logits, loss_sig)\n    \n>           self.assertEqual(loss_logits, loss_sig)\nE           AssertionError: Tensor-likes are not close!\nE           \nE           Mismatched elements: 64450 / 262144 (24.6%)\nE           Greatest absolute difference: 7.11679458618164e-05 at index (598, 65) (up to 1e-05 allowed)\nE           Greatest relative difference: 0.00011570849892450497 at index (418, 63) (up to 1.3e-06 allowed)\n\nsrc/pytorch_tests_reduced/bcewithlogitsloss_test.py:75: AssertionError"
            },
            "teardown": {
                "duration": 0.00020158500046818517,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_has_correct_grad_at_zero_xla",
            "lineno": 86,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003629929997259751,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.14375771499999246,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019057499957852997,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_ones_in_pos_weights_are_the_same_as_none_xla",
            "lineno": 118,
            "outcome": "passed",
            "setup": {
                "duration": 0.00043614099922706373,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.11726774099952308,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016467400018882472,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_stability_xla",
            "lineno": 158,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004017219998786459,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.08771891000014875,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015501800044148695,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bcewithlogitsloss_test.py::TestNLLLossXLA::test_bce_with_logits_with_pos_weight_has_correct_grad_at_zero_xla",
            "lineno": 146,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036633299987443024,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.021539047000260325,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00024034699981712038,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestNamedTensorCPU::test_bitwise_not_cpu",
            "lineno": 22,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004008109999631415,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.000933637999878556,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013397400016401662,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/bitwise_not_test.py::TestNamedTensorXLA::test_bitwise_not_xla",
            "lineno": 22,
            "outcome": "passed",
            "setup": {
                "duration": 0.0021385640002336004,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.049909141000171076,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000170363000506768,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsCPU::test_broadcast_shapes_cpu",
            "lineno": 41,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004018559993710369,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.013665793000654958,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012831399999413406,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsCPU::test_broadcast_tensors_cpu_float32",
            "lineno": 27,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033574300050531747,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006995820003794506,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001650989997870056,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsXLA::test_broadcast_shapes_xla",
            "lineno": 41,
            "outcome": "passed",
            "setup": {
                "duration": 0.0018122269993909867,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.18505708599968784,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016950900044321315,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/broadcast_tensors_test.py::TestOldViewOpsXLA::test_broadcast_tensors_xla_float32",
            "lineno": 27,
            "outcome": "passed",
            "setup": {
                "duration": 0.0006043700004738639,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.08472227599941107,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00036685400027636206,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat2_cpu_float16",
            "lineno": 289,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004121909996683826,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.006176951000270492,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000149593000060122,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat2_cpu_float64",
            "lineno": 289,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027605499963101465,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.004678987000261259,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014743799965799553,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat2_cpu_int32",
            "lineno": 289,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003298310002719518,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.004278964000150154,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011388500024622772,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_all_dtypes_and_devices_cpu",
            "lineno": 28,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002691889994821395,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.006804708000345272,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011653099954855861,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_big_cpu",
            "lineno": 275,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00028633799956878647,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007412989998556441,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py', 276, 'Skipped: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test')"
            },
            "teardown": {
                "duration": 0.00011812499997176928,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_cpu",
            "lineno": 250,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002845660001185024,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005355819994292688,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py', 251, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00012188900018372806,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_empty_cpu",
            "lineno": 60,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002636139997775899,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0017986249995374237,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012079299995093606,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_empty_legacy_cpu",
            "lineno": 44,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003131929997834959,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001780865000000631,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011260500014032004,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_in_channels_last_cpu",
            "lineno": 123,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002690189994609682,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.4037280840002495,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00023710499954177067,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_mem_overlap_cpu",
            "lineno": 21,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004969829997207853,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.009211764000610856,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015986899961717427,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_out_channels_last_cpu",
            "lineno": 113,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039331700008915504,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001983426000151667,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018428400017000968,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_out_cpu",
            "lineno": 74,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003607500002544839,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0028914609993080376,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001326989995504846,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_out_memory_format_cpu",
            "lineno": 174,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003327750000607921,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005728170008296729,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py', 175, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00011971000003541121,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_preserve_channels_last_cpu",
            "lineno": 151,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002781469993351493,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0016123570003401255,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013705400033359183,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationCPU::test_cat_stack_cross_devices_cpu",
            "lineno": 235,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00031128499995247694,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0008003650000318885,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py', 236, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.0003300710004623397,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat2_xla_float16",
            "lineno": 289,
            "outcome": "skipped",
            "setup": {
                "duration": 0.002593942000203242,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006027339995853254,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py', 290, 'Skipped: Only runs on cpu')"
            },
            "teardown": {
                "duration": 0.00016187700020964257,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat2_xla_float64",
            "lineno": 289,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00029591299971798435,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005252840001048753,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py', 290, 'Skipped: Only runs on cpu')"
            },
            "teardown": {
                "duration": 0.0001258729998880881,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat2_xla_int32",
            "lineno": 289,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00027545499960979214,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005438959997263737,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py', 290, 'Skipped: Only runs on cpu')"
            },
            "teardown": {
                "duration": 0.00011527799961186247,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_all_dtypes_and_devices_xla",
            "lineno": 28,
            "outcome": "failed",
            "setup": {
                "duration": 0.00028522499997052364,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.816967828000088,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py",
                    "lineno": 37,
                    "message": "RuntimeError: Comparing\n\nTensorOrArrayPair(\n    id=(),\n    actual=tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j]], device='xla:1'),\n    expected=tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j]], device='xla:1'),\n    rtol=1.3e-06,\n    atol=1e-05,\n    equal_nan=True,\n    check_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\nresulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/cat_test.py",
                        "lineno": 37,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "actual = tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j]], device='xla:1')\nexpected = tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j]], device='xla:1')\npair_types = (<class 'torch.testing._comparison.NonePair'>, <class 'torch.testing._internal.common_utils.RelaxedBooleanPair'>, <cla...<class 'torch.testing._internal.common_utils.StringPair'>, <class 'torch.testing._internal.common_utils.SetPair'>, ...)\nsequence_types = (<class 'collections.abc.Sequence'>, <class 'torch.storage._TypedStorage'>, <class 'torch.nn.modules.container.Sequent...nn.modules.container.ModuleList'>, <class 'torch.nn.modules.container.ParameterList'>, <class 'torch.ScriptList'>, ...)\nmapping_types = (<class 'collections.abc.Mapping'>, <class 'torch.nn.modules.container.ModuleDict'>, <class 'torch.nn.modules.container.ParameterDict'>, <class 'torch.ScriptDict'>)\nmsg = None, options = {'atol': None, 'atol_override': 0, 'check_device': False, 'check_dtype': True, ...}, __tracebackhide__ = True\npairs = [TensorOrArrayPair(\n    id=(),\n    actual=tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j]...ck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)]\n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n>               pair.compare()\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1075: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\n    def compare(self) -> None:\n        actual, expected = self.actual, self.expected\n    \n        self._compare_attributes(actual, expected)\n        if any(input.device.type == \"meta\" for input in (actual, expected)):\n            return\n    \n        actual, expected = self._equalize_attributes(actual, expected)\n>       self._compare_values(actual, expected)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:620: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j]], device='xla:1')\nexpected = tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j]], device='xla:1')\n\n    def _compare_values(self, actual: torch.Tensor, expected: torch.Tensor) -> None:\n        if actual.is_quantized:\n            compare_fn = self._compare_quantized_values\n        elif actual.is_sparse:\n            compare_fn = self._compare_sparse_coo_values\n        elif actual.layout in {torch.sparse_csr, torch.sparse_csc, torch.sparse_bsr, torch.sparse_bsc}:\n            compare_fn = self._compare_sparse_compressed_values\n        else:\n            compare_fn = self._compare_regular_values_close\n    \n>       compare_fn(actual, expected, rtol=self.rtol, atol=self.atol, equal_nan=self.equal_nan)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:714: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j]], device='xla:1', dtype=torch.complex128)\nexpected = tensor([[1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j],\n        [1.+0.j, 2.+0.j],\n        [3.+0.j, 4.+0.j]], device='xla:1', dtype=torch.complex128)\n\n    def _compare_regular_values_close(\n        self,\n        actual: torch.Tensor,\n        expected: torch.Tensor,\n        *,\n        rtol: float,\n        atol: float,\n        equal_nan: bool,\n        identifier: Optional[Union[str, Callable[[str], str]]] = None,\n    ) -> None:\n        \"\"\"Checks if the values of two tensors are close up to a desired tolerance.\"\"\"\n        actual, expected = self._promote_for_comparison(actual, expected)\n        matches = torch.isclose(actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan)\n>       if torch.all(matches):\nE       RuntimeError: Error while lowering: [] aten::isnan\nE       XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE       Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:847: RuntimeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <src.pytorch_tests_reduced.cat_test.TestTensorCreationXLA testMethod=test_cat_all_dtypes_and_devices_xla>, device = 'xla:1'\n\n    def test_cat_all_dtypes_and_devices(self, device):\n        for dt in all_types_and_complex_and(torch.half, torch.bool, torch.bfloat16, torch.chalf):\n            x = torch.tensor([[1, 2], [3, 4]], dtype=dt, device=device)\n    \n            expected1 = torch.tensor(\n                [[1, 2], [3, 4], [1, 2], [3, 4]], dtype=dt, device=device)\n            with pytorch_op_timer():\n                test_1 = torch.cat((x, x), 0)\n>           self.assertEqual(test_1, expected1)\nE           RuntimeError: Comparing\nE           \nE           TensorOrArrayPair(\nE               id=(),\nE               actual=tensor([[1.+0.j, 2.+0.j],\nE                   [3.+0.j, 4.+0.j],\nE                   [1.+0.j, 2.+0.j],\nE                   [3.+0.j, 4.+0.j]], device='xla:1'),\nE               expected=tensor([[1.+0.j, 2.+0.j],\nE                   [3.+0.j, 4.+0.j],\nE                   [1.+0.j, 2.+0.j],\nE                   [3.+0.j, 4.+0.j]], device='xla:1'),\nE               rtol=1.3e-06,\nE               atol=1e-05,\nE               equal_nan=True,\nE               check_device=False,\nE               check_dtype=True,\nE               check_layout=False,\nE               check_stride=False,\nE               check_is_coalesced=False,\nE           )\nE           \nE           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.\n\nsrc/pytorch_tests_reduced/cat_test.py:37: RuntimeError"
            },
            "teardown": {
                "duration": 0.00021335499968699878,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_big_xla",
            "lineno": 275,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003714889999173465,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007476580003640265,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py', 276, 'Skipped: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test')"
            },
            "teardown": {
                "duration": 0.00012760200024786172,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_empty_legacy_xla",
            "lineno": 44,
            "outcome": "failed",
            "setup": {
                "duration": 0.000312588999804575,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.004293491999305843,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/cat_test.py",
                        "lineno": 53,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.cat_test.TestTensorCreationXLA testMethod=test_cat_empty_legacy_xla>, device = 'xla:1'\n\n    def test_cat_empty_legacy(self, device):\n        # FIXME: this is legacy behavior and should be removed\n        # when we support empty tensors with arbitrary sizes\n        dtype = torch.float32\n    \n        x = torch.randn((4, 3, 32, 32), dtype=dtype, device=device)\n        empty = torch.randn((0,), dtype=dtype, device=device)\n        with pytorch_op_timer():\n>           res1 = torch.cat([x, empty], dim=1)\n\nsrc/pytorch_tests_reduced/cat_test.py:53: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00013369299995247275,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_empty_xla",
            "lineno": 60,
            "outcome": "failed",
            "setup": {
                "duration": 0.00029700899995077634,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0020549869996102643,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/cat_test.py",
                        "lineno": 67,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.cat_test.TestTensorCreationXLA testMethod=test_cat_empty_xla>, device = 'xla:1'\n\n    def test_cat_empty(self, device):\n        dtype = torch.float32\n    \n        x = torch.randn((4, 3, 32, 32), dtype=dtype, device=device)\n        empty = torch.randn((4, 0, 32, 32), dtype=dtype, device=device)\n        with pytorch_op_timer():\n>           res1 = torch.cat([x, empty], dim=1)\n\nsrc/pytorch_tests_reduced/cat_test.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00014867699974274728,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_in_channels_last_xla",
            "lineno": 123,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003671710001071915,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0020597270004145685,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/cat_test.py",
                        "lineno": 130,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.cat_test.TestTensorCreationXLA testMethod=test_cat_in_channels_last_xla>, device = 'xla:1'\n\n    @onlyNativeDeviceTypes\n    def test_cat_in_channels_last(self, device):\n        for dim in range(4):\n            x = torch.randn((4, 15, 8, 8), device=device)\n            y = torch.randn(x.shape, device=device)\n            with pytorch_op_timer():\n>               res1 = torch.cat((x, y), dim=dim)\n\nsrc/pytorch_tests_reduced/cat_test.py:130: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.0001312869999310351,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_mem_overlap_xla",
            "lineno": 21,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002818729999489733,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002496127999620512,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012849999984609894,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_out_channels_last_xla",
            "lineno": 113,
            "outcome": "failed",
            "setup": {
                "duration": 0.00032095999995362945,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0013491949994204333,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/cat_test.py",
                        "lineno": 118,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.cat_test.TestTensorCreationXLA testMethod=test_cat_out_channels_last_xla>, device = 'xla:1'\n\n    def test_cat_out_channels_last(self, device):\n        x = torch.randn((4, 3, 8, 8))\n        y = torch.randn(x.shape)\n        with pytorch_op_timer():\n>           res1 = torch.cat((x, y))\n\nsrc/pytorch_tests_reduced/cat_test.py:118: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00013347000003705034,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_out_memory_format_xla",
            "lineno": 174,
            "outcome": "failed",
            "setup": {
                "duration": 0.00028544999986479525,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0026159380004173727,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/cat_test.py",
                        "lineno": 195,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.cat_test.TestTensorCreationXLA testMethod=test_cat_out_memory_format_xla>, device = 'xla:1'\n\n    @onlyAcceleratedDeviceTypes\n    def test_cat_out_memory_format(self, device):\n        inp_size = (4, 4, 4, 4)\n        expected_size = (8, 4, 4, 4)\n        a_cuda = torch.randn(inp_size, device=device).contiguous(\n            memory_format=torch.channels_last)\n        a_cpu = torch.randn(inp_size, device='cpu').contiguous(\n            memory_format=torch.channels_last)\n        b_cuda = torch.randn(inp_size, device=device).contiguous(\n            memory_format=torch.contiguous_format)\n        b_cpu = torch.randn(inp_size, device='cpu').contiguous(\n            memory_format=torch.contiguous_format)\n        c_cuda = torch.randn(inp_size, device=device).contiguous(\n            memory_format=torch.channels_last)\n    \n        # Case 1: if out= is the correct shape then the memory format of out= is respected\n    \n        out_cuda = torch.empty(expected_size, device=device).contiguous(\n            memory_format=torch.contiguous_format)\n        with pytorch_op_timer():\n>           res1_cuda = torch.cat((a_cuda, b_cuda), out=out_cuda)\n\nsrc/pytorch_tests_reduced/cat_test.py:195: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00018312200063519413,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_out_xla",
            "lineno": 74,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003477609998299158,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.47597842999948625,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019204599993827287,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_preserve_channels_last_xla",
            "lineno": 151,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039122599991969764,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.2267168580001453,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020603999928425765,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_stack_cross_devices_xla",
            "lineno": 235,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003970990001107566,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.013272297000185063,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001188790001833695,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cat_test.py::TestTensorCreationXLA::test_cat_xla",
            "lineno": 250,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003157860001010704,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.1176396049995674,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00042260099962732056,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_add_dataset_cpu",
            "lineno": 158,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005033589995946386,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0018315369998163078,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011680700026772683,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_concat_raises_index_error_cpu",
            "lineno": 150,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003275010003562784,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007703139999648556,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012934099959238665,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_concat_two_non_singletons_cpu",
            "lineno": 132,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003090600002906285,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007780450005157036,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011193800037290202,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_concat_two_non_singletons_with_empty_cpu",
            "lineno": 140,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002651329996297136,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007689459998800885,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001180139997813967,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_concat_two_singletons_cpu",
            "lineno": 125,
            "outcome": "passed",
            "setup": {
                "duration": 0.00029086400081723696,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006993110000621527,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011681700016197283,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetCPU::test_iterable_dataset_err_cpu",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026443700062372955,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0008180459999493905,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00021517599998333026,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_add_dataset_xla",
            "lineno": 158,
            "outcome": "passed",
            "setup": {
                "duration": 0.001606677000381751,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.003271632000178215,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011324899969622493,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_concat_raises_index_error_xla",
            "lineno": 150,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002917199999501463,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007253889998537488,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011240000003454043,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_concat_two_non_singletons_with_empty_xla",
            "lineno": 140,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002743759996519657,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007814840000719414,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011808399995061336,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_concat_two_non_singletons_xla",
            "lineno": 132,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027995700020255754,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007136909998735064,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011169800018251408,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_concat_two_singletons_xla",
            "lineno": 125,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027577899982134113,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007018030000836006,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014932900012354366,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/concatdataset_test.py::TestConcatDatasetXLA::test_iterable_dataset_err_xla",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.00031714899978396716,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0024521690002075047,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017754599957697792,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_backward_depthwise_cpu_complex128",
            "lineno": 499,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00035619600021163933,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.000598505999732879,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 500, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.0001191180008390802,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_backward_depthwise_cpu_float64",
            "lineno": 499,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00026602799971442437,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005370720000428264,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 500, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00012488599986681947,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_depthwise_naive_groups_cpu_float16",
            "lineno": 391,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002687070000320091,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005910119998588925,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 392, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00014605700016545597,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_depthwise_naive_groups_cpu_float32",
            "lineno": 391,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003139379996355274,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005878579995624023,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 392, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00013512000077753328,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_depthwise_naive_groups_cpu_float64",
            "lineno": 391,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00030380500083992956,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006051619993741042,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 392, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00014483199993264861,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_deterministic_cudnn_cpu_float16",
            "lineno": 296,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002782419996947283,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007069370003591757,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 297, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00011754500064853346,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_deterministic_cudnn_cpu_float32",
            "lineno": 296,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002757129996098229,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.000536628999725508,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 297, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00011720600014086813,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_deterministic_cudnn_cpu_float64",
            "lineno": 296,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002844889995685662,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005277669997667545,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 297, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00011678900045808405,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_large_workspace_cpu_float16",
            "lineno": 319,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00026449599954503356,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005352309999580029,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 320, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00011634300062723923,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_large_workspace_cpu_float32",
            "lineno": 319,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002617680002003908,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005286830000841292,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 320, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00011917700066987891,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_large_workspace_cpu_float64",
            "lineno": 319,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003075819995501661,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006210000001374283,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 320, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00013339899942366173,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_naive_groups_cpu_float32",
            "lineno": 460,
            "outcome": "passed",
            "setup": {
                "duration": 0.00031596600001648767,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.033158303999698546,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017387099978805054,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeCPU::test_Conv2d_size_1_kernel_cpu",
            "lineno": 439,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00035516899970389204,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009736849997352692,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 440, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.0003448920006121625,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_backward_depthwise_xla_complex128",
            "lineno": 499,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0018820289997165673,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0011424519998399774,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 500, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on xla\")"
            },
            "teardown": {
                "duration": 0.00016389699976571137,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_backward_depthwise_xla_float64",
            "lineno": 499,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003635990005932399,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009432339993509231,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 500, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on xla\")"
            },
            "teardown": {
                "duration": 0.00017186199966090498,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_depthwise_naive_groups_xla_float16",
            "lineno": 391,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003706840006998391,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0010057609997602412,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 392, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on xla\")"
            },
            "teardown": {
                "duration": 0.00016348300050594844,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_depthwise_naive_groups_xla_float32",
            "lineno": 391,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003897500000675791,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007236580004246207,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 392, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on xla\")"
            },
            "teardown": {
                "duration": 0.0001482659999965108,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_depthwise_naive_groups_xla_float64",
            "lineno": 391,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00036855599955742946,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007018149999566958,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 392, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on xla\")"
            },
            "teardown": {
                "duration": 0.00013893699997424847,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_deterministic_cudnn_xla_float16",
            "lineno": 296,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00037999300002411474,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006164599999465281,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 297, 'Skipped: cuDNN not available')"
            },
            "teardown": {
                "duration": 0.00012376700033200905,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_deterministic_cudnn_xla_float32",
            "lineno": 296,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0002867149996745866,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007597490002808627,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 297, 'Skipped: cuDNN not available')"
            },
            "teardown": {
                "duration": 0.00013076199957140489,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_deterministic_cudnn_xla_float64",
            "lineno": 296,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00028679099978035083,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006545870000991272,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 297, 'Skipped: cuDNN not available')"
            },
            "teardown": {
                "duration": 0.0001349100002698833,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_large_workspace_xla_float16",
            "lineno": 319,
            "outcome": "passed",
            "setup": {
                "duration": 0.00030941699969844194,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.07044734800001606,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017922200004250044,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_large_workspace_xla_float32",
            "lineno": 319,
            "outcome": "passed",
            "setup": {
                "duration": 0.00046045700037211645,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.05142483999952674,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014746899978490546,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_large_workspace_xla_float64",
            "lineno": 319,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036825999995926395,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02088207499946293,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001569400001244503,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_naive_groups_xla_float32",
            "lineno": 460,
            "outcome": "passed",
            "setup": {
                "duration": 0.00040739700034464477,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.9473693139998431,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003146310000374797,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNDeviceTypeXLA::test_Conv2d_size_1_kernel_xla",
            "lineno": 439,
            "outcome": "passed",
            "setup": {
                "duration": 0.00042357100028311834,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.3723814759996458,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00043563300005189376,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_1x1_cpu",
            "lineno": 110,
            "outcome": "passed",
            "setup": {
                "duration": 0.00044283400075073587,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.008223499999985506,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017235599989362527,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_OneDNN_cpu",
            "lineno": 121,
            "outcome": "passed",
            "setup": {
                "duration": 0.00044960899958823575,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.045805306999682216,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018678400010685436,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_backward_twice_cpu",
            "lineno": 176,
            "outcome": "passed",
            "setup": {
                "duration": 0.00045472600049834,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.014954897000279743,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001651860002311878,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_groups_nobias_cpu",
            "lineno": 189,
            "outcome": "passed",
            "setup": {
                "duration": 0.00037418000010802643,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.025326185000267287,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001959549999810406,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_groups_nobias_v2_cpu",
            "lineno": 232,
            "outcome": "passed",
            "setup": {
                "duration": 0.00038107100044726394,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02270667999982834,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000279939999927592,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_inconsistent_types_cpu",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.00037297099970601266,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0031688139997640974,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000182327000402438,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_inconsistent_types_on_GPU_with_cudnn_cpu",
            "lineno": 157,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0005282310003167368,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006404929999916931,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 158, 'Skipped: CUDNN not available')"
            },
            "teardown": {
                "duration": 0.00018165099936595652,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_inconsistent_types_on_GPU_without_cudnn_cpu",
            "lineno": 94,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0006650670002272818,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0010716060005506733,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 95, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00018529899989516707,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_missing_argument_cpu",
            "lineno": 172,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005139659997439594,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0019202700004825601,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018497199926059693,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNCPU::test_Conv2d_module_same_padding_cpu",
            "lineno": 46,
            "outcome": "passed",
            "setup": {
                "duration": 0.00041403000068385154,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.013034774000516336,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003201020008418709,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_1x1_xla",
            "lineno": 110,
            "outcome": "failed",
            "setup": {
                "duration": 0.0018162599999413942,
                "outcome": "passed"
            },
            "call": {
                "duration": 22.290309050999895,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                    "lineno": 1280,
                    "message": "torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor(0., device='xla:1', dtype=torch.float64)\nanalytical:tensor(-0.5171, device='xla:1', dtype=torch.float64)\n\nThe above quantities relating the numerical and analytical jacobians are computed \nin fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nabout fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\n\nNumerical:\n tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000, -1.3046,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.1841,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n       device='xla:1', dtype=torch.float64)\nAnalytical:\ntensor([[-0.6680,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000, -0.6680,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000, -0.6680,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.1885,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.1885,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.1885]],\n       device='xla:1', dtype=torch.float64)\n\nThe max per-element difference (slow mode) is: 0.66796875."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/conv2d_test.py",
                        "lineno": 120,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 3019,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1414,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1428,
                        "message": "in _gradcheck_helper"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1075,
                        "message": "in _gradcheck_real_imag"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1307,
                        "message": "in _fast_gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1280,
                        "message": "GradcheckError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.conv2d_test.TestConvolutionNNXLA testMethod=test_Conv2d_1x1_xla>, device = 'xla:1'\n\n    def test_Conv2d_1x1(self, device):\n        in_channels = 2\n        out_channels = 2\n    \n        with pytorch_op_timer():\n            mod = torch.nn.Conv2d(2, 2, 1, bias=False).to(dtype=torch.double).to(device)\n        input = torch.randn(1, in_channels, 5, 5, requires_grad=True, dtype=torch.double, device=device)\n        for enabled in (False, True):\n            with torch.backends.mkldnn.flags(enabled=enabled):\n>               gradcheck(F.conv2d, (input, mod.weight))\n\nsrc/pytorch_tests_reduced/conv2d_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:3019: in gradcheck\n    return torch.autograd.gradcheck(fn, inputs, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1414: in gradcheck\n    return _gradcheck_helper(**args)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1428: in _gradcheck_helper\n    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1075: in _gradcheck_real_imag\n    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1307: in _fast_gradcheck\n    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nall_analytical = [[tensor(-0.5171, device='xla:1', dtype=torch.float64), tensor(-0.5659, device='xla:1', dtype=torch.float64)]]\nall_numerical = [[tensor(0., device='xla:1', dtype=torch.float64)], [tensor(0., device='xla:1', dtype=torch.float64)]], complex_indices = None\ntupled_inputs = (tensor([[[[-0.8978, -0.8774, -1.8107, -0.7155,  0.3947],\n          [-0.8679,  0.6493, -0.6601, -0.8287, -1.8193],\n   ...7]]],\n\n\n        [[[-0.3396]],\n\n         [[-0.1886]]]], device='xla:1', dtype=torch.float64,\n       requires_grad=True))\noutputs = (tensor([[[[ 0.5628,  0.6013,  1.2505,  0.3518, -0.1129],\n          [ 0.8631, -0.4556,  0.5336,  0.6092,  1.1325],\n   ..., -0.3273, -0.0811, -0.1147,  0.6365]]]], device='xla:1',\n       dtype=torch.float64, grad_fn=<ConvolutionBackward0>),)\nfunc = <built-in method conv2d of type object at 0x7fd01c25f980>\nall_v = [tensor([0.0636, 0.1637, 0.2115, 0.0509, 0.1360, 0.0595, 0.0553, 0.0326, 0.1496,\n        0.0223, 0.1118, 0.2346, 0.220..., 0.2113, 0.1651, 0.1660,\n        0.0138, 0.1721, 0.0786, 0.1260, 0.0296], device='xla:1',\n       dtype=torch.float64)]\nall_u = [tensor([0.0679, 0.2215, 0.0851, 0.1023, 0.1998, 0.1162, 0.0183, 0.2466, 0.1814,\n        0.1085, 0.0215, 0.1245, 0.042...ce='xla:1',\n       dtype=torch.float64), tensor([0.0700, 0.7148, 0.3396, 0.6073], device='xla:1', dtype=torch.float64)]\nrtol = 0.001, atol = 1e-05, test_imag = False\n\n    def _check_analytical_numerical_equal(all_analytical, all_numerical, complex_indices, tupled_inputs, outputs,\n                                          func, all_v, all_u, rtol, atol, test_imag, *, is_forward_ad=False):\n        for i, all_numerical_for_input_i in enumerate(all_numerical):\n            for j, n in enumerate(all_numerical_for_input_i):\n                # Forward AD generates the transpose of what this function expects\n                if is_forward_ad:\n                    a = all_analytical[i][j]\n                else:\n                    a = all_analytical[j][i]\n                n = n.to(device=a.device)\n                updated_atol = _adjusted_atol(atol, all_u[i], all_v[j] if all_v else None)\n                if not _allclose_with_type_promotion(a, n.to(a.device), rtol, updated_atol):\n                    jacobians_str = _run_slow_mode_and_get_error(func, tupled_inputs, outputs, i, j, rtol, atol, is_forward_ad)\n>                   raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)\nE                   torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nE                   numerical:tensor(0., device='xla:1', dtype=torch.float64)\nE                   analytical:tensor(-0.5171, device='xla:1', dtype=torch.float64)\nE                   \nE                   The above quantities relating the numerical and analytical jacobians are computed \nE                   in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nE                   about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\nE                   \nE                   Numerical:\nE                    tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\nE                           [ 0.0000, -1.3046,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\nE                           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\nE                           ...,\nE                           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\nE                           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.1841,  0.0000],\nE                           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\nE                          device='xla:1', dtype=torch.float64)\nE                   Analytical:\nE                   tensor([[-0.6680,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\nE                           [ 0.0000, -0.6680,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\nE                           [ 0.0000,  0.0000, -0.6680,  ...,  0.0000,  0.0000,  0.0000],\nE                           ...,\nE                           [ 0.0000,  0.0000,  0.0000,  ..., -0.1885,  0.0000,  0.0000],\nE                           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.1885,  0.0000],\nE                           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.1885]],\nE                          device='xla:1', dtype=torch.float64)\nE                   \nE                   The max per-element difference (slow mode) is: 0.66796875.\n\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1280: GradcheckError"
            },
            "teardown": {
                "duration": 0.00024441700043098535,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_OneDNN_xla",
            "lineno": 121,
            "outcome": "passed",
            "setup": {
                "duration": 0.00040091299979394535,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.0120371379998687,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020830699941143394,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_backward_twice_xla",
            "lineno": 176,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003806280001299456,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.10394174300017767,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018402800014882814,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_groups_nobias_v2_xla",
            "lineno": 232,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004053169996041106,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.024578300999564817,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020197499998175772,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_groups_nobias_xla",
            "lineno": 189,
            "outcome": "passed",
            "setup": {
                "duration": 0.00041007100026035914,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.019962953000685957,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020409099943208275,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_inconsistent_types_on_GPU_with_cudnn_xla",
            "lineno": 157,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0004202170002827188,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00027452900030766614,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/conv2d_test.py', 158, 'Skipped: CUDNN not available')"
            },
            "teardown": {
                "duration": 0.00014814399946772028,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_inconsistent_types_on_GPU_without_cudnn_xla",
            "lineno": 94,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036012100008520065,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.003912352999577706,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011107599948445568,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_inconsistent_types_xla",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002756240000962862,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009799570007089642,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001269269996555522,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_missing_argument_xla",
            "lineno": 172,
            "outcome": "passed",
            "setup": {
                "duration": 0.00031746500008011935,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0010081620002893033,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011094999990746146,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/conv2d_test.py::TestConvolutionNNXLA::test_Conv2d_module_same_padding_xla",
            "lineno": 46,
            "outcome": "passed",
            "setup": {
                "duration": 0.00032436600031360285,
                "outcome": "passed"
            },
            "call": {
                "duration": 2.3521774800001367,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002999440002895426,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestTorchCPU::test_device_cpu",
            "lineno": 65,
            "outcome": "passed",
            "setup": {
                "duration": 0.00043048199950135313,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.024327576999894518,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014108800041867653,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/cuda_test.py::TestTorchXLA::test_device_xla",
            "lineno": 65,
            "outcome": "passed",
            "setup": {
                "duration": 0.001962659000128042,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.023718938999991224,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013585699980467325,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestTorchCPU::test_to_cpu",
            "lineno": 66,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003235730000596959,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.008034161000068707,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019246499959990615,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/data_ptr_test.py::TestTorchXLA::test_to_xla",
            "lineno": 66,
            "outcome": "failed",
            "setup": {
                "duration": 0.001722579000670521,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0030644120006400044,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/data_ptr_test.py",
                    "lineno": 140,
                    "message": "RuntimeError: Cannot access data pointer of Tensor that doesn't have storage"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/data_ptr_test.py",
                        "lineno": 68,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/data_ptr_test.py",
                        "lineno": 140,
                        "message": "in _test_to_with_layout"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/data_ptr_test.py",
                        "lineno": 115,
                        "message": "in test_data_ptr"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/data_ptr_test.py",
                        "lineno": 140,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.data_ptr_test.TestTorchXLA testMethod=test_to_xla>, device = 'xla:1'\n\n    def test_to(self, device):\n>       self._test_to_with_layout(torch.strided, device=device)\n\nsrc/pytorch_tests_reduced/data_ptr_test.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/data_ptr_test.py:140: in _test_to_with_layout\n    test_data_ptr(lambda a: a.data_ptr())\nsrc/pytorch_tests_reduced/data_ptr_test.py:115: in test_data_ptr\n    test_1 = getter(a)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\na = tensor(5, device='xla:1')\n\n>   test_data_ptr(lambda a: a.data_ptr())\nE   RuntimeError: Cannot access data pointer of Tensor that doesn't have storage\n\nsrc/pytorch_tests_reduced/data_ptr_test.py:140: RuntimeError"
            },
            "teardown": {
                "duration": 0.00015348200031439774,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsCPU::test_diag_cpu_bool",
            "lineno": 23,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033469100071670255,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0011727230003089062,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013903200033382745,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsCPU::test_diag_cpu_float32",
            "lineno": 23,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003046510000785929,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001021842999762157,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014795299921388505,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsXLA::test_diag_xla_bool",
            "lineno": 23,
            "outcome": "passed",
            "setup": {
                "duration": 0.00192298000001756,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.10822818799988454,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001631679997444735,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/diag_test.py::TestShapeOpsXLA::test_diag_xla_float32",
            "lineno": 23,
            "outcome": "passed",
            "setup": {
                "duration": 0.00030827099999442,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.09582312499969703,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019134499962092377,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNDeviceTypeCPU::test_Dropout3d_cpu",
            "lineno": 124,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004071020002811565,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02505757499966421,
                "outcome": "passed",
                "log": [
                    {
                        "name": "tensorflow",
                        "msg": "Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.",
                        "args": null,
                        "levelname": "WARNING",
                        "levelno": 30,
                        "pathname": "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py",
                        "filename": "deprecation.py",
                        "module": "deprecation",
                        "exc_info": null,
                        "exc_text": null,
                        "stack_info": null,
                        "lineno": 699,
                        "funcName": "getter",
                        "created": 1682973810.1778183,
                        "msecs": 177.81829833984375,
                        "relativeCreated": 1505715.6250476837,
                        "thread": 140535878245440,
                        "threadName": "MainThread",
                        "processName": "MainProcess",
                        "process": 150209
                    }
                ]
            },
            "teardown": {
                "duration": 0.00015864800025156,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNDeviceTypeXLA::test_Dropout3d_xla",
            "lineno": 124,
            "outcome": "failed",
            "setup": {
                "duration": 0.0021095910005897167,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.209603605000666,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/dropout3d_test.py",
                    "lineno": 99,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 208 / 400 (52.0%)\nGreatest absolute difference: 1.9859619140625 at index (24, 1, 0, 0) (up to 1e-05 allowed)\nGreatest relative difference: inf at index (3, 0, 0, 0) (up to 1.3e-06 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/dropout3d_test.py",
                        "lineno": 147,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/dropout3d_test.py",
                        "lineno": 99,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.dropout3d_test.TestDropoutNNDeviceTypeXLA testMethod=test_Dropout3d_xla>, device = 'xla:1'\n\n    def test_Dropout3d(self, device):\n        b = random.randint(1, 5)\n        w = random.randint(1, 5)\n        h = random.randint(1, 5)\n        d = random.randint(1, 2)\n        num_features = 1000\n        input = torch.empty(num_features, b, d, w, h)\n        self._test_dropout(nn.Dropout3d, device, input)\n    \n        self._test_dropout_discontiguous(nn.Dropout3d, device)\n        self._test_dropout_discontiguous(nn.Dropout3d, device, memory_format=torch.channels_last)\n    \n        with self.assertWarnsRegex(UserWarning, \"Received a 6-D input to dropout3d\"):\n            with pytorch_op_timer():\n                nn.Dropout3d(p=0.5)(torch.rand(1, 2, 2, 2, 2, 2, device=device))\n    \n        with self.assertWarnsRegex(UserWarning, \"Received a 3-D input to dropout3d\"):\n            with pytorch_op_timer():\n                nn.Dropout3d(p=0.5)(torch.rand(1, 2, 2, device=device))\n    \n        # no batch dims\n        input = torch.rand(50, 2, 2, 2, device=device)\n>       self._test_dropoutNd_no_batch(nn.Dropout3d(p=0.5), input)\n\nsrc/pytorch_tests_reduced/dropout3d_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.pytorch_tests_reduced.dropout3d_test.TestDropoutNNDeviceTypeXLA testMethod=test_Dropout3d_xla>, dropout = Dropout3d(p=0.5, inplace=False)\ninput = tensor([[[[6.1713e-01, 9.9986e-01],\n          [5.9957e-01, 4.4109e-01]],\n\n         [[9.4326e-02, 8.1565e-01],\n        ... [9.6623e-01, 1.6211e-01]],\n\n         [[4.2947e-01, 7.4822e-01],\n          [7.4879e-01, 5.5811e-01]]]], device='xla:1')\n\n    def _test_dropoutNd_no_batch(self, dropout, input):\n        input_clone = input.clone()\n        with freeze_rng_state():\n            with pytorch_op_timer():\n                res_no_batch = dropout(input)\n    \n        with freeze_rng_state():\n            with pytorch_op_timer():\n                res_batched = dropout(input_clone.unsqueeze(0)).squeeze(0)\n    \n>       self.assertEqual(res_no_batch, res_batched)\nE       AssertionError: Tensor-likes are not close!\nE       \nE       Mismatched elements: 208 / 400 (52.0%)\nE       Greatest absolute difference: 1.9859619140625 at index (24, 1, 0, 0) (up to 1e-05 allowed)\nE       Greatest relative difference: inf at index (3, 0, 0, 0) (up to 1.3e-06 allowed)\n\nsrc/pytorch_tests_reduced/dropout3d_test.py:99: AssertionError"
            },
            "teardown": {
                "duration": 0.00023272799990081694,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNCPU::test_invalid_dropout_p_cpu",
            "lineno": 19,
            "outcome": "passed",
            "setup": {
                "duration": 0.00037687700023525394,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007708919993092422,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013848900016455445,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout3d_test.py::TestDropoutNNXLA::test_invalid_dropout_p_xla",
            "lineno": 19,
            "outcome": "passed",
            "setup": {
                "duration": 0.0016521990000910591,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007620270007464569,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013765899984719,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNDeviceTypeCPU::test_empty_dropout_cpu",
            "lineno": 166,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003290630002084072,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03097158299988223,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014520500008075032,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNDeviceTypeXLA::test_empty_dropout_xla",
            "lineno": 166,
            "outcome": "passed",
            "setup": {
                "duration": 0.0015854709999985062,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01801403100034804,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015910699949017726,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNCPU::test_invalid_dropout_p_cpu",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003894479996233713,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006569720007973956,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014853999982733512,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNCPU::test_native_dropout_corner_case_cpu",
            "lineno": 34,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026698399960878305,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0018605530003696913,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014798600022913888,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNXLA::test_invalid_dropout_p_xla",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.0017432069998903899,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006711409996569273,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001199509997604764,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/dropout_test.py::TestDropoutNNXLA::test_native_dropout_corner_case_xla",
            "lineno": 34,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027726000007533,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.20305630500024563,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00025967999954445986,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_cpu_complex128",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.00048650500048097456,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0032408030001533916,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012390899973979685,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_cpu_float64",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.00029588500001409557,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002537590999963868,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013246999969851458,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_cpu_int64",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003381629994692048,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0021297499997672276,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011351000011927681,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_invalid_cpu_complex128",
            "lineno": 72,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026245800017932197,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.007457007000084559,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001297449998673983,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_invalid_cpu_float64",
            "lineno": 72,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002662500000951695,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.006470607000665041,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011258100039412966,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_fliplr_invalid_cpu_int64",
            "lineno": 72,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002601159994810587,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.007034169000689872,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013481099995260593,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_flipud_cpu_complex128",
            "lineno": 80,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026360799984104233,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.003222908000680036,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014677400031359866,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_flipud_cpu_float64",
            "lineno": 80,
            "outcome": "passed",
            "setup": {
                "duration": 0.00030821200016362127,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002893605000281241,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011541100047907094,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsCPU::test_flipud_cpu_int64",
            "lineno": 80,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002765890003502136,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002396111999587447,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002065190001303563,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_invalid_xla_complex128",
            "lineno": 72,
            "outcome": "passed",
            "setup": {
                "duration": 0.0016204960002141888,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.008413708999796654,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013156999921193346,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_invalid_xla_float64",
            "lineno": 72,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003203149999535526,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00831260100039799,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001131429999077227,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_invalid_xla_int64",
            "lineno": 72,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002879590001612087,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.008548313000574126,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012174299990874715,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_xla_complex128",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028099700011807727,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.484853861999909,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019889999930455815,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_xla_float64",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003682630003822851,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.39524202100074035,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020336200032033958,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_fliplr_xla_int64",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004284779997760779,
                "outcome": "passed"
            },
            "call": {
                "duration": 5.277434462000201,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019077500019193394,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_flipud_xla_complex128",
            "lineno": 80,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003932879999410943,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.61990223399971,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001981370005523786,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_flipud_xla_float64",
            "lineno": 80,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004241149999870686,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.49672616900079447,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00025475799975538393,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/fliplr_test.py::TestShapeOpsXLA::test_flipud_xla_int64",
            "lineno": 80,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003762910000659758,
                "outcome": "passed"
            },
            "call": {
                "duration": 8.100395940000453,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002949800000351388,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestQuantizedOpsCPU::test_group_norm_cpu",
            "lineno": 138,
            "outcome": "passed",
            "setup": {
                "duration": 0.000465918000372767,
                "outcome": "passed"
            },
            "call": {
                "duration": 8.240430915000616,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003035549998458009,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/group_norm_test.py::TestQuantizedOpsXLA::test_group_norm_xla",
            "lineno": 138,
            "outcome": "failed",
            "setup": {
                "duration": 0.00297935900016455,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.009264312000595964,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/_ops.py",
                    "lineno": 143,
                    "message": "NotImplementedError: Could not run 'quantized::group_norm' with arguments from the 'UNKNOWN_TENSOR_TYPE_ID' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::group_norm' is only available for these backends: [Vulkan, Negative, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nXLA: registered at torch_xla/csrc/aten_cpu_fallback.cpp:44 [backend fallback]\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qnormalization.cpp:119 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradMPS: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradXPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradHPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:68 [backend fallback]\nAutogradLazy: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:55 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:295 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/group_norm_test.py",
                        "lineno": 214,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/_ops.py",
                        "lineno": 143,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.group_norm_test.TestQuantizedOpsXLA testMethod=test_group_norm_xla>, device = 'xla:1'\n\n    @skipIfNoFBGEMM\n    def test_group_norm(self, device):\n        # hypothesis is flaky for this test, create test cases manually\n        batches_list = (1, 7)\n        num_groups_list = (1, 4)\n        channels_per_groups = (1, 36, 72)\n        elements_per_channels = (8, 128, 1024)\n        torch_types = (torch.qint8, torch.quint8)\n        y_scales = (0.1, 4.23)\n        y_zero_points = (0, 1)\n        channels_last_list = [True, False]\n        affine_list = [True, False]\n        combined = [batches_list, num_groups_list, channels_per_groups, elements_per_channels,\n                    torch_types, y_scales, y_zero_points, channels_last_list, affine_list]\n        test_cases = itertools.product(*combined)\n    \n        with override_quantized_engine(\"fbgemm\"):\n            for test_case in test_cases:\n    \n                batches, num_groups, channels_per_group, elements_per_channel, \\\n                    torch_type, Y_scale, Y_zero_point, channels_last, \\\n                    affine = test_case\n                num_channels = num_groups * channels_per_group\n                # minimum rank for channels_last\n                shapes = (batches, num_channels, elements_per_channel, 1)\n    \n                # In the FP kernel, sums and sums of squares are calculated in floating point.\n                # In the int8 and uint8 versions of the quantized kernel, they are\n                # calculated in integer arithmetic (which is exact).\n                # Because of this, the numerics do not always match exactly which is\n                # expected and acceptable. We do the following to allow this failure\n                # in this test:\n                # 1. do not use Hypothesis to generate the input tensor.  Hypothesis\n                #    favors homogeneous inputs in its search strategies which isn't\n                #    representative of the inputs we care about, and tends to maximize\n                #    this particular numerics difference.\n                # 2. allow a small % of off by Y_scale errors.  Even when the\n                #    variance of the input is high, there can be off by one errors\n                #    in the result if the input value happens to fall exactly on\n                #    the bin boundary of the output scale.\n                #\n                # If we want the numerics to match we could switch to calculating\n                # mean+var in floating point in the future, at the cost of speed.\n                X, X_scale, X_zero_point = \\\n                    _get_random_tensor_and_q_params(shapes, 1.0, torch_type)\n    \n                # Initialize the weights non-randomly for reproducibility\n                if affine:\n                    weight = torch.ones(num_channels, device=device).float() * 0.5\n                    bias = torch.ones(num_channels, device=device).float()\n                    for i in range(num_channels):\n                        weight[i] *= i\n                        bias[i] *= i\n                else:\n                    weight = None\n                    bias = None\n    \n                eps = 0.001\n    \n                qX = torch.quantize_per_tensor(X, X_scale, X_zero_point, torch_type)\n                if channels_last:\n                    qX = qX.contiguous(memory_format=torch.channels_last)\n                dqX = qX.dequantize()\n    \n                # Enforce non-homogeneous inputs\n                for batch_idx in range(batches):\n                    for group_idx in range(num_groups):\n                        ch_start = group_idx * channels_per_group\n                        ch_end = ch_start + channels_per_group\n                        group_vals = dqX[batch_idx][ch_start:ch_end]\n                        assume(\n                            float(torch.unique(group_vals).shape[0]) / group_vals.numel() > 0.001\n                            or group_vals.numel() < 5)\n    \n                with pytorch_op_timer():\n>                   qY = torch.ops.quantized.group_norm(qX, num_groups, weight, bias, eps, Y_scale, Y_zero_point)\n\nsrc/pytorch_tests_reduced/group_norm_test.py:214: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <OpOverloadPacket(op='quantized.group_norm')>\nargs = (tensor([[[[-0.3411],\n          [-0.0971],\n          [-0.2414],\n          [-0.1338],\n          [-0.3411],\n          [ ...6236933190375566,\n       zero_point=2), 1, tensor([0.], device='xla:1'), tensor([0.], device='xla:1'), 0.001, 0.1, ...)\nkwargs = {}\n\n    def __call__(self, *args, **kwargs):\n        # overloading __call__ to ensure torch.ops.foo.bar()\n        # is still callable from JIT\n        # We save the function ptr as the `op` attribute on\n        # OpOverloadPacket to access it here.\n>       return self._op(*args, **kwargs or {})\nE       NotImplementedError: Could not run 'quantized::group_norm' with arguments from the 'UNKNOWN_TENSOR_TYPE_ID' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::group_norm' is only available for these backends: [Vulkan, Negative, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\nE       \nE       XLA: registered at torch_xla/csrc/aten_cpu_fallback.cpp:44 [backend fallback]\nE       QuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qnormalization.cpp:119 [kernel]\nE       BackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nE       Python: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nE       Named: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nE       Conjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nE       Negative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nE       ZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nE       ADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nE       AutogradOther: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:35 [backend fallback]\nE       AutogradCPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:39 [backend fallback]\nE       AutogradCUDA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:47 [backend fallback]\nE       AutogradXLA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:51 [backend fallback]\nE       AutogradMPS: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:59 [backend fallback]\nE       AutogradXPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:43 [backend fallback]\nE       AutogradHPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:68 [backend fallback]\nE       AutogradLazy: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:55 [backend fallback]\nE       Tracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:295 [backend fallback]\nE       AutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nE       Autocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nE       Batched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nE       VmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nE       Functionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nE       PythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n\n/usr/local/lib/python3.8/dist-packages/torch/_ops.py:143: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00020978700013074558,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestTorchCPU::test_is_same_size_cpu",
            "lineno": 69,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003919060000043828,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0010814119996211957,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001765730003171484,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/is_same_size_test.py::TestTorchXLA::test_is_same_size_xla",
            "lineno": 69,
            "outcome": "passed",
            "setup": {
                "duration": 0.001948742999957176,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.030457423999905586,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013977100024931133,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jacobian_match_vjp_jvp_base_tensor_cpu",
            "lineno": 328,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004043159997308976,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002598183999907633,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012614200022653677,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jacobian_match_vjp_jvp_logging_tensor_cpu",
            "lineno": 328,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027376700018066913,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01352676300029998,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011981999978161184,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_create_graph_base_tensor_cpu",
            "lineno": 283,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002803070001391461,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.044226506000086374,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011645299946394516,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_create_graph_logging_tensor_cpu",
            "lineno": 283,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002829430004567257,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.35134765499969944,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011789400014095008,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_err_check_base_tensor_cpu",
            "lineno": 127,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002757519996521296,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0018014509996646666,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011433500003477093,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_err_check_logging_tensor_cpu",
            "lineno": 127,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002791150000120979,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0029991510000400012,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014624300001742085,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_err_check_strict_base_tensor_cpu",
            "lineno": 156,
            "outcome": "passed",
            "setup": {
                "duration": 0.00031861200022831326,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002217782000116131,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011507300041557755,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_err_check_strict_logging_tensor_cpu",
            "lineno": 156,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002701540006455616,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.005291692999890074,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001563099995109951,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_no_grad_base_tensor_cpu",
            "lineno": 193,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034079399938491406,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001368394999190059,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011251399973843945,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_no_grad_logging_tensor_cpu",
            "lineno": 193,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002869199997803662,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0031233390000124928,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011343200003466336,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_output_base_tensor_cpu",
            "lineno": 216,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002746579993981868,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001792654000382754,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001456140007576323,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_output_logging_tensor_cpu",
            "lineno": 216,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003784620002988959,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.005093732999739586,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011269699916738318,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_scalar_base_tensor_cpu",
            "lineno": 256,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002705000006244518,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0016577689993937383,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012058399988745805,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalCPU::test_jvp_scalar_logging_tensor_cpu",
            "lineno": 256,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026189399977738503,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0056177750002461835,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00024414000017713988,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jacobian_match_vjp_jvp_base_tensor_xla",
            "lineno": 328,
            "outcome": "passed",
            "setup": {
                "duration": 0.002166310000575322,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.17978139299975737,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016334800056938548,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jacobian_match_vjp_jvp_logging_tensor_xla",
            "lineno": 328,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036917600027663866,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.021388108999417454,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014503700003842823,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_create_graph_base_tensor_xla",
            "lineno": 283,
            "outcome": "failed",
            "setup": {
                "duration": 0.00034623000010469696,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.7438686989999042,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                    "lineno": 1280,
                    "message": "torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor(1.2879, device='xla:1', dtype=torch.float64)\nanalytical:tensor(1.2896, device='xla:1', dtype=torch.float64)\n\nThe above quantities relating the numerical and analytical jacobians are computed \nin fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nabout fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\n\nNumerical:\n tensor([[1.0000, 0.0000],\n        [1.0000, 0.0000],\n        [0.0000, 1.0000],\n        [0.0000, 1.0000]], device='xla:1', dtype=torch.float64)\nAnalytical:\ntensor([[1., 0.],\n        [1., 0.],\n        [0., 1.],\n        [0., 1.]], device='xla:1', dtype=torch.float64)\n\nThe max per-element difference (slow mode) is: 1.2934207916259766e-05.\nFast gradcheck failed but element-wise differences are small. This means that the\ntest might've passed in slow_mode!\n\nIf you are adding a new operator, please file an issue and then use one of the\nworkarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:\n\nIf the test\n- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck\n  with `fast_mode=False` as a keyword argument.\n- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test\n  to have `gradcheck_fast_mode=False`\n- is a Module test (e.g., in common_nn.py), then modify the corresponding\n  module_test entry to have `gradcheck_fast_mode=False`"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/jvp_test.py",
                        "lineno": 300,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 3019,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1414,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1428,
                        "message": "in _gradcheck_helper"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1075,
                        "message": "in _gradcheck_real_imag"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1307,
                        "message": "in _fast_gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1280,
                        "message": "GradcheckError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.jvp_test.TestAutogradFunctionalXLA testMethod=test_jvp_create_graph_base_tensor_xla>\nctors = namespace(ones=<built-in method ones of type object at 0x7fd01c25f980>, rand=<built-in method rand of type object at 0...ilt-in method tensor of type object at 0x7fd01c25f980>, zeros=<built-in method zeros of type object at 0x7fd01c25f980>)\ndevice = 'xla:1'\n\n    @base_and_logging_tensor\n    def test_jvp_create_graph(self, ctors, device):\n        def reducer(x):\n            return x.sum(dim=1)\n        inputs = ctors.rand(2, 2, dtype=torch.double, device=device)\n        v = ctors.ones(2, 2, dtype=torch.double, device=device)\n    \n        inputs.requires_grad_()\n        v.requires_grad_()\n    \n        with pytorch_op_timer():\n            res = autogradF.jvp(reducer, inputs, v, create_graph=True)\n        self._assert_same_struct(res[1], res[0])\n        self.assertIsNotNone(res[0].grad_fn)\n        self.assertIsNotNone(res[1].grad_fn)\n    \n>       gradcheck(lambda inp, v: autogradF.jvp(reducer, inp, v, create_graph=True), (inputs, v))\n\nsrc/pytorch_tests_reduced/jvp_test.py:300: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:3019: in gradcheck\n    return torch.autograd.gradcheck(fn, inputs, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1414: in gradcheck\n    return _gradcheck_helper(**args)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1428: in _gradcheck_helper\n    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1075: in _gradcheck_real_imag\n    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1307: in _fast_gradcheck\n    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nall_analytical = [[tensor(1.2896, device='xla:1', dtype=torch.float64), tensor(0., device='xla:1', dtype=torch.float64)], [tensor(0., device='xla:1', dtype=torch.float64), tensor(0.9298, device='xla:1', dtype=torch.float64)]]\nall_numerical = [[tensor(1.2879, device='xla:1', dtype=torch.float64), tensor(0., device='xla:1', dtype=torch.float64)], [tensor(0., device='xla:1', dtype=torch.float64), tensor(0.8669, device='xla:1', dtype=torch.float64)]]\ncomplex_indices = None\ntupled_inputs = (tensor([[0.5356, 0.2687],\n        [0.3933, 0.1214]], device='xla:1', dtype=torch.float64,\n       requires_grad=True), tensor([[1., 1.],\n        [1., 1.]], device='xla:1', dtype=torch.float64, requires_grad=True))\noutputs = (tensor([0.8044, 0.5147], device='xla:1', dtype=torch.float64,\n       grad_fn=<SumBackward1>), tensor([2., 2.], device='xla:1', dtype=torch.float64,\n       grad_fn=<SqueezeBackward1>))\nfunc = <function TestAutogradFunctional.test_jvp_create_graph.<locals>.<lambda> at 0x7fcde546c3a0>\nall_v = [tensor([0.8582, 0.5133], device='xla:1', dtype=torch.float64), tensor([0.1699, 0.9855], device='xla:1', dtype=torch.float64)]\nall_u = [tensor([0.2540, 0.8291, 0.3186, 0.3829], device='xla:1', dtype=torch.float64), tensor([0.5903, 0.3432, 0.0540, 0.7286], device='xla:1', dtype=torch.float64)]\nrtol = 0.001, atol = 1e-05, test_imag = False\n\n    def _check_analytical_numerical_equal(all_analytical, all_numerical, complex_indices, tupled_inputs, outputs,\n                                          func, all_v, all_u, rtol, atol, test_imag, *, is_forward_ad=False):\n        for i, all_numerical_for_input_i in enumerate(all_numerical):\n            for j, n in enumerate(all_numerical_for_input_i):\n                # Forward AD generates the transpose of what this function expects\n                if is_forward_ad:\n                    a = all_analytical[i][j]\n                else:\n                    a = all_analytical[j][i]\n                n = n.to(device=a.device)\n                updated_atol = _adjusted_atol(atol, all_u[i], all_v[j] if all_v else None)\n                if not _allclose_with_type_promotion(a, n.to(a.device), rtol, updated_atol):\n                    jacobians_str = _run_slow_mode_and_get_error(func, tupled_inputs, outputs, i, j, rtol, atol, is_forward_ad)\n>                   raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)\nE                   torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nE                   numerical:tensor(1.2879, device='xla:1', dtype=torch.float64)\nE                   analytical:tensor(1.2896, device='xla:1', dtype=torch.float64)\nE                   \nE                   The above quantities relating the numerical and analytical jacobians are computed \nE                   in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nE                   about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\nE                   \nE                   Numerical:\nE                    tensor([[1.0000, 0.0000],\nE                           [1.0000, 0.0000],\nE                           [0.0000, 1.0000],\nE                           [0.0000, 1.0000]], device='xla:1', dtype=torch.float64)\nE                   Analytical:\nE                   tensor([[1., 0.],\nE                           [1., 0.],\nE                           [0., 1.],\nE                           [0., 1.]], device='xla:1', dtype=torch.float64)\nE                   \nE                   The max per-element difference (slow mode) is: 1.2934207916259766e-05.\nE                   Fast gradcheck failed but element-wise differences are small. This means that the\nE                   test might've passed in slow_mode!\nE                   \nE                   If you are adding a new operator, please file an issue and then use one of the\nE                   workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:\nE                   \nE                   If the test\nE                   - manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck\nE                     with `fast_mode=False` as a keyword argument.\nE                   - is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test\nE                     to have `gradcheck_fast_mode=False`\nE                   - is a Module test (e.g., in common_nn.py), then modify the corresponding\nE                     module_test entry to have `gradcheck_fast_mode=False`\n\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1280: GradcheckError"
            },
            "teardown": {
                "duration": 0.00023472600059903925,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_create_graph_logging_tensor_xla",
            "lineno": 283,
            "outcome": "failed",
            "setup": {
                "duration": 0.00039486100013164105,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.1851688369997646,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                    "lineno": 1280,
                    "message": "torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:LoggingTensor(1.2879002094268799, device='xla:1', dtype=torch.float64)\nanalytical:LoggingTensor(1.2895770072937012, device='xla:1', dtype=torch.float64)\n\nThe above quantities relating the numerical and analytical jacobians are computed \nin fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nabout fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\n\nNumerical:\n LoggingTensor(tensor([[1.0000, 0.0000],\n        [1.0000, 0.0000],\n        [0.0000, 1.0000],\n        [0.0000, 1.0000]], device='xla:1', dtype=torch.float64),\n              device='xla:1', dtype=torch.float64)\nAnalytical:\nLoggingTensor(tensor([[1., 0.],\n        [1., 0.],\n        [0., 1.],\n        [0., 1.]], device='xla:1', dtype=torch.float64), device='xla:1',\n              dtype=torch.float64)\n\nThe max per-element difference (slow mode) is: 4.661083221435547e-05.\nFast gradcheck failed but element-wise differences are small. This means that the\ntest might've passed in slow_mode!\n\nIf you are adding a new operator, please file an issue and then use one of the\nworkarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:\n\nIf the test\n- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck\n  with `fast_mode=False` as a keyword argument.\n- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test\n  to have `gradcheck_fast_mode=False`\n- is a Module test (e.g., in common_nn.py), then modify the corresponding\n  module_test entry to have `gradcheck_fast_mode=False`"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/jvp_test.py",
                        "lineno": 300,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 3019,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1414,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1428,
                        "message": "in _gradcheck_helper"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1075,
                        "message": "in _gradcheck_real_imag"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1307,
                        "message": "in _fast_gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1280,
                        "message": "GradcheckError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.jvp_test.TestAutogradFunctionalXLA testMethod=test_jvp_create_graph_logging_tensor_xla>\nctors = namespace(ones=<function wrap_with_logging_tensor.<locals>.wrapper at 0x7fce4eeb9940>, rand=<function wrap_with_loggin...nsor.<locals>.wrapper at 0x7fce4eeb9b80>, zeros=<function wrap_with_logging_tensor.<locals>.wrapper at 0x7fce4eeb99d0>)\ndevice = 'xla:1'\n\n    @base_and_logging_tensor\n    def test_jvp_create_graph(self, ctors, device):\n        def reducer(x):\n            return x.sum(dim=1)\n        inputs = ctors.rand(2, 2, dtype=torch.double, device=device)\n        v = ctors.ones(2, 2, dtype=torch.double, device=device)\n    \n        inputs.requires_grad_()\n        v.requires_grad_()\n    \n        with pytorch_op_timer():\n            res = autogradF.jvp(reducer, inputs, v, create_graph=True)\n        self._assert_same_struct(res[1], res[0])\n        self.assertIsNotNone(res[0].grad_fn)\n        self.assertIsNotNone(res[1].grad_fn)\n    \n>       gradcheck(lambda inp, v: autogradF.jvp(reducer, inp, v, create_graph=True), (inputs, v))\n\nsrc/pytorch_tests_reduced/jvp_test.py:300: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:3019: in gradcheck\n    return torch.autograd.gradcheck(fn, inputs, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1414: in gradcheck\n    return _gradcheck_helper(**args)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1428: in _gradcheck_helper\n    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1075: in _gradcheck_real_imag\n    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1307: in _fast_gradcheck\n    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nall_analytical = [[LoggingTensor(1.2895770072937012, device='xla:1', dtype=torch.float64), LoggingTensor(0.0, device='xla:1', dtype=tor...sor(0.0, device='xla:1', dtype=torch.float64), LoggingTensor(0.9297502040863037, device='xla:1', dtype=torch.float64)]]\nall_numerical = [[LoggingTensor(1.2879002094268799, device='xla:1', dtype=torch.float64), LoggingTensor(0.0, device='xla:1', dtype=tor...sor(0.0, device='xla:1', dtype=torch.float64), LoggingTensor(0.8668793439865112, device='xla:1', dtype=torch.float64)]]\ncomplex_indices = None\ntupled_inputs = (LoggingTensor(tensor([[0.8314, 0.5653],\n        [0.3822, 0.9677]], device='xla:1', dtype=torch.float64),\n            ...1., 1.]], device='xla:1', dtype=torch.float64), device='xla:1',\n              dtype=torch.float64, requires_grad=True))\noutputs = (LoggingTensor(tensor([1.3968, 1.3500], device='xla:1', dtype=torch.float64),\n              device='xla:1', dtype=torc..., device='xla:1', dtype=torch.float64),\n              device='xla:1', dtype=torch.float64, grad_fn=<SqueezeBackward1>))\nfunc = <function TestAutogradFunctional.test_jvp_create_graph.<locals>.<lambda> at 0x7fcde546caf0>\nall_v = [tensor([0.8582, 0.5133], device='xla:1', dtype=torch.float64), tensor([0.1699, 0.9855], device='xla:1', dtype=torch.float64)]\nall_u = [tensor([0.2540, 0.8291, 0.3186, 0.3829], device='xla:1', dtype=torch.float64), tensor([0.5903, 0.3432, 0.0540, 0.7286], device='xla:1', dtype=torch.float64)]\nrtol = 0.001, atol = 1e-05, test_imag = False\n\n    def _check_analytical_numerical_equal(all_analytical, all_numerical, complex_indices, tupled_inputs, outputs,\n                                          func, all_v, all_u, rtol, atol, test_imag, *, is_forward_ad=False):\n        for i, all_numerical_for_input_i in enumerate(all_numerical):\n            for j, n in enumerate(all_numerical_for_input_i):\n                # Forward AD generates the transpose of what this function expects\n                if is_forward_ad:\n                    a = all_analytical[i][j]\n                else:\n                    a = all_analytical[j][i]\n                n = n.to(device=a.device)\n                updated_atol = _adjusted_atol(atol, all_u[i], all_v[j] if all_v else None)\n                if not _allclose_with_type_promotion(a, n.to(a.device), rtol, updated_atol):\n                    jacobians_str = _run_slow_mode_and_get_error(func, tupled_inputs, outputs, i, j, rtol, atol, is_forward_ad)\n>                   raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)\nE                   torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nE                   numerical:LoggingTensor(1.2879002094268799, device='xla:1', dtype=torch.float64)\nE                   analytical:LoggingTensor(1.2895770072937012, device='xla:1', dtype=torch.float64)\nE                   \nE                   The above quantities relating the numerical and analytical jacobians are computed \nE                   in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nE                   about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\nE                   \nE                   Numerical:\nE                    LoggingTensor(tensor([[1.0000, 0.0000],\nE                           [1.0000, 0.0000],\nE                           [0.0000, 1.0000],\nE                           [0.0000, 1.0000]], device='xla:1', dtype=torch.float64),\nE                                 device='xla:1', dtype=torch.float64)\nE                   Analytical:\nE                   LoggingTensor(tensor([[1., 0.],\nE                           [1., 0.],\nE                           [0., 1.],\nE                           [0., 1.]], device='xla:1', dtype=torch.float64), device='xla:1',\nE                                 dtype=torch.float64)\nE                   \nE                   The max per-element difference (slow mode) is: 4.661083221435547e-05.\nE                   Fast gradcheck failed but element-wise differences are small. This means that the\nE                   test might've passed in slow_mode!\nE                   \nE                   If you are adding a new operator, please file an issue and then use one of the\nE                   workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:\nE                   \nE                   If the test\nE                   - manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck\nE                     with `fast_mode=False` as a keyword argument.\nE                   - is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test\nE                     to have `gradcheck_fast_mode=False`\nE                   - is a Module test (e.g., in common_nn.py), then modify the corresponding\nE                     module_test entry to have `gradcheck_fast_mode=False`\n\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1280: GradcheckError"
            },
            "teardown": {
                "duration": 0.00022709400036546867,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_err_check_base_tensor_xla",
            "lineno": 127,
            "outcome": "passed",
            "setup": {
                "duration": 0.00038184899949555984,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.061521885000729526,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001616889994693338,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_err_check_logging_tensor_xla",
            "lineno": 127,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033273400003963616,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.055173531000036746,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015457300014531938,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_err_check_strict_base_tensor_xla",
            "lineno": 156,
            "outcome": "passed",
            "setup": {
                "duration": 0.00041953300024033524,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.2135907279998719,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002032470001722686,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_err_check_strict_logging_tensor_xla",
            "lineno": 156,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004517190000115079,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.018049774000246543,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001360060005026753,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_no_grad_base_tensor_xla",
            "lineno": 193,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003346700004840386,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.09233971699995891,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015119300041988026,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_no_grad_logging_tensor_xla",
            "lineno": 193,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003474890008874354,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.006271027000366303,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012388399954943452,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_output_base_tensor_xla",
            "lineno": 216,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003521819999150466,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.004878827000538877,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014504299997497583,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_output_logging_tensor_xla",
            "lineno": 216,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028236599973752163,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.007193983999968623,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011315699975966709,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_scalar_base_tensor_xla",
            "lineno": 256,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002871830001822673,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.13432774400007474,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015233500016620383,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/jvp_test.py::TestAutogradFunctionalXLA::test_jvp_scalar_logging_tensor_xla",
            "lineno": 256,
            "outcome": "passed",
            "setup": {
                "duration": 0.00037796100059495075,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00988464700003533,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00027926199982175604,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNCPU::test_KLDivLoss_batch_mean_cpu",
            "lineno": 90,
            "outcome": "passed",
            "setup": {
                "duration": 0.00042600300002959557,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0015717969999968773,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015762299972266192,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNCPU::test_KLDivLoss_batch_mean_log_target_cpu",
            "lineno": 105,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003029529998457292,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001327738000327372,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015310100025089923,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNXLA::test_KLDivLoss_batch_mean_log_target_xla",
            "lineno": 105,
            "outcome": "passed",
            "setup": {
                "duration": 0.001912046999677841,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.16095530900020094,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001577259999976377,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/kldivloss_test.py::TestNNXLA::test_KLDivLoss_batch_mean_xla",
            "lineno": 90,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034543200035841437,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.09103488399978232,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002103650003846269,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestNNCPU::test_to_cpu",
            "lineno": 67,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004208129994367482,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001403111999934481,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015307099965866655,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/linear_test.py::TestNNXLA::test_to_xla",
            "lineno": 67,
            "outcome": "passed",
            "setup": {
                "duration": 0.0016430480000053649,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.034064823999869986,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017832699995778967,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_float32",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039716700030112406,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.016320644000188622,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001505899999756366,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_float64",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003523619998304639,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.017555261999405047,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016116999995574588,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_int16",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.00035692399978870526,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.04416724600014277,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013133700031175977,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_int32",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002885089998017065,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.044133835999673465,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001260189992535743,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_int64",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002648289992066566,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.04372907299966755,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001307479997194605,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_int8",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.00032767100037744967,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.04393069599973387,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001135320007961127,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseCPU::test_log1p_cpu_uint8",
            "lineno": 84,
            "outcome": "passed",
            "setup": {
                "duration": 0.000278270999842789,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.04346840600010182,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002362650002396549,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_float32",
            "lineno": 84,
            "outcome": "failed",
            "setup": {
                "duration": 0.0018481710003470653,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.08095348700044269,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/log1p_test.py",
                    "lineno": 89,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/log1p_test.py",
                        "lineno": 89,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.log1p_test.TestSparseXLA testMethod=test_log1p_xla_float32>, device = 'xla:1', dtype = torch.float32\ncoalesced = True\n\n    @coalescedonoff\n    @dtypes(*all_types())\n    def test_log1p(self, device, dtype, coalesced):\n        if coalesced:\n>           input_coalesced = torch.sparse_coo_tensor(\n                indices=torch.tensor([[0], [1], [2]]).transpose(1, 0),\n                values=torch.tensor([3.0, 4.0, 5.0]),\n                size=[3, ],\n                device=device,\n                dtype=dtype\n            ).coalesce()\nE           NotImplementedError: Unsupported device type for sparse layout: xla\n\nsrc/pytorch_tests_reduced/log1p_test.py:89: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00014911600010236725,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_float64",
            "lineno": 84,
            "outcome": "failed",
            "setup": {
                "duration": 0.0002955469999506022,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.015228803000354674,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/log1p_test.py",
                    "lineno": 89,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/log1p_test.py",
                        "lineno": 89,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.log1p_test.TestSparseXLA testMethod=test_log1p_xla_float64>, device = 'xla:1', dtype = torch.float64\ncoalesced = True\n\n    @coalescedonoff\n    @dtypes(*all_types())\n    def test_log1p(self, device, dtype, coalesced):\n        if coalesced:\n>           input_coalesced = torch.sparse_coo_tensor(\n                indices=torch.tensor([[0], [1], [2]]).transpose(1, 0),\n                values=torch.tensor([3.0, 4.0, 5.0]),\n                size=[3, ],\n                device=device,\n                dtype=dtype\n            ).coalesce()\nE           NotImplementedError: Unsupported device type for sparse layout: xla\n\nsrc/pytorch_tests_reduced/log1p_test.py:89: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00013340900022740243,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_int16",
            "lineno": 84,
            "outcome": "failed",
            "setup": {
                "duration": 0.00029543900018325076,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02827763099958247,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/log1p_test.py",
                    "lineno": 89,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/log1p_test.py",
                        "lineno": 89,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.log1p_test.TestSparseXLA testMethod=test_log1p_xla_int16>, device = 'xla:1', dtype = torch.int16, coalesced = True\n\n    @coalescedonoff\n    @dtypes(*all_types())\n    def test_log1p(self, device, dtype, coalesced):\n        if coalesced:\n>           input_coalesced = torch.sparse_coo_tensor(\n                indices=torch.tensor([[0], [1], [2]]).transpose(1, 0),\n                values=torch.tensor([3.0, 4.0, 5.0]),\n                size=[3, ],\n                device=device,\n                dtype=dtype\n            ).coalesce()\nE           NotImplementedError: Unsupported device type for sparse layout: xla\n\nsrc/pytorch_tests_reduced/log1p_test.py:89: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00013526800012186868,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_int32",
            "lineno": 84,
            "outcome": "failed",
            "setup": {
                "duration": 0.00033539200012455694,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01498828500007221,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/log1p_test.py",
                    "lineno": 89,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/log1p_test.py",
                        "lineno": 89,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.log1p_test.TestSparseXLA testMethod=test_log1p_xla_int32>, device = 'xla:1', dtype = torch.int32, coalesced = True\n\n    @coalescedonoff\n    @dtypes(*all_types())\n    def test_log1p(self, device, dtype, coalesced):\n        if coalesced:\n>           input_coalesced = torch.sparse_coo_tensor(\n                indices=torch.tensor([[0], [1], [2]]).transpose(1, 0),\n                values=torch.tensor([3.0, 4.0, 5.0]),\n                size=[3, ],\n                device=device,\n                dtype=dtype\n            ).coalesce()\nE           NotImplementedError: Unsupported device type for sparse layout: xla\n\nsrc/pytorch_tests_reduced/log1p_test.py:89: NotImplementedError"
            },
            "teardown": {
                "duration": 0.0001281020004171296,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_int64",
            "lineno": 84,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003153079996991437,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.015508216000853281,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/log1p_test.py",
                    "lineno": 89,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/log1p_test.py",
                        "lineno": 89,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.log1p_test.TestSparseXLA testMethod=test_log1p_xla_int64>, device = 'xla:1', dtype = torch.int64, coalesced = True\n\n    @coalescedonoff\n    @dtypes(*all_types())\n    def test_log1p(self, device, dtype, coalesced):\n        if coalesced:\n>           input_coalesced = torch.sparse_coo_tensor(\n                indices=torch.tensor([[0], [1], [2]]).transpose(1, 0),\n                values=torch.tensor([3.0, 4.0, 5.0]),\n                size=[3, ],\n                device=device,\n                dtype=dtype\n            ).coalesce()\nE           NotImplementedError: Unsupported device type for sparse layout: xla\n\nsrc/pytorch_tests_reduced/log1p_test.py:89: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00012829499974031933,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_int8",
            "lineno": 84,
            "outcome": "failed",
            "setup": {
                "duration": 0.00027484499969432363,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.015183448999778193,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/log1p_test.py",
                    "lineno": 89,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/log1p_test.py",
                        "lineno": 89,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.log1p_test.TestSparseXLA testMethod=test_log1p_xla_int8>, device = 'xla:1', dtype = torch.int8, coalesced = True\n\n    @coalescedonoff\n    @dtypes(*all_types())\n    def test_log1p(self, device, dtype, coalesced):\n        if coalesced:\n>           input_coalesced = torch.sparse_coo_tensor(\n                indices=torch.tensor([[0], [1], [2]]).transpose(1, 0),\n                values=torch.tensor([3.0, 4.0, 5.0]),\n                size=[3, ],\n                device=device,\n                dtype=dtype\n            ).coalesce()\nE           NotImplementedError: Unsupported device type for sparse layout: xla\n\nsrc/pytorch_tests_reduced/log1p_test.py:89: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00015343300037784502,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/log1p_test.py::TestSparseXLA::test_log1p_xla_uint8",
            "lineno": 84,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003250269992349786,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.026960821000102442,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/log1p_test.py",
                    "lineno": 89,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/log1p_test.py",
                        "lineno": 89,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.log1p_test.TestSparseXLA testMethod=test_log1p_xla_uint8>, device = 'xla:1', dtype = torch.uint8, coalesced = True\n\n    @coalescedonoff\n    @dtypes(*all_types())\n    def test_log1p(self, device, dtype, coalesced):\n        if coalesced:\n>           input_coalesced = torch.sparse_coo_tensor(\n                indices=torch.tensor([[0], [1], [2]]).transpose(1, 0),\n                values=torch.tensor([3.0, 4.0, 5.0]),\n                size=[3, ],\n                device=device,\n                dtype=dtype\n            ).coalesce()\nE           NotImplementedError: Unsupported device type for sparse layout: xla\n\nsrc/pytorch_tests_reduced/log1p_test.py:89: NotImplementedError"
            },
            "teardown": {
                "duration": 0.00021335299970814958,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgCPU::test_det_logdet_slogdet_batched_cpu_float64",
            "lineno": 247,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003397310001673759,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.024190647000068566,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011601100050029345,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgCPU::test_det_logdet_slogdet_cpu_float64",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002677100001164945,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.8458107750002455,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0006430159992305562,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgXLA::test_det_logdet_slogdet_batched_xla_float64",
            "lineno": 247,
            "outcome": "passed",
            "setup": {
                "duration": 0.00335401299980731,
                "outcome": "passed"
            },
            "call": {
                "duration": 6.681738647999737,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002176670004701009,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/logdet_test.py::TestLinalgXLA::test_det_logdet_slogdet_xla_float64",
            "lineno": 68,
            "outcome": "failed",
            "setup": {
                "duration": 0.0004441150003913208,
                "outcome": "passed"
            },
            "call": {
                "duration": 9.068301735000205,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/logdet_test.py",
                    "lineno": 111,
                    "message": "AssertionError: Scalars are not close!\n\nAbsolute difference: 0.0001773834228515625 (up to 1e-06 allowed)\nRelative difference: 3.286301238803055e-05 (up to 0 allowed) : scale a row (logdet non-negative case)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/logdet_test.py",
                        "lineno": 213,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/logdet_test.py",
                        "lineno": 148,
                        "message": "in test"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/logdet_test.py",
                        "lineno": 111,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.logdet_test.TestLinalgXLA testMethod=test_det_logdet_slogdet_xla_float64>, device = 'xla:1', dtype = torch.float64\n\n    @skipCUDAIf(torch.version.cuda is not None\n                and torch.version.cuda.split(\".\") < [\"11\", \"3\"], \"There's a bug in cuSOLVER < 11.3\")\n    # FIXME One of the backends of lu_factor fails in windows. I haven't investigated which or why\n    # https://github.com/pytorch/pytorch/issues/75225\n    # @skipCUDAIfNoCusolver\n    # @skipCPUIfNoLapack\n    @unittest.skipIf(IS_WINDOWS, \"Skipped on Windows!\")\n    @dtypes(torch.double)\n    def test_det_logdet_slogdet(self, device, dtype):\n        def reference_slogdet(M):\n            sdet, logabsdet = np.linalg.slogdet(M.detach().cpu().numpy())\n            return M.new_tensor(sdet), M.new_tensor(logabsdet)\n    \n        def test_single_det(M, target, desc):\n            target_sdet, target_logabsdet = target\n    \n            det = M.det()\n            with pytorch_op_timer():\n                logdet = M.logdet()\n            sdet, logabsdet = M.slogdet()\n            linalg_sdet, linalg_logabsdet = torch.linalg.slogdet(M)\n    \n            # Test det\n            # self.assertEqual(det, target_sdet * target_logabsdet.exp(),\n            #                  atol=1e-6, rtol=0, msg='{} (det)'.format(desc))\n    \n            # Test slogdet\n            # Compare the overall value rather than individual parts because of\n            # precision issues when det is near zero.\n            # self.assertEqual(sdet * logabsdet.exp(), target_sdet * target_logabsdet.exp(),\n            #                  atol=1e-6, rtol=0, msg='{} (slogdet)'.format(desc))\n            # self.assertEqual(linalg_sdet * linalg_logabsdet.exp(), target_sdet * target_logabsdet.exp(),\n            #                  atol=1e-6, rtol=0, msg='{} (linalg_slogdet)'.format(desc))\n    \n            # Test logdet\n            # Compare logdet against our own pytorch slogdet because they should\n            # be consistent, while it may behave slightly differently with other\n            # slogdet implementations when det is near zero due to precision\n            # issues.\n            if sdet.item() < 0:\n                self.assertTrue(logdet.item() != logdet.item(), '{} (logdet negative case)'.format(desc))\n            else:\n                self.assertEqual(logdet.exp(), target_logabsdet.exp(),\n                                 atol=1e-6, rtol=0, msg='{} (logdet non-negative case)'.format(desc))\n    \n        eye = torch.eye(5, dtype=dtype, device=device)\n        test_single_det(eye, (torch.ones((), dtype=dtype, device=device), torch.zeros((), dtype=dtype, device=device)), 'identity')\n        # Testing bug in #34061 (https://github.com/pytorch/pytorch/issues/34061)\n        for n in range(250, 551, 100):\n            mat = torch.randn(n, n, dtype=dtype, device=device)\n            q, _ = torch.qr(mat)\n            ref_det, ref_logabsdet = reference_slogdet(q)\n            test_single_det(q, (ref_det, ref_logabsdet), 'orthogonal')\n    \n        def test(M):\n            assert M.size(0) >= 5, 'this helper fn assumes M to be at least 5x5'\n            M = M.to(device)\n    \n            ref_M_sdet, ref_M_logabsdet = reference_slogdet(M)\n    \n            test_single_det(M, (ref_M_sdet, ref_M_logabsdet), 'basic')\n            if ref_M_logabsdet.exp().item() >= 1e-6:  # skip singular\n                M_inv = M.inverse()\n                test_single_det(M_inv, reference_slogdet(M_inv), 'inverse')\n    \n            test_single_det(M, (ref_M_sdet, ref_M_logabsdet), 'transpose')\n    \n            for x in [0, 2, 4]:\n                for scale in [-2, -0.1, 0, 10]:\n                    if scale > 0:\n                        target = ref_M_sdet, ref_M_logabsdet + math.log(scale)\n                    elif scale == 0:\n                        target = torch.zeros_like(ref_M_sdet), torch.full_like(ref_M_logabsdet, -inf)\n                    else:\n                        target = ref_M_sdet.neg(), ref_M_logabsdet + math.log(-scale)\n    \n                    # dim 0\n                    M_clone = M.clone()\n                    M_clone[:, x] *= scale\n                    test_single_det(M_clone, target, 'scale a row')\n                    # dim 1\n                    M_clone = M.clone()\n                    M_clone[x, :] *= scale\n                    test_single_det(M_clone, target, 'scale a column')\n    \n            for x1, x2 in [(0, 3), (4, 1), (3, 2)]:\n                assert x1 != x2, 'x1 and x2 needs to be different for this test'\n                target = torch.zeros_like(ref_M_sdet), torch.full_like(ref_M_logabsdet, -inf)\n                # dim 0\n                M_clone = M.clone()\n                M_clone[:, x2] = M_clone[:, x1]\n                test_single_det(M_clone, target, 'two rows are same')\n                # dim 1\n                M_clone = M.clone()\n                M_clone[x2, :] = M_clone[x1, :]\n                test_single_det(M_clone, target, 'two columns are same')\n    \n                for scale1, scale2 in [(0.3, -1), (0, 2), (10, 0.1)]:\n                    det_scale = scale1 * scale2 * -1\n                    if det_scale > 0:\n                        target = ref_M_sdet, ref_M_logabsdet + math.log(det_scale)\n                    elif det_scale == 0:\n                        target = torch.zeros_like(ref_M_sdet), torch.full_like(ref_M_logabsdet, -inf)\n                    else:\n                        target = ref_M_sdet.neg(), ref_M_logabsdet + math.log(-det_scale)\n    \n                    # dim 0\n                    M_clone = M.clone()\n                    t = M_clone[:, x1] * scale1\n                    M_clone[:, x1] += M_clone[:, x2] * scale2\n                    M_clone[:, x2] = t\n                    test_single_det(M_clone, target, 'exchanging rows')\n                    # dim 1\n                    M_clone = M.clone()\n                    t = M_clone[x1, :] * scale1\n                    M_clone[x1, :] += M_clone[x2, :] * scale2\n                    M_clone[x2, :] = t\n                    test_single_det(M_clone, target, 'exchanging columns')\n    \n        def get_random_mat_scale(n):\n            # For matrices with values i.i.d. with 0 mean, unit variance, and\n            # subexponential tail, we have:\n            #   E[log det(A^2)] \\approx log((n-1)!)\n            #\n            # Notice:\n            #   log Var[det(A)] = log E[det(A^2)] >= E[log det(A^2)]\n            #\n            # So:\n            #   stddev[det(A)] >= sqrt( (n-1)! )\n            #\n            # We use this as an intuitive guideline to scale random generated\n            # matrices so our closeness tests can work more robustly:\n            #   scale by sqrt( (n-1)! )^(-1/n) = ( (n-1)! )^(-1/(2n))\n            #\n            # source: https://arxiv.org/pdf/1112.0752.pdf\n    \n            # TODO: technically we need subexponential distn for this to hold,\n            #       but we mostly use gaussian entries below. Consider switching\n            #       to Chi-sq if this turns out not stable enough, since Chi-sq\n            #       is easy enough to sample from.\n            return math.factorial(n - 1) ** (-1.0 / (2 * n))\n    \n        for n in [5, 10, 25]:\n            scale = get_random_mat_scale(n)\n>           test(torch.randn(n, n, dtype=dtype, device=device) * scale)\n\nsrc/pytorch_tests_reduced/logdet_test.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/logdet_test.py:148: in test\n    test_single_det(M_clone, target, 'scale a row')\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nM = tensor([[-0.5886, -0.6797,  0.3379,  0.3322,  0.6921],\n        [ 1.7295, -0.3013, -0.6385, -1.2301,  0.5146],\n        ...  0.3483,  0.1877],\n        [-1.1505,  0.3019, -0.3632,  1.6163,  1.1181]], device='xla:1',\n       dtype=torch.float64)\ntarget = (tensor(1., device='xla:1', dtype=torch.float64), tensor(1.6860, device='xla:1', dtype=torch.float64)), desc = 'scale a row'\n\n    def test_single_det(M, target, desc):\n        target_sdet, target_logabsdet = target\n    \n        det = M.det()\n        with pytorch_op_timer():\n            logdet = M.logdet()\n        sdet, logabsdet = M.slogdet()\n        linalg_sdet, linalg_logabsdet = torch.linalg.slogdet(M)\n    \n        # Test det\n        # self.assertEqual(det, target_sdet * target_logabsdet.exp(),\n        #                  atol=1e-6, rtol=0, msg='{} (det)'.format(desc))\n    \n        # Test slogdet\n        # Compare the overall value rather than individual parts because of\n        # precision issues when det is near zero.\n        # self.assertEqual(sdet * logabsdet.exp(), target_sdet * target_logabsdet.exp(),\n        #                  atol=1e-6, rtol=0, msg='{} (slogdet)'.format(desc))\n        # self.assertEqual(linalg_sdet * linalg_logabsdet.exp(), target_sdet * target_logabsdet.exp(),\n        #                  atol=1e-6, rtol=0, msg='{} (linalg_slogdet)'.format(desc))\n    \n        # Test logdet\n        # Compare logdet against our own pytorch slogdet because they should\n        # be consistent, while it may behave slightly differently with other\n        # slogdet implementations when det is near zero due to precision\n        # issues.\n        if sdet.item() < 0:\n            self.assertTrue(logdet.item() != logdet.item(), '{} (logdet negative case)'.format(desc))\n        else:\n>           self.assertEqual(logdet.exp(), target_logabsdet.exp(),\n                             atol=1e-6, rtol=0, msg='{} (logdet non-negative case)'.format(desc))\nE           AssertionError: Scalars are not close!\nE           \nE           Absolute difference: 0.0001773834228515625 (up to 1e-06 allowed)\nE           Relative difference: 3.286301238803055e-05 (up to 0 allowed) : scale a row (logdet non-negative case)\n\nsrc/pytorch_tests_reduced/logdet_test.py:111: AssertionError"
            },
            "teardown": {
                "duration": 0.0002607480000733631,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNDeviceTypeCPU::test_lstmcell_backward_only_one_output_grad_cpu_float64",
            "lineno": 161,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00048177400003623916,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007452019999618642,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/lstmcell_test.py', 162, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00017237399970326805,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNDeviceTypeXLA::test_lstmcell_backward_only_one_output_grad_xla_float64",
            "lineno": 161,
            "outcome": "passed",
            "setup": {
                "duration": 0.0018535170001996448,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.2506008370000927,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000252267000178108,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU::test_LSTM_cell_cpu",
            "lineno": 120,
            "outcome": "passed",
            "setup": {
                "duration": 0.00046721199942112435,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.005056511000475439,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015742499999760184,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU::test_LSTM_cell_forward_hidden_size_cpu",
            "lineno": 146,
            "outcome": "passed",
            "setup": {
                "duration": 0.00032706699948903406,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.009033348999764712,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012317200071265688,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU::test_LSTM_cell_forward_input_size_cpu",
            "lineno": 136,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028287500026635826,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00484371899983671,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011300499954813858,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNCPU::test_RNN_cell_no_broadcasting_cpu",
            "lineno": 91,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002701879993765033,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.024215161000029184,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016345899985026335,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA::test_LSTM_cell_forward_hidden_size_xla",
            "lineno": 146,
            "outcome": "passed",
            "setup": {
                "duration": 0.0018244550001327298,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.13484285899994575,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017559700063429773,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA::test_LSTM_cell_forward_input_size_xla",
            "lineno": 136,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003583369998523267,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.12726630099950853,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001675160001468612,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA::test_LSTM_cell_xla",
            "lineno": 120,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039661000027990667,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.2889173980001942,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017590199968253728,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lstmcell_test.py::TestNNXLA::test_RNN_cell_no_broadcasting_xla",
            "lineno": 91,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036556499981088564,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.1443679969997902,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00024854399998730514,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossCPU::test_lt_cpu",
            "lineno": 46,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004877929995927843,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0013759749999735504,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014318400008050958,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossCPU::test_lt_scalar_cpu",
            "lineno": 61,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028343000030872645,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009663509999882081,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001699620006547775,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossXLA::test_lt_scalar_xla",
            "lineno": 61,
            "outcome": "passed",
            "setup": {
                "duration": 0.0018120810000255005,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03831417799938208,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001344779993814882,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/lt_test.py::TestNLLLossXLA::test_lt_xla",
            "lineno": 46,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033102799989137566,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.024468990999594098,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018173799981013872,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_cpu_complex128",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039595699945493834,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.031039047999911418,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011979299961240031,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_cpu_complex64",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002888890003305278,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.028278423999836377,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015125499976420542,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_cpu_float32",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.00029980299950693734,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.026673643000322045,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015467699995497242,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_cpu_float64",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.000361157000043022,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.025695500999972865,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011696900037350133,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_atol_rtol_cpu_float64",
            "lineno": 138,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002803819998007384,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0024152109999704408,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015269999948941404,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_basic_cpu_complex128",
            "lineno": 247,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036852099947282113,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0016039000001910608,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011488100062706508,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_basic_cpu_complex64",
            "lineno": 247,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002837820002241642,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0014922850004950305,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012975200024811784,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_basic_cpu_float32",
            "lineno": 247,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027440799931355286,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0014484349994745571,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011601500045799185,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_basic_cpu_float64",
            "lineno": 247,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027571700047701597,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0015571919993817573,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015870800052653067,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_cpu_complex128",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003490009994493448,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.022964477000641637,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019129600059386576,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_cpu_complex64",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003856570001516957,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02425612600018212,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001665029994910583,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_cpu_float32",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003787280002143234,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.023531273999651603,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016824900012579747,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_cpu_float64",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003888360006385483,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.022744109999621287,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016158699963852996,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_empty_cpu_complex128",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039561700032209046,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.018853620999834675,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011280899980192771,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_empty_cpu_complex64",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.00032733399984863354,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.016373254999962228,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012056000014126766,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_empty_cpu_float32",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027533999946172116,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01600182099991798,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012310399961279472,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_empty_cpu_float64",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026910699943982763,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.015129481000258238,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001160849997177138,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_out_errors_and_warnings_cpu_complex128",
            "lineno": 219,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034443500044289976,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.004584339999382792,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011671599986584624,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_out_errors_and_warnings_cpu_complex64",
            "lineno": 219,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002764920000117854,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0037872129996685544,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013319099980435567,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_out_errors_and_warnings_cpu_float32",
            "lineno": 219,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003147139996144688,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0039720029999443796,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011628399988694582,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgCPU::test_matrix_rank_out_errors_and_warnings_cpu_float64",
            "lineno": 219,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027011000020138454,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.003784803000598913,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003964140005336958,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_rtol_xla_float64",
            "lineno": 138,
            "outcome": "passed",
            "setup": {
                "duration": 0.001782293999895046,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.32266243699996267,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020295800004532794,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_xla_complex128",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.000394691999645147,
                "outcome": "passed"
            },
            "call": {
                "duration": 20.53025729500041,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00023290799981623422,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_xla_complex64",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004932840001856675,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.40467438799987576,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019597000027715694,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_xla_float32",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004458169996723882,
                "outcome": "passed"
            },
            "call": {
                "duration": 19.034033726000416,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002464179997332394,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_atol_xla_float64",
            "lineno": 107,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004838820004806621,
                "outcome": "passed"
            },
            "call": {
                "duration": 19.488440753999384,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00021465099962370005,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_basic_xla_complex128",
            "lineno": 247,
            "outcome": "failed",
            "setup": {
                "duration": 0.00044274499941820977,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.23083492499972635,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/matrix_rank_test.py",
                    "lineno": 263,
                    "message": "AssertionError: Scalars are not equal!\n\nAbsolute difference: 1\nRelative difference: 0.1111111111111111"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/matrix_rank_test.py",
                        "lineno": 263,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.matrix_rank_test.TestLinalgXLA testMethod=test_matrix_rank_basic_xla_complex128>, device = 'xla:1'\ndtype = torch.complex128\n\n    @dtypes(*floating_and_complex_types())\n    def test_matrix_rank_basic(self, device, dtype):\n        matrix_rank = torch.linalg.matrix_rank\n    \n        a = torch.eye(10, dtype=dtype, device=device)\n        with pytorch_op_timer():\n            test_1 = matrix_rank(a).item()\n        with pytorch_op_timer():\n            test_2 = matrix_rank(a, hermitian=True).item()\n        self.assertEqual(test_1, 10)\n        self.assertEqual(test_2, 10)\n    \n        a[5, 5] = 0\n        with pytorch_op_timer():\n            test_3 = matrix_rank(a).item()\n>       self.assertEqual(test_3, 9)\nE       AssertionError: Scalars are not equal!\nE       \nE       Absolute difference: 1\nE       Relative difference: 0.1111111111111111\n\nsrc/pytorch_tests_reduced/matrix_rank_test.py:263: AssertionError"
            },
            "teardown": {
                "duration": 0.00019976499970653094,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_basic_xla_complex64",
            "lineno": 247,
            "outcome": "failed",
            "setup": {
                "duration": 0.00035396000021137297,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.02022739600033674,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/matrix_rank_test.py",
                    "lineno": 263,
                    "message": "AssertionError: Scalars are not equal!\n\nAbsolute difference: 1\nRelative difference: 0.1111111111111111"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/matrix_rank_test.py",
                        "lineno": 263,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.matrix_rank_test.TestLinalgXLA testMethod=test_matrix_rank_basic_xla_complex64>, device = 'xla:1'\ndtype = torch.complex64\n\n    @dtypes(*floating_and_complex_types())\n    def test_matrix_rank_basic(self, device, dtype):\n        matrix_rank = torch.linalg.matrix_rank\n    \n        a = torch.eye(10, dtype=dtype, device=device)\n        with pytorch_op_timer():\n            test_1 = matrix_rank(a).item()\n        with pytorch_op_timer():\n            test_2 = matrix_rank(a, hermitian=True).item()\n        self.assertEqual(test_1, 10)\n        self.assertEqual(test_2, 10)\n    \n        a[5, 5] = 0\n        with pytorch_op_timer():\n            test_3 = matrix_rank(a).item()\n>       self.assertEqual(test_3, 9)\nE       AssertionError: Scalars are not equal!\nE       \nE       Absolute difference: 1\nE       Relative difference: 0.1111111111111111\n\nsrc/pytorch_tests_reduced/matrix_rank_test.py:263: AssertionError"
            },
            "teardown": {
                "duration": 0.00016953500016825274,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_basic_xla_float32",
            "lineno": 247,
            "outcome": "failed",
            "setup": {
                "duration": 0.00036726300004374934,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.11784653599988815,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/matrix_rank_test.py",
                    "lineno": 263,
                    "message": "AssertionError: Scalars are not equal!\n\nAbsolute difference: 1\nRelative difference: 0.1111111111111111"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/matrix_rank_test.py",
                        "lineno": 263,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.matrix_rank_test.TestLinalgXLA testMethod=test_matrix_rank_basic_xla_float32>, device = 'xla:1'\ndtype = torch.float32\n\n    @dtypes(*floating_and_complex_types())\n    def test_matrix_rank_basic(self, device, dtype):\n        matrix_rank = torch.linalg.matrix_rank\n    \n        a = torch.eye(10, dtype=dtype, device=device)\n        with pytorch_op_timer():\n            test_1 = matrix_rank(a).item()\n        with pytorch_op_timer():\n            test_2 = matrix_rank(a, hermitian=True).item()\n        self.assertEqual(test_1, 10)\n        self.assertEqual(test_2, 10)\n    \n        a[5, 5] = 0\n        with pytorch_op_timer():\n            test_3 = matrix_rank(a).item()\n>       self.assertEqual(test_3, 9)\nE       AssertionError: Scalars are not equal!\nE       \nE       Absolute difference: 1\nE       Relative difference: 0.1111111111111111\n\nsrc/pytorch_tests_reduced/matrix_rank_test.py:263: AssertionError"
            },
            "teardown": {
                "duration": 0.00018421000004309462,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_basic_xla_float64",
            "lineno": 247,
            "outcome": "failed",
            "setup": {
                "duration": 0.00036771500072063645,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.019513143000040145,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/matrix_rank_test.py",
                    "lineno": 263,
                    "message": "AssertionError: Scalars are not equal!\n\nAbsolute difference: 1\nRelative difference: 0.1111111111111111"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/matrix_rank_test.py",
                        "lineno": 263,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.matrix_rank_test.TestLinalgXLA testMethod=test_matrix_rank_basic_xla_float64>, device = 'xla:1'\ndtype = torch.float64\n\n    @dtypes(*floating_and_complex_types())\n    def test_matrix_rank_basic(self, device, dtype):\n        matrix_rank = torch.linalg.matrix_rank\n    \n        a = torch.eye(10, dtype=dtype, device=device)\n        with pytorch_op_timer():\n            test_1 = matrix_rank(a).item()\n        with pytorch_op_timer():\n            test_2 = matrix_rank(a, hermitian=True).item()\n        self.assertEqual(test_1, 10)\n        self.assertEqual(test_2, 10)\n    \n        a[5, 5] = 0\n        with pytorch_op_timer():\n            test_3 = matrix_rank(a).item()\n>       self.assertEqual(test_3, 9)\nE       AssertionError: Scalars are not equal!\nE       \nE       Absolute difference: 1\nE       Relative difference: 0.1111111111111111\n\nsrc/pytorch_tests_reduced/matrix_rank_test.py:263: AssertionError"
            },
            "teardown": {
                "duration": 0.00016534699989279034,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_empty_xla_complex128",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.000391764000596595,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.8210464579997279,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018084499970427714,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_empty_xla_complex64",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003957520002586534,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.3496062479998727,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001786840002750978,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_empty_xla_float32",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.00040437200004816987,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.3221236810004484,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019944300038332585,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_empty_xla_float64",
            "lineno": 168,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004524329997366294,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.305179474000397,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016991000029520364,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_out_errors_and_warnings_xla_complex128",
            "lineno": 219,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039930799994181143,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.08233644999927492,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015140699997573392,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_out_errors_and_warnings_xla_complex64",
            "lineno": 219,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039859299977251794,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.009570125000209373,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012654100009967806,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_out_errors_and_warnings_xla_float32",
            "lineno": 219,
            "outcome": "passed",
            "setup": {
                "duration": 0.00030839400005788775,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06753695200040966,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015938499927869998,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_out_errors_and_warnings_xla_float64",
            "lineno": 219,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003532029995767516,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00840659100049379,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013248800041765207,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_xla_complex128",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003881329994328553,
                "outcome": "passed"
            },
            "call": {
                "duration": 2.3498835020000115,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001849529999162769,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_xla_complex64",
            "lineno": 47,
            "outcome": "failed",
            "setup": {
                "duration": 0.000394224000046961,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.04508047000035731,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/matrix_rank_test.py",
                    "lineno": 72,
                    "message": "AssertionError: Scalars are not equal!\n\nAbsolute difference: 10\nRelative difference: 0.7692307692307693"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/matrix_rank_test.py",
                        "lineno": 104,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/matrix_rank_test.py",
                        "lineno": 72,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.matrix_rank_test.TestLinalgXLA testMethod=test_matrix_rank_xla_complex64>, device = 'xla:1', dtype = torch.complex64\n\n    @dtypes(*floating_and_complex_types())\n    def test_matrix_rank(self, device, dtype):\n        matrix_rank = torch.linalg.matrix_rank\n    \n        def run_test(shape0, shape1, batch):\n            a = torch.randn(*batch, shape0, shape1, dtype=dtype, device=device)\n            with pytorch_op_timer():\n                rank_a = matrix_rank(a)\n    \n            with pytorch_op_timer():\n                test_1 = matrix_rank(a.mH)\n            self.assertEqual(rank_a, test_1)\n            aaH = torch.matmul(a, a.mH)\n            with pytorch_op_timer():\n                rank_aaH = matrix_rank(aaH)\n            with pytorch_op_timer():\n                rank_aaH_hermitian = matrix_rank(aaH, hermitian=True)\n            self.assertEqual(rank_aaH, rank_aaH_hermitian)\n            aHa = torch.matmul(a.mH, a)\n    \n            with pytorch_op_timer():\n                test_2 = matrix_rank(aHa)\n            with pytorch_op_timer():\n                test_3 = matrix_rank(aHa, hermitian=True)\n            self.assertEqual(test_2, test_3)\n    \n            # check against NumPy\n            self.assertEqual(rank_a, np.linalg.matrix_rank(a.cpu().numpy()))\n            with pytorch_op_timer():\n                test_4 = matrix_rank(a, 0.01)\n            self.assertEqual(test_4, np.linalg.matrix_rank(a.cpu().numpy(), 0.01))\n    \n            self.assertEqual(rank_aaH, np.linalg.matrix_rank(aaH.cpu().numpy()))\n            with pytorch_op_timer():\n                test_5 = matrix_rank(aaH, 0.01)\n            self.assertEqual(test_5, np.linalg.matrix_rank(aaH.cpu().numpy(), 0.01))\n    \n            # hermitian flag for NumPy was added in 1.14.0\n            if np.lib.NumpyVersion(np.__version__) >= '1.14.0':\n                self.assertEqual(rank_aaH_hermitian,\n                                 np.linalg.matrix_rank(aaH.cpu().numpy(), hermitian=True))\n                with pytorch_op_timer():\n                    test_6 = matrix_rank(aaH, 0.01, True)\n                self.assertEqual(test_6,\n                                 np.linalg.matrix_rank(aaH.cpu().numpy(), 0.01, True))\n    \n            # check out= variant\n            out = torch.empty(a.shape[:-2], dtype=torch.int64, device=device)\n            with pytorch_op_timer():\n                ans = matrix_rank(a, out=out)\n            self.assertEqual(ans, out)\n            self.assertEqual(ans, rank_a)\n    \n        shapes = (3, 13)\n        batches = ((), (0, ), (4, ), (3, 5, ))\n        for (shape0, shape1), batch in zip(itertools.product(shapes, reversed(shapes)), batches):\n>           run_test(shape0, shape1, batch)\n\nsrc/pytorch_tests_reduced/matrix_rank_test.py:104: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape0 = 3, shape1 = 13, batch = ()\n\n    def run_test(shape0, shape1, batch):\n        a = torch.randn(*batch, shape0, shape1, dtype=dtype, device=device)\n        with pytorch_op_timer():\n            rank_a = matrix_rank(a)\n    \n        with pytorch_op_timer():\n            test_1 = matrix_rank(a.mH)\n        self.assertEqual(rank_a, test_1)\n        aaH = torch.matmul(a, a.mH)\n        with pytorch_op_timer():\n            rank_aaH = matrix_rank(aaH)\n        with pytorch_op_timer():\n            rank_aaH_hermitian = matrix_rank(aaH, hermitian=True)\n        self.assertEqual(rank_aaH, rank_aaH_hermitian)\n        aHa = torch.matmul(a.mH, a)\n    \n        with pytorch_op_timer():\n            test_2 = matrix_rank(aHa)\n        with pytorch_op_timer():\n            test_3 = matrix_rank(aHa, hermitian=True)\n>       self.assertEqual(test_2, test_3)\nE       AssertionError: Scalars are not equal!\nE       \nE       Absolute difference: 10\nE       Relative difference: 0.7692307692307693\n\nsrc/pytorch_tests_reduced/matrix_rank_test.py:72: AssertionError"
            },
            "teardown": {
                "duration": 0.00014496099993266398,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_xla_float32",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.00032184100018639583,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.613322058000449,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00025494500005152076,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/matrix_rank_test.py::TestLinalgXLA::test_matrix_rank_xla_float64",
            "lineno": 47,
            "outcome": "passed",
            "setup": {
                "duration": 0.00042134700015594717,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.2913091059999715,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00045042799956718227,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_cpu_complex128",
            "lineno": 88,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004849660008403589,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06860773800053721,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015514200003963197,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_cpu_float32",
            "lineno": 88,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003344569995533675,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06079746300019906,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001306509993810323,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_cpu_int64",
            "lineno": 88,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002690880000955076,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03216354400046839,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011771500066970475,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_invalid_cpu_complex128",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002787789999274537,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.061178541999652225,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011387799986550817,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_invalid_cpu_float32",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002700889999687206,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.059969107000142685,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011966400052187964,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsCPU::test_movedim_invalid_cpu_int64",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002735660000325879,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.059762257000329555,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018327300040255068,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_invalid_xla_complex128",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.0019905049994122237,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.08706391399937274,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012482199963415042,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_invalid_xla_float32",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.00035149399991496466,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06609417599975131,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011774700033129193,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_invalid_xla_int64",
            "lineno": 59,
            "outcome": "passed",
            "setup": {
                "duration": 0.00029313300001376774,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06288779699934821,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012099299965484533,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_xla_complex128",
            "lineno": 88,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003641860002971953,
                "outcome": "passed"
            },
            "call": {
                "duration": 4.04399482000008,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020792500072275288,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_xla_float32",
            "lineno": 88,
            "outcome": "passed",
            "setup": {
                "duration": 0.00041497000074741663,
                "outcome": "passed"
            },
            "call": {
                "duration": 3.121680111000387,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00021087400000396883,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/moveaxis_test.py::TestShapeOpsXLA::test_movedim_xla_int64",
            "lineno": 88,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003847680000035325,
                "outcome": "passed"
            },
            "call": {
                "duration": 21.889475537999715,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003416819999984,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestNumericalStabilityCPU::test_multinomial_log_prob_with_logits_cpu",
            "lineno": 191,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004914399996778229,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.004498887000409013,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00021211300008872058,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestNumericalStabilityXLA::test_multinomial_log_prob_with_logits_xla",
            "lineno": 191,
            "outcome": "passed",
            "setup": {
                "duration": 0.001528752999547578,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.6895330459992692,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00032093200024974067,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsCPU::test_multinomial_1d_cpu",
            "lineno": 104,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004797100000359933,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.013122868000209564,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012997499925404554,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsCPU::test_multinomial_1d_log_prob_and_entropy_cpu",
            "lineno": 122,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00030764799976168433,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0002999090002049343,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/multinomial_test.py', 123, 'Skipped: NumPy not found')"
            },
            "teardown": {
                "duration": 0.000164416000188794,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsCPU::test_multinomial_2d_cpu",
            "lineno": 144,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003527569997459068,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.012550047999866365,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018004100002144696,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsXLA::test_multinomial_1d_log_prob_and_entropy_xla",
            "lineno": 122,
            "outcome": "skipped",
            "setup": {
                "duration": 0.002000941000005696,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00023142800000641728,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/multinomial_test.py', 123, 'Skipped: NumPy not found')"
            },
            "teardown": {
                "duration": 0.00013653800033353036,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsXLA::test_multinomial_1d_xla",
            "lineno": 104,
            "outcome": "failed",
            "setup": {
                "duration": 0.0002846890001819702,
                "outcome": "passed"
            },
            "call": {
                "duration": 3.81494838099934,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                    "lineno": 1280,
                    "message": "torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor(-0.9537, device='xla:1')\nanalytical:tensor(-0.8931, device='xla:1')\n\nThe above quantities relating the numerical and analytical jacobians are computed \nin fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nabout fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\n\nNumerical:\n tensor([[ 3.3507],\n        [-1.6570],\n        [-0.0129]], device='xla:1')\nAnalytical:\ntensor([[ 3.3333e+00],\n        [-1.6667e+00],\n        [ 1.9073e-06]], device='xla:1')\n\nThe max per-element difference (slow mode) is: 0.017398595809936523."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/multinomial_test.py",
                        "lineno": 118,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/multinomial_test.py",
                        "lineno": 102,
                        "message": "in _gradcheck_log_prob"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 3019,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1414,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1428,
                        "message": "in _gradcheck_helper"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1075,
                        "message": "in _gradcheck_real_imag"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1307,
                        "message": "in _fast_gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1280,
                        "message": "GradcheckError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.multinomial_test.TestDistributionsXLA testMethod=test_multinomial_1d_xla>, device = 'xla:1'\n\n    def test_multinomial_1d(self, device):\n        torch.set_default_dtype(torch.double)\n        total_count = 10\n        p = torch.tensor([0.1, 0.2, 0.3], requires_grad=True, device=device)\n        with pytorch_op_timer():\n            test_1 = Multinomial(total_count, p).sample().size()\n        self.assertEqual(test_1, (3,))\n        with pytorch_op_timer():\n            test_2 = Multinomial(total_count, p).sample((2, 2)).size()\n        self.assertEqual(test_2, (2, 2, 3))\n        with pytorch_op_timer():\n            test_3 = Multinomial(total_count, p).sample((1,)).size()\n        self.assertEqual(test_3, (1, 3))\n>       self._gradcheck_log_prob(lambda p: Multinomial(total_count, p), [p])\n\nsrc/pytorch_tests_reduced/multinomial_test.py:118: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/multinomial_test.py:102: in _gradcheck_log_prob\n    gradcheck(apply_fn, (s,) + tuple(ctor_params), raise_exception=True)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:3019: in gradcheck\n    return torch.autograd.gradcheck(fn, inputs, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1414: in gradcheck\n    return _gradcheck_helper(**args)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1428: in _gradcheck_helper\n    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1075: in _gradcheck_real_imag\n    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1307: in _fast_gradcheck\n    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nall_analytical = [[tensor(-0.8931, device='xla:1')]], all_numerical = [[tensor(-0.9537, device='xla:1')]], complex_indices = None\ntupled_inputs = (tensor([2., 3., 5.], device='xla:1'), tensor([0.1000, 0.2000, 0.3000], device='xla:1', requires_grad=True))\noutputs = (tensor(-2.5133, device='xla:1', grad_fn=<AddBackward0>),)\nfunc = <function TestDistributions._gradcheck_log_prob.<locals>.apply_fn at 0x7fcdd39d7c10>, all_v = [tensor([1.], device='xla:1')]\nall_u = [tensor([0.1828, 0.9015, 0.3923], device='xla:1')], rtol = 0.001, atol = 1e-05, test_imag = False\n\n    def _check_analytical_numerical_equal(all_analytical, all_numerical, complex_indices, tupled_inputs, outputs,\n                                          func, all_v, all_u, rtol, atol, test_imag, *, is_forward_ad=False):\n        for i, all_numerical_for_input_i in enumerate(all_numerical):\n            for j, n in enumerate(all_numerical_for_input_i):\n                # Forward AD generates the transpose of what this function expects\n                if is_forward_ad:\n                    a = all_analytical[i][j]\n                else:\n                    a = all_analytical[j][i]\n                n = n.to(device=a.device)\n                updated_atol = _adjusted_atol(atol, all_u[i], all_v[j] if all_v else None)\n                if not _allclose_with_type_promotion(a, n.to(a.device), rtol, updated_atol):\n                    jacobians_str = _run_slow_mode_and_get_error(func, tupled_inputs, outputs, i, j, rtol, atol, is_forward_ad)\n>                   raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)\nE                   torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nE                   numerical:tensor(-0.9537, device='xla:1')\nE                   analytical:tensor(-0.8931, device='xla:1')\nE                   \nE                   The above quantities relating the numerical and analytical jacobians are computed \nE                   in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nE                   about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\nE                   \nE                   Numerical:\nE                    tensor([[ 3.3507],\nE                           [-1.6570],\nE                           [-0.0129]], device='xla:1')\nE                   Analytical:\nE                   tensor([[ 3.3333e+00],\nE                           [-1.6667e+00],\nE                           [ 1.9073e-06]], device='xla:1')\nE                   \nE                   The max per-element difference (slow mode) is: 0.017398595809936523.\n\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1280: GradcheckError"
            },
            "teardown": {
                "duration": 0.00026551299924904015,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionsXLA::test_multinomial_2d_xla",
            "lineno": 144,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003785599992625066,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.07828915899972344,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022353399981511757,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionShapesCPU::test_multinomial_shape_cpu",
            "lineno": 171,
            "outcome": "passed",
            "setup": {
                "duration": 0.00042601899986038916,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0021372390001488384,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001408870002705953,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/multinomial_test.py::TestDistributionShapesXLA::test_multinomial_shape_xla",
            "lineno": 171,
            "outcome": "passed",
            "setup": {
                "duration": 0.002394578999883379,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.40417912600059935,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00025682900013634935,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_cpu_complex128",
            "lineno": 67,
            "outcome": "passed",
            "setup": {
                "duration": 0.00046669499988638563,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.14389649999975518,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00023071600026014494,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_cpu_complex64",
            "lineno": 67,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004514029997153557,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.16236434700022073,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002068129997496726,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_cpu_float32",
            "lineno": 67,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003987889995187288,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.1295339469997998,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001736289996188134,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_cpu_float64",
            "lineno": 67,
            "outcome": "passed",
            "setup": {
                "duration": 0.000420438000219292,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.12769167799979186,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018180000006395858,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_errors_and_warnings_cpu_complex128",
            "lineno": 116,
            "outcome": "passed",
            "setup": {
                "duration": 0.00042909900002996437,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03835872499985271,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013312800001585856,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_errors_and_warnings_cpu_complex64",
            "lineno": 116,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034912099999928614,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03573214799962443,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014945000020816224,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_errors_and_warnings_cpu_float32",
            "lineno": 116,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003701370005728677,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03543208399969444,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011990900020464323,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgCPU::test_ormqr_errors_and_warnings_cpu_float64",
            "lineno": 116,
            "outcome": "passed",
            "setup": {
                "duration": 0.00030081999921094393,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03548577900073724,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022924399945623009,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_errors_and_warnings_xla_complex128",
            "lineno": 116,
            "outcome": "passed",
            "setup": {
                "duration": 0.0027779390002251603,
                "outcome": "passed"
            },
            "call": {
                "duration": 2.779350273000091,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003198390004399698,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_errors_and_warnings_xla_complex64",
            "lineno": 116,
            "outcome": "passed",
            "setup": {
                "duration": 0.000543054999980086,
                "outcome": "passed"
            },
            "call": {
                "duration": 7.267584643000191,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00029499500033125514,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_errors_and_warnings_xla_float32",
            "lineno": 116,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004896680002275389,
                "outcome": "passed"
            },
            "call": {
                "duration": 3.8522282039994025,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00028823399952671025,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_errors_and_warnings_xla_float64",
            "lineno": 116,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005262920003588079,
                "outcome": "passed"
            },
            "call": {
                "duration": 4.714312444000825,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002865610003937036,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_xla_complex128",
            "lineno": 67,
            "outcome": "failed",
            "setup": {
                "duration": 0.0005422529993666103,
                "outcome": "passed"
            },
            "call": {
                "duration": 2.7145855979997577,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/ormqr_test.py",
                    "lineno": 88,
                    "message": "RuntimeError: Comparing\n\nTensorOrArrayPair(\n    id=(),\n    actual=tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\n           7.8461-4.6431j],\n        [ -8.5251-6.8409j,  -1.0120-4.6169j,  -5.1341+1.3247j,  -5.6286-6.1405j,\n          -0.2531-7.5523j],\n        [ -2.4844+6.4225j,   5.9277-0.3956j,   2.1676-5.7796j,  -3.6696+3.1946j,\n          -2.7297+2.2063j],\n        [  3.5039-9.3657j,   4.3676-3.4608j,  10.2168+7.4772j,  -6.6466-1.4621j,\n          -2.7231+2.7202j],\n        [  0.6307+0.7053j,  11.6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\n         -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128),\n    expected=tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\n           7.8461-4.6431j],\n        [ -8.5251-6.8409j,  -1.0120-4.6169j,  -5.1341+1.3247j,  -5.6286-6.1405j,\n          -0.2531-7.5523j],\n        [ -2.4844+6.4225j,   5.9277-0.3956j,   2.1676-5.7796j,  -3.6696+3.1946j,\n          -2.7297+2.2063j],\n        [  3.5039-9.3657j,   4.3676-3.4608j,  10.2168+7.4772j,  -6.6466-1.4621j,\n          -2.7231+2.7202j],\n        [  0.6307+0.7053j,  11.6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\n         -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128),\n    rtol=1e-07,\n    atol=1e-07,\n    equal_nan=True,\n    check_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\nresulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/ormqr_test.py",
                        "lineno": 115,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/ormqr_test.py",
                        "lineno": 88,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "actual = tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\n           7.8461-4.6431j],\n        [....6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\n         -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128)\nexpected = tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\n           7.8461-4.6431j],\n        [....6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\n         -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128)\npair_types = (<class 'torch.testing._comparison.NonePair'>, <class 'torch.testing._internal.common_utils.RelaxedBooleanPair'>, <cla...<class 'torch.testing._internal.common_utils.StringPair'>, <class 'torch.testing._internal.common_utils.SetPair'>, ...)\nsequence_types = (<class 'collections.abc.Sequence'>, <class 'torch.storage._TypedStorage'>, <class 'torch.nn.modules.container.Sequent...nn.modules.container.ModuleList'>, <class 'torch.nn.modules.container.ParameterList'>, <class 'torch.ScriptList'>, ...)\nmapping_types = (<class 'collections.abc.Mapping'>, <class 'torch.nn.modules.container.ModuleDict'>, <class 'torch.nn.modules.container.ParameterDict'>, <class 'torch.ScriptDict'>)\nmsg = None, options = {'atol': None, 'atol_override': 0, 'check_device': False, 'check_dtype': True, ...}, __tracebackhide__ = True\npairs = [TensorOrArrayPair(\n    id=(),\n    actual=tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.34...ck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)]\n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n>               pair.compare()\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1075: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.345...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\n    def compare(self) -> None:\n        actual, expected = self.actual, self.expected\n    \n        self._compare_attributes(actual, expected)\n        if any(input.device.type == \"meta\" for input in (actual, expected)):\n            return\n    \n        actual, expected = self._equalize_attributes(actual, expected)\n>       self._compare_values(actual, expected)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:620: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.345...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\n           7.8461-4.6431j],\n        [....6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\n         -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128)\nexpected = tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\n           7.8461-4.6431j],\n        [....6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\n         -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128)\n\n    def _compare_values(self, actual: torch.Tensor, expected: torch.Tensor) -> None:\n        if actual.is_quantized:\n            compare_fn = self._compare_quantized_values\n        elif actual.is_sparse:\n            compare_fn = self._compare_sparse_coo_values\n        elif actual.layout in {torch.sparse_csr, torch.sparse_csc, torch.sparse_bsr, torch.sparse_bsc}:\n            compare_fn = self._compare_sparse_compressed_values\n        else:\n            compare_fn = self._compare_regular_values_close\n    \n>       compare_fn(actual, expected, rtol=self.rtol, atol=self.atol, equal_nan=self.equal_nan)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:714: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.345...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\n           7.8461-4.6431j],\n        [....6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\n         -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128)\nexpected = tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\n           7.8461-4.6431j],\n        [....6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\n         -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128)\n\n    def _compare_regular_values_close(\n        self,\n        actual: torch.Tensor,\n        expected: torch.Tensor,\n        *,\n        rtol: float,\n        atol: float,\n        equal_nan: bool,\n        identifier: Optional[Union[str, Callable[[str], str]]] = None,\n    ) -> None:\n        \"\"\"Checks if the values of two tensors are close up to a desired tolerance.\"\"\"\n        actual, expected = self._promote_for_comparison(actual, expected)\n        matches = torch.isclose(actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan)\n>       if torch.all(matches):\nE       RuntimeError: Error while lowering: [] aten::isnan\nE       XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE       Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:847: RuntimeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <src.pytorch_tests_reduced.ormqr_test.TestLinalgXLA testMethod=test_ormqr_xla_complex128>, device = 'xla:1', dtype = torch.complex128\n\n    @skipCPUIfNoLapack\n    @skipCUDAIfNoCusolver\n    @dtypes(*floating_and_complex_types())\n    def test_ormqr(self, device, dtype):\n    \n        def run_test(batch, m, n, fortran_contiguous):\n            A = make_tensor((*batch, m, n), dtype=dtype, device=device)\n            reflectors, tau = torch.geqrf(A)\n            if not fortran_contiguous:\n                self.assertTrue(reflectors.mT.is_contiguous())\n                reflectors = reflectors.contiguous()\n    \n            # Q is of size m x m\n            Q, _ = torch.linalg.qr(A, mode='complete')\n            C_right = make_tensor((*batch, m, n), dtype=dtype, device=device)\n            C_left = make_tensor((*batch, n, m), dtype=dtype, device=device)\n    \n            expected = Q @ C_right\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=False)\n            self.assertEqual(expected, actual)\n    \n            expected = C_left @ Q\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_left, left=False, transpose=False)\n            self.assertEqual(expected, actual)\n    \n            expected = Q.mH @ C_right\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=True)\n            self.assertEqual(expected, actual)\n    \n            expected = C_left @ Q.mH\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_left, left=False, transpose=True)\n            self.assertEqual(expected, actual)\n    \n            # if tau is all zeros then the implicit matrix Q is the identity matrix\n            # so the actual result should be C_right in this case\n            zero_tau = torch.zeros_like(tau)\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, zero_tau, C_right, left=True, transpose=False)\n            self.assertEqual(C_right, actual)\n    \n        batches = [(), (0, ), (2, ), (2, 1)]\n        ns = [5, 2, 0]\n        for batch, (m, n), fortran_contiguous in product(batches, product(ns, ns), [True, False]):\n>           run_test(batch, m, n, fortran_contiguous)\n\nsrc/pytorch_tests_reduced/ormqr_test.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nbatch = (), m = 5, n = 5, fortran_contiguous = True\n\n    def run_test(batch, m, n, fortran_contiguous):\n        A = make_tensor((*batch, m, n), dtype=dtype, device=device)\n        reflectors, tau = torch.geqrf(A)\n        if not fortran_contiguous:\n            self.assertTrue(reflectors.mT.is_contiguous())\n            reflectors = reflectors.contiguous()\n    \n        # Q is of size m x m\n        Q, _ = torch.linalg.qr(A, mode='complete')\n        C_right = make_tensor((*batch, m, n), dtype=dtype, device=device)\n        C_left = make_tensor((*batch, n, m), dtype=dtype, device=device)\n    \n        expected = Q @ C_right\n        with pytorch_op_timer():\n            actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=False)\n>       self.assertEqual(expected, actual)\nE       RuntimeError: Comparing\nE       \nE       TensorOrArrayPair(\nE           id=(),\nE           actual=tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\nE                  7.8461-4.6431j],\nE               [ -8.5251-6.8409j,  -1.0120-4.6169j,  -5.1341+1.3247j,  -5.6286-6.1405j,\nE                 -0.2531-7.5523j],\nE               [ -2.4844+6.4225j,   5.9277-0.3956j,   2.1676-5.7796j,  -3.6696+3.1946j,\nE                 -2.7297+2.2063j],\nE               [  3.5039-9.3657j,   4.3676-3.4608j,  10.2168+7.4772j,  -6.6466-1.4621j,\nE                 -2.7231+2.7202j],\nE               [  0.6307+0.7053j,  11.6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\nE                -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128),\nE           expected=tensor([[ -0.4777+0.4252j,  -2.3197+2.7611j,  -1.2809+2.7332j,   4.7764-0.3458j,\nE                  7.8461-4.6431j],\nE               [ -8.5251-6.8409j,  -1.0120-4.6169j,  -5.1341+1.3247j,  -5.6286-6.1405j,\nE                 -0.2531-7.5523j],\nE               [ -2.4844+6.4225j,   5.9277-0.3956j,   2.1676-5.7796j,  -3.6696+3.1946j,\nE                 -2.7297+2.2063j],\nE               [  3.5039-9.3657j,   4.3676-3.4608j,  10.2168+7.4772j,  -6.6466-1.4621j,\nE                 -2.7231+2.7202j],\nE               [  0.6307+0.7053j,  11.6461-6.3778j,  -7.8152-3.2604j,   1.1880-3.1413j,\nE                -13.0419-3.7714j]], device='xla:1', dtype=torch.complex128),\nE           rtol=1e-07,\nE           atol=1e-07,\nE           equal_nan=True,\nE           check_device=False,\nE           check_dtype=True,\nE           check_layout=False,\nE           check_stride=False,\nE           check_is_coalesced=False,\nE       )\nE       \nE       resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.\n\nsrc/pytorch_tests_reduced/ormqr_test.py:88: RuntimeError"
            },
            "teardown": {
                "duration": 0.0002853070000128355,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_xla_complex64",
            "lineno": 67,
            "outcome": "failed",
            "setup": {
                "duration": 0.00042410999958519824,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.19400120999944193,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/ormqr_test.py",
                        "lineno": 115,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/ormqr_test.py",
                        "lineno": 87,
                        "message": "in run_test"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.ormqr_test.TestLinalgXLA testMethod=test_ormqr_xla_complex64>, device = 'xla:1', dtype = torch.complex64\n\n    @skipCPUIfNoLapack\n    @skipCUDAIfNoCusolver\n    @dtypes(*floating_and_complex_types())\n    def test_ormqr(self, device, dtype):\n    \n        def run_test(batch, m, n, fortran_contiguous):\n            A = make_tensor((*batch, m, n), dtype=dtype, device=device)\n            reflectors, tau = torch.geqrf(A)\n            if not fortran_contiguous:\n                self.assertTrue(reflectors.mT.is_contiguous())\n                reflectors = reflectors.contiguous()\n    \n            # Q is of size m x m\n            Q, _ = torch.linalg.qr(A, mode='complete')\n            C_right = make_tensor((*batch, m, n), dtype=dtype, device=device)\n            C_left = make_tensor((*batch, n, m), dtype=dtype, device=device)\n    \n            expected = Q @ C_right\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=False)\n            self.assertEqual(expected, actual)\n    \n            expected = C_left @ Q\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_left, left=False, transpose=False)\n            self.assertEqual(expected, actual)\n    \n            expected = Q.mH @ C_right\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=True)\n            self.assertEqual(expected, actual)\n    \n            expected = C_left @ Q.mH\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_left, left=False, transpose=True)\n            self.assertEqual(expected, actual)\n    \n            # if tau is all zeros then the implicit matrix Q is the identity matrix\n            # so the actual result should be C_right in this case\n            zero_tau = torch.zeros_like(tau)\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, zero_tau, C_right, left=True, transpose=False)\n            self.assertEqual(C_right, actual)\n    \n        batches = [(), (0, ), (2, ), (2, 1)]\n        ns = [5, 2, 0]\n        for batch, (m, n), fortran_contiguous in product(batches, product(ns, ns), [True, False]):\n>           run_test(batch, m, n, fortran_contiguous)\n\nsrc/pytorch_tests_reduced/ormqr_test.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/ormqr_test.py:87: in run_test\n    actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=False)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.0002671960000952822,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_xla_float32",
            "lineno": 67,
            "outcome": "failed",
            "setup": {
                "duration": 0.0004905279993181466,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.15231934300027206,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/ormqr_test.py",
                        "lineno": 115,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/ormqr_test.py",
                        "lineno": 87,
                        "message": "in run_test"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.ormqr_test.TestLinalgXLA testMethod=test_ormqr_xla_float32>, device = 'xla:1', dtype = torch.float32\n\n    @skipCPUIfNoLapack\n    @skipCUDAIfNoCusolver\n    @dtypes(*floating_and_complex_types())\n    def test_ormqr(self, device, dtype):\n    \n        def run_test(batch, m, n, fortran_contiguous):\n            A = make_tensor((*batch, m, n), dtype=dtype, device=device)\n            reflectors, tau = torch.geqrf(A)\n            if not fortran_contiguous:\n                self.assertTrue(reflectors.mT.is_contiguous())\n                reflectors = reflectors.contiguous()\n    \n            # Q is of size m x m\n            Q, _ = torch.linalg.qr(A, mode='complete')\n            C_right = make_tensor((*batch, m, n), dtype=dtype, device=device)\n            C_left = make_tensor((*batch, n, m), dtype=dtype, device=device)\n    \n            expected = Q @ C_right\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=False)\n            self.assertEqual(expected, actual)\n    \n            expected = C_left @ Q\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_left, left=False, transpose=False)\n            self.assertEqual(expected, actual)\n    \n            expected = Q.mH @ C_right\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=True)\n            self.assertEqual(expected, actual)\n    \n            expected = C_left @ Q.mH\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_left, left=False, transpose=True)\n            self.assertEqual(expected, actual)\n    \n            # if tau is all zeros then the implicit matrix Q is the identity matrix\n            # so the actual result should be C_right in this case\n            zero_tau = torch.zeros_like(tau)\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, zero_tau, C_right, left=True, transpose=False)\n            self.assertEqual(C_right, actual)\n    \n        batches = [(), (0, ), (2, ), (2, 1)]\n        ns = [5, 2, 0]\n        for batch, (m, n), fortran_contiguous in product(batches, product(ns, ns), [True, False]):\n>           run_test(batch, m, n, fortran_contiguous)\n\nsrc/pytorch_tests_reduced/ormqr_test.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/ormqr_test.py:87: in run_test\n    actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=False)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.0002517630000511417,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/ormqr_test.py::TestLinalgXLA::test_ormqr_xla_float64",
            "lineno": 67,
            "outcome": "failed",
            "setup": {
                "duration": 0.00046533400018233806,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.19131377400026395,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/ormqr_test.py",
                        "lineno": 115,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/ormqr_test.py",
                        "lineno": 87,
                        "message": "in run_test"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.ormqr_test.TestLinalgXLA testMethod=test_ormqr_xla_float64>, device = 'xla:1', dtype = torch.float64\n\n    @skipCPUIfNoLapack\n    @skipCUDAIfNoCusolver\n    @dtypes(*floating_and_complex_types())\n    def test_ormqr(self, device, dtype):\n    \n        def run_test(batch, m, n, fortran_contiguous):\n            A = make_tensor((*batch, m, n), dtype=dtype, device=device)\n            reflectors, tau = torch.geqrf(A)\n            if not fortran_contiguous:\n                self.assertTrue(reflectors.mT.is_contiguous())\n                reflectors = reflectors.contiguous()\n    \n            # Q is of size m x m\n            Q, _ = torch.linalg.qr(A, mode='complete')\n            C_right = make_tensor((*batch, m, n), dtype=dtype, device=device)\n            C_left = make_tensor((*batch, n, m), dtype=dtype, device=device)\n    \n            expected = Q @ C_right\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=False)\n            self.assertEqual(expected, actual)\n    \n            expected = C_left @ Q\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_left, left=False, transpose=False)\n            self.assertEqual(expected, actual)\n    \n            expected = Q.mH @ C_right\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=True)\n            self.assertEqual(expected, actual)\n    \n            expected = C_left @ Q.mH\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, tau, C_left, left=False, transpose=True)\n            self.assertEqual(expected, actual)\n    \n            # if tau is all zeros then the implicit matrix Q is the identity matrix\n            # so the actual result should be C_right in this case\n            zero_tau = torch.zeros_like(tau)\n            with pytorch_op_timer():\n                actual = torch.ormqr(reflectors, zero_tau, C_right, left=True, transpose=False)\n            self.assertEqual(C_right, actual)\n    \n        batches = [(), (0, ), (2, ), (2, 1)]\n        ns = [5, 2, 0]\n        for batch, (m, n), fortran_contiguous in product(batches, product(ns, ns), [True, False]):\n>           run_test(batch, m, n, fortran_contiguous)\n\nsrc/pytorch_tests_reduced/ormqr_test.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/ormqr_test.py:87: in run_test\n    actual = torch.ormqr(reflectors, tau, C_right, left=True, transpose=False)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.0004854990002058912,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationCPU::test_randperm_cpu",
            "lineno": 81,
            "outcome": "failed",
            "setup": {
                "duration": 0.0005391570002757362,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0022942479999983334,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/randperm_test.py",
                        "lineno": 105,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.randperm_test.TestRandomTensorCreationCPU testMethod=test_randperm_cpu>, device = 'cpu'\n\n    def test_randperm(self, device):\n        if device == 'cpu' or device == 'meta' or device == 'xla:1':\n            rng_device = None\n        else:\n            # TODO: This won't actually work for non-CUDA device\n            # see https://github.com/pytorch/pytorch/issues/54282\n            rng_device = [device]\n    \n        # Test core functionality. On CUDA, different value of n has different\n        # code path\n        for n in (5, 100, 50000, 100000):\n            # Ensure both integer and floating-point numbers are tested. Half follows an execution path that is\n            # different from others on CUDA.\n            for dtype in (torch.long, torch.half, torch.float, torch.bfloat16):\n                if dtype != torch.half or device != 'xla:1':\n                    if n > 2049 and dtype == torch.half:  # Large n for torch.half will raise an exception, do not test here.\n                        continue\n                    if dtype == torch.bfloat16 and device != 'cpu':\n                        continue\n                    if n > 256 and dtype == torch.bfloat16:\n                        continue\n                    with torch.random.fork_rng(devices=rng_device):\n                        with pytorch_op_timer():\n>                           res1 = torch.randperm(n, dtype=dtype, device=device)\n\nsrc/pytorch_tests_reduced/randperm_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00016033200063247932,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationCPU::test_randperm_device_compatibility_cpu",
            "lineno": 151,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0003438499998082989,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006858549995740759,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/randperm_test.py', 152, \"Skipped: onlyAcceleratedDeviceTypes: doesn't run on cpu\")"
            },
            "teardown": {
                "duration": 0.00015335600073740352,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationXLA::test_randperm_device_compatibility_xla",
            "lineno": 151,
            "outcome": "failed",
            "setup": {
                "duration": 0.0019897570000466658,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001935663000040222,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/randperm_test.py",
                    "lineno": 154,
                    "message": "RuntimeError: Device type XLA is not supported for torch.Generator() api."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/randperm_test.py",
                        "lineno": 154,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.randperm_test.TestRandomTensorCreationXLA testMethod=test_randperm_device_compatibility_xla>, device = 'xla:1'\n\n    @onlyAcceleratedDeviceTypes\n    def test_randperm_device_compatibility(self, device):\n>       cuda_gen = torch.Generator(device=device)\nE       RuntimeError: Device type XLA is not supported for torch.Generator() api.\n\nsrc/pytorch_tests_reduced/randperm_test.py:154: RuntimeError"
            },
            "teardown": {
                "duration": 0.00015195000014500692,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/randperm_test.py::TestRandomTensorCreationXLA::test_randperm_xla",
            "lineno": 81,
            "outcome": "failed",
            "setup": {
                "duration": 0.00033178000012412667,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.018941803999950935,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/randperm_test.py",
                        "lineno": 105,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.randperm_test.TestRandomTensorCreationXLA testMethod=test_randperm_xla>, device = 'xla:1'\n\n    def test_randperm(self, device):\n        if device == 'cpu' or device == 'meta' or device == 'xla:1':\n            rng_device = None\n        else:\n            # TODO: This won't actually work for non-CUDA device\n            # see https://github.com/pytorch/pytorch/issues/54282\n            rng_device = [device]\n    \n        # Test core functionality. On CUDA, different value of n has different\n        # code path\n        for n in (5, 100, 50000, 100000):\n            # Ensure both integer and floating-point numbers are tested. Half follows an execution path that is\n            # different from others on CUDA.\n            for dtype in (torch.long, torch.half, torch.float, torch.bfloat16):\n                if dtype != torch.half or device != 'xla:1':\n                    if n > 2049 and dtype == torch.half:  # Large n for torch.half will raise an exception, do not test here.\n                        continue\n                    if dtype == torch.bfloat16 and device != 'cpu':\n                        continue\n                    if n > 256 and dtype == torch.bfloat16:\n                        continue\n                    with torch.random.fork_rng(devices=rng_device):\n                        with pytorch_op_timer():\n>                           res1 = torch.randperm(n, dtype=dtype, device=device)\n\nsrc/pytorch_tests_reduced/randperm_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00023105000036593992,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationCPU::test_range_cpu",
            "lineno": 35,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004559070002869703,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002631942999869352,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013350899916986236,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationCPU::test_range_warning_cpu",
            "lineno": 71,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003512109997245716,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.000790135999523045,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016434600001957733,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationXLA::test_range_warning_xla",
            "lineno": 71,
            "outcome": "passed",
            "setup": {
                "duration": 0.002209592999861343,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0030023680001249886,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011580700083868578,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/range_test.py::TestTensorCreationXLA::test_range_xla",
            "lineno": 35,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028457200005505,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.15722675300003175,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002106729998558876,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_add_module_raises_error_if_attr_exists_cpu",
            "lineno": 153,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003971679998358013,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0011534730001585558,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011228699986531865,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_register_buffer_raises_error_if_attr_exists_cpu",
            "lineno": 89,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003244700001232559,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0009124240004894091,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012848999995185295,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_register_parameter_allows_overwriting_with_same_name_cpu",
            "lineno": 136,
            "outcome": "passed",
            "setup": {
                "duration": 0.00030554099976143334,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0012832809998144512,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012536200028989697,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_register_parameter_raises_error_if_attr_exists_cpu",
            "lineno": 118,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028269700032979017,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007159110000429791,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011103100041509606,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNCPU::test_register_parameter_raises_error_if_name_is_not_string_cpu",
            "lineno": 108,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002733329993134248,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0008523260003130417,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016844500078150304,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_add_module_raises_error_if_attr_exists_xla",
            "lineno": 153,
            "outcome": "passed",
            "setup": {
                "duration": 0.0014980450005168677,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0010644260000844952,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013085699993098387,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_register_buffer_raises_error_if_attr_exists_xla",
            "lineno": 89,
            "outcome": "passed",
            "setup": {
                "duration": 0.000335571000505297,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0008818520000204444,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001124360005633207,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_register_parameter_allows_overwriting_with_same_name_xla",
            "lineno": 136,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002728039999055909,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001217200000610319,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001137529998231912,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_register_parameter_raises_error_if_attr_exists_xla",
            "lineno": 118,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002871530004995293,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006400900001608534,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001151529995695455,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/register_parameter_test.py::TestNNXLA::test_register_parameter_raises_error_if_name_is_not_string_xla",
            "lineno": 108,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027176799994776957,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007506489992010756,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001719030005915556,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestConstraints::test_params_constraints",
            "lineno": 364,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003231740001865546,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.003782301000683219,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001369279998471029,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU::test_argmax_relaxed_categorical_cpu",
            "lineno": 241,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00033672500012471573,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00020736500027851434,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/relaxedonehotcategorical_test.py', 242, 'Skipped: Numpy not found')"
            },
            "teardown": {
                "duration": 0.00012806999984604772,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU::test_mode_cpu",
            "lineno": 323,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002962930002468056,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0012516500000856468,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011472200003481703,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU::test_relaxed_one_hot_categorical_1d_cpu",
            "lineno": 195,
            "outcome": "passed",
            "setup": {
                "duration": 0.000273694000497926,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.009110510000027716,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012673999935941538,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsCPU::test_relaxed_one_hot_categorical_2d_cpu",
            "lineno": 216,
            "outcome": "passed",
            "setup": {
                "duration": 0.00029966900001454633,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.014515204999952402,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00021583400030067423,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA::test_argmax_relaxed_categorical_xla",
            "lineno": 241,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0014663399997516535,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0002085329997498775,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/relaxedonehotcategorical_test.py', 242, 'Skipped: Numpy not found')"
            },
            "teardown": {
                "duration": 0.00011712200011970708,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA::test_mode_xla",
            "lineno": 323,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002792309996948461,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0012530189997050911,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012234899986651726,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA::test_relaxed_one_hot_categorical_1d_xla",
            "lineno": 195,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003052990005016909,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.9206821289999425,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                    "lineno": 1227,
                    "message": "RuntimeError: Float did not match Double"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py",
                        "lineno": 214,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py",
                        "lineno": 194,
                        "message": "in _gradcheck_log_prob"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 3019,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1414,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1428,
                        "message": "in _gradcheck_helper"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1075,
                        "message": "in _gradcheck_real_imag"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1307,
                        "message": "in _fast_gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1279,
                        "message": "in _check_analytical_numerical_equal"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1227,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.relaxedonehotcategorical_test.TestDistributionsXLA testMethod=test_relaxed_one_hot_categorical_1d_xla>\ndevice = 'xla:1'\n\n    def test_relaxed_one_hot_categorical_1d(self, device):\n    \n        torch.set_default_dtype(torch.float64)\n        p = torch.tensor([0.1, 0.2, 0.3], requires_grad=True, device=device)\n        temp = torch.tensor(0.67, requires_grad=True, device=device)\n        with pytorch_op_timer():\n            result = RelaxedOneHotCategorical(\n                probs=p, temperature=temp)\n        self.assertEqual(result.sample().size(), (3,))\n        with pytorch_op_timer():\n            result = RelaxedOneHotCategorical(probs=p, temperature=temp)\n        self.assertFalse(result.sample().requires_grad)\n        with pytorch_op_timer():\n            result = RelaxedOneHotCategorical(probs=p, temperature=temp)\n        self.assertEqual(result.sample((2, 2)).size(), (2, 2, 3))\n        with pytorch_op_timer():\n            result = RelaxedOneHotCategorical(probs=p, temperature=temp)\n        self.assertEqual(result.sample((1,)).size(), (1, 3))\n>       self._gradcheck_log_prob(lambda t, p: RelaxedOneHotCategorical(\n            t, p, validate_args=False), (temp, p))\n\nsrc/pytorch_tests_reduced/relaxedonehotcategorical_test.py:214: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/relaxedonehotcategorical_test.py:194: in _gradcheck_log_prob\n    gradcheck(apply_fn, (s,) + tuple(ctor_params), raise_exception=True)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:3019: in gradcheck\n    return torch.autograd.gradcheck(fn, inputs, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1414: in gradcheck\n    return _gradcheck_helper(**args)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1428: in _gradcheck_helper\n    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1075: in _gradcheck_real_imag\n    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1307: in _fast_gradcheck\n    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1279: in _check_analytical_numerical_equal\n    jacobians_str = _run_slow_mode_and_get_error(func, tupled_inputs, outputs, i, j, rtol, atol, is_forward_ad)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function TestDistributions._gradcheck_log_prob.<locals>.apply_fn at 0x7fcde4c7a4c0>\ntupled_inputs = (tensor([2.7771e-04, 2.6277e-04, 9.9946e-01], device='xla:1',\n       requires_grad=True), tensor(0.6700, device='xla:1... requires_grad=True), tensor([0.1000, 0.2000, 0.3000], device='xla:1', dtype=torch.float64,\n       requires_grad=True))\noutputs = (tensor(9.2861, device='xla:1', dtype=torch.float64, grad_fn=<AddBackward0>),), input_idx = 0, output_idx = 0, rtol = 0.001, atol = 1e-05\nis_forward_ad = False\n\n    def _run_slow_mode_and_get_error(func, tupled_inputs, outputs, input_idx, output_idx, rtol, atol, is_forward_ad):\n        # Compute jacobians in slow mode for better error message\n        slow_numerical = _get_numerical_jacobian(func, tupled_inputs, outputs, is_forward_ad=is_forward_ad)[input_idx][output_idx]\n        if is_forward_ad:\n            def new_fn(inp):\n                new_inputs = list(tupled_inputs)\n                new_inputs[input_idx] = inp\n                return _as_tuple(func(*new_inputs))[output_idx]\n            slow_analytical = _get_analytical_jacobian_forward_ad(new_fn, (tupled_inputs[input_idx],), (outputs[output_idx],))[0][0]\n        else:\n            slow_analytical = _get_analytical_jacobian(tupled_inputs, outputs, input_idx, output_idx)\n    \n    \n        # Assume jacobians are non-empty and have the same shape\n        slow_max_diff = (slow_numerical - slow_analytical).abs().max()\n    \n>       slow_allclose = torch.allclose(slow_analytical, slow_numerical, rtol, atol)\nE       RuntimeError: Float did not match Double\n\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1227: RuntimeError"
            },
            "teardown": {
                "duration": 0.0002467990007062326,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py::TestDistributionsXLA::test_relaxed_one_hot_categorical_2d_xla",
            "lineno": 216,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003923249996660161,
                "outcome": "passed"
            },
            "call": {
                "duration": 3.7792622479992133,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                    "lineno": 1280,
                    "message": "torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor(-4.9543, device='xla:1')\nanalytical:tensor(-4.0173, device='xla:1')\n\nThe above quantities relating the numerical and analytical jacobians are computed \nin fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nabout fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\n\nNumerical:\n tensor([[ 8.8702,  0.0000],\n        [-6.0710,  0.0000],\n        [-5.7135,  0.0000],\n        [ 0.0000, -3.2500],\n        [ 0.0000, -7.0832],\n        [ 0.0000,  5.8086]], device='xla:1')\nAnalytical:\ntensor([[ 8.8727,  0.0000],\n        [-6.0792,  0.0000],\n        [-5.7142,  0.0000],\n        [ 0.0000, -3.2402],\n        [ 0.0000, -7.0962],\n        [ 0.0000,  5.7864]], device='xla:1')\n\nThe max per-element difference (slow mode) is: 0.022222042083740234."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py",
                        "lineno": 237,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/relaxedonehotcategorical_test.py",
                        "lineno": 194,
                        "message": "in _gradcheck_log_prob"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 3019,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1414,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1428,
                        "message": "in _gradcheck_helper"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1075,
                        "message": "in _gradcheck_real_imag"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1307,
                        "message": "in _fast_gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1280,
                        "message": "GradcheckError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.relaxedonehotcategorical_test.TestDistributionsXLA testMethod=test_relaxed_one_hot_categorical_2d_xla>\ndevice = 'xla:1'\n\n    def test_relaxed_one_hot_categorical_2d(self, device):\n        torch.set_default_dtype(torch.float64)\n        probabilities = [[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]]\n        probabilities_1 = [[1.0, 0.0], [0.0, 1.0]]\n        temp = torch.tensor([3.0], requires_grad=True, device=device)\n        # The lower the temperature, the more unstable the log_prob gradcheck is\n        # w.r.t. the sample. Values below 0.25 empirically fail the default tol.\n        temp_2 = torch.tensor([0.25], requires_grad=True, device=device)\n        p = torch.tensor(probabilities, requires_grad=True, device=device)\n        s = torch.tensor(probabilities_1, requires_grad=True, device=device)\n        with pytorch_op_timer():\n            result = RelaxedOneHotCategorical(temp, p)\n        self.assertEqual(result.sample().size(), (2, 3))\n        with pytorch_op_timer():\n            result = RelaxedOneHotCategorical(temp, p)\n        self.assertEqual(result.sample(\n            sample_shape=(3, 4)).size(), (3, 4, 2, 3))\n        with pytorch_op_timer():\n            RelaxedOneHotCategorical(temp, p)\n        self.assertEqual(result.sample((6,)).size(), (6, 2, 3))\n>       self._gradcheck_log_prob(lambda t, p: RelaxedOneHotCategorical(\n            t, p, validate_args=False), (temp, p))\n\nsrc/pytorch_tests_reduced/relaxedonehotcategorical_test.py:237: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/relaxedonehotcategorical_test.py:194: in _gradcheck_log_prob\n    gradcheck(apply_fn, (s,) + tuple(ctor_params), raise_exception=True)\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:3019: in gradcheck\n    return torch.autograd.gradcheck(fn, inputs, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1414: in gradcheck\n    return _gradcheck_helper(**args)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1428: in _gradcheck_helper\n    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1075: in _gradcheck_real_imag\n    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1307: in _fast_gradcheck\n    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nall_analytical = [[tensor(-4.0173, device='xla:1', dtype=torch.float64), tensor(0.0912, device='xla:1', dtype=torch.float64), tensor(-3.0535, device='xla:1', dtype=torch.float64)]]\nall_numerical = [[tensor(-4.9543, device='xla:1', dtype=torch.float64)], [tensor(226.6296, device='xla:1', dtype=torch.float64)], [tensor(-3.1356, device='xla:1', dtype=torch.float64)]]\ncomplex_indices = None\ntupled_inputs = (tensor([[0.1951, 0.3616, 0.4433],\n        [0.3526, 0.4350, 0.2124]], device='xla:1', dtype=torch.float64,\n       requ...0, 0.2000, 0.3000],\n        [0.5000, 0.3000, 0.2000]], device='xla:1', dtype=torch.float64,\n       requires_grad=True))\noutputs = (tensor([2.4817, 2.3363], device='xla:1', dtype=torch.float64,\n       grad_fn=<AddBackward0>),)\nfunc = <function TestDistributions._gradcheck_log_prob.<locals>.apply_fn at 0x7fcde4c7f670>\nall_v = [tensor([0.7780, 0.6282], device='xla:1', dtype=torch.float64)]\nall_u = [tensor([0.1010, 0.4981, 0.2168, 0.4202, 0.5237, 0.4938], device='xla:1',\n       dtype=torch.float64), tensor([1.], de...e=torch.float64), tensor([0.6284, 0.4815, 0.5140, 0.3286, 0.0145, 0.0308], device='xla:1',\n       dtype=torch.float64)]\nrtol = 0.001, atol = 1e-05, test_imag = False\n\n    def _check_analytical_numerical_equal(all_analytical, all_numerical, complex_indices, tupled_inputs, outputs,\n                                          func, all_v, all_u, rtol, atol, test_imag, *, is_forward_ad=False):\n        for i, all_numerical_for_input_i in enumerate(all_numerical):\n            for j, n in enumerate(all_numerical_for_input_i):\n                # Forward AD generates the transpose of what this function expects\n                if is_forward_ad:\n                    a = all_analytical[i][j]\n                else:\n                    a = all_analytical[j][i]\n                n = n.to(device=a.device)\n                updated_atol = _adjusted_atol(atol, all_u[i], all_v[j] if all_v else None)\n                if not _allclose_with_type_promotion(a, n.to(a.device), rtol, updated_atol):\n                    jacobians_str = _run_slow_mode_and_get_error(func, tupled_inputs, outputs, i, j, rtol, atol, is_forward_ad)\n>                   raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)\nE                   torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nE                   numerical:tensor(-4.9543, device='xla:1')\nE                   analytical:tensor(-4.0173, device='xla:1')\nE                   \nE                   The above quantities relating the numerical and analytical jacobians are computed \nE                   in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nE                   about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\nE                   \nE                   Numerical:\nE                    tensor([[ 8.8702,  0.0000],\nE                           [-6.0710,  0.0000],\nE                           [-5.7135,  0.0000],\nE                           [ 0.0000, -3.2500],\nE                           [ 0.0000, -7.0832],\nE                           [ 0.0000,  5.8086]], device='xla:1')\nE                   Analytical:\nE                   tensor([[ 8.8727,  0.0000],\nE                           [-6.0792,  0.0000],\nE                           [-5.7142,  0.0000],\nE                           [ 0.0000, -3.2402],\nE                           [ 0.0000, -7.0962],\nE                           [ 0.0000,  5.7864]], device='xla:1')\nE                   \nE                   The max per-element difference (slow mode) is: 0.022222042083740234.\n\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1280: GradcheckError"
            },
            "teardown": {
                "duration": 0.0003264639999542851,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeCPU::test_batchnorm_simple_average_cpu_bfloat16",
            "lineno": 120,
            "outcome": "passed",
            "setup": {
                "duration": 0.00043127900062245317,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.07187568100016506,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017031599963956978,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeCPU::test_batchnorm_simple_average_cpu_float32",
            "lineno": 120,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003606079999372014,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.004933647000143537,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00018616800025483826,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeXLA::test_batchnorm_simple_average_xla_bfloat16",
            "lineno": 120,
            "outcome": "failed",
            "setup": {
                "duration": 0.0014942679999876418,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.858399529000053,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/reset_running_stats_test.py",
                    "lineno": 115,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 2 / 12 (16.7%)\nGreatest absolute difference: 0.009765625 at index (2, 2) (up to 1e-05 allowed)\nGreatest relative difference: 0.04433497413992882 at index (3, 2) (up to 0.016 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/reset_running_stats_test.py",
                        "lineno": 124,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/reset_running_stats_test.py",
                        "lineno": 115,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.reset_running_stats_test.TestNNDeviceTypeXLA testMethod=test_batchnorm_simple_average_xla_bfloat16>\ndevice = 'xla:1', dtype = torch.bfloat16\n\n    @dtypes(torch.float, torch.bfloat16)\n    # @dtypesIfCUDA(torch.float, torch.bfloat16)\n    def test_batchnorm_simple_average(self, device, dtype):\n>       self._test_batchnorm_simple_average(device, dtype)\n\nsrc/pytorch_tests_reduced/reset_running_stats_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.pytorch_tests_reduced.reset_running_stats_test.TestNNDeviceTypeXLA testMethod=test_batchnorm_simple_average_xla_bfloat16>\ndevice = 'xla:1', dtype = torch.bfloat16, module_dtype = torch.bfloat16\n\n    def _test_batchnorm_simple_average(self, device, dtype, module_dtype=None):\n        module_dtype = module_dtype or dtype\n        module = nn.BatchNorm1d(3, momentum=None).to(\n            dtype=module_dtype, device=device)\n        zeros = torch.zeros(3, dtype=module_dtype, device=device)\n        ones = torch.ones(3, dtype=module_dtype, device=device)\n        self.assertEqual(module.running_mean, zeros)\n        self.assertEqual(module.running_var, ones)\n    \n        data1 = torch.rand(4, 3, dtype=dtype, device=device)\n        data2 = torch.rand(4, 3, dtype=dtype, device=device)\n    \n        # 1st pass\n        res1 = module(data1)\n        running_mean1 = module.running_mean.clone()\n        running_var1 = module.running_var.clone()\n        self.assertNotEqual(running_mean1, zeros)\n        self.assertNotEqual(running_var1, ones)\n    \n        # reset stats\n        with pytorch_op_timer():\n            module.reset_running_stats()\n        self.assertEqual(module.running_mean, zeros)\n        self.assertEqual(module.running_var, ones)\n    \n        # 2nd pass\n        res2 = module(data2)\n        running_mean2 = module.running_mean.clone()\n        running_var2 = module.running_var.clone()\n        self.assertNotEqual(running_mean2, zeros)\n        self.assertNotEqual(running_var2, ones)\n    \n        # reset stats\n        with pytorch_op_timer():\n            module.reset_running_stats()\n        self.assertEqual(module.running_mean, zeros)\n        self.assertEqual(module.running_var, ones)\n    \n        # 3rd (combined) pass\n        res3 = module(data1)\n        res4 = module(data2)\n>       self.assertEqual(res3, res1)\nE       AssertionError: Tensor-likes are not close!\nE       \nE       Mismatched elements: 2 / 12 (16.7%)\nE       Greatest absolute difference: 0.009765625 at index (2, 2) (up to 1e-05 allowed)\nE       Greatest relative difference: 0.04433497413992882 at index (3, 2) (up to 0.016 allowed)\n\nsrc/pytorch_tests_reduced/reset_running_stats_test.py:115: AssertionError"
            },
            "teardown": {
                "duration": 0.00019656600034068106,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/reset_running_stats_test.py::TestNNDeviceTypeXLA::test_batchnorm_simple_average_xla_float32",
            "lineno": 120,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003494630000204779,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.74326476799979,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/reset_running_stats_test.py",
                    "lineno": 117,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 3 / 3 (100.0%)\nGreatest absolute difference: 0.07063984870910645 at index (0,) (up to 1e-05 allowed)\nGreatest relative difference: 0.1745309978723526 at index (0,) (up to 1.3e-06 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/reset_running_stats_test.py",
                        "lineno": 124,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/reset_running_stats_test.py",
                        "lineno": 117,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.reset_running_stats_test.TestNNDeviceTypeXLA testMethod=test_batchnorm_simple_average_xla_float32>, device = 'xla:1'\ndtype = torch.float32\n\n    @dtypes(torch.float, torch.bfloat16)\n    # @dtypesIfCUDA(torch.float, torch.bfloat16)\n    def test_batchnorm_simple_average(self, device, dtype):\n>       self._test_batchnorm_simple_average(device, dtype)\n\nsrc/pytorch_tests_reduced/reset_running_stats_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.pytorch_tests_reduced.reset_running_stats_test.TestNNDeviceTypeXLA testMethod=test_batchnorm_simple_average_xla_float32>, device = 'xla:1'\ndtype = torch.float32, module_dtype = torch.float32\n\n    def _test_batchnorm_simple_average(self, device, dtype, module_dtype=None):\n        module_dtype = module_dtype or dtype\n        module = nn.BatchNorm1d(3, momentum=None).to(\n            dtype=module_dtype, device=device)\n        zeros = torch.zeros(3, dtype=module_dtype, device=device)\n        ones = torch.ones(3, dtype=module_dtype, device=device)\n        self.assertEqual(module.running_mean, zeros)\n        self.assertEqual(module.running_var, ones)\n    \n        data1 = torch.rand(4, 3, dtype=dtype, device=device)\n        data2 = torch.rand(4, 3, dtype=dtype, device=device)\n    \n        # 1st pass\n        res1 = module(data1)\n        running_mean1 = module.running_mean.clone()\n        running_var1 = module.running_var.clone()\n        self.assertNotEqual(running_mean1, zeros)\n        self.assertNotEqual(running_var1, ones)\n    \n        # reset stats\n        with pytorch_op_timer():\n            module.reset_running_stats()\n        self.assertEqual(module.running_mean, zeros)\n        self.assertEqual(module.running_var, ones)\n    \n        # 2nd pass\n        res2 = module(data2)\n        running_mean2 = module.running_mean.clone()\n        running_var2 = module.running_var.clone()\n        self.assertNotEqual(running_mean2, zeros)\n        self.assertNotEqual(running_var2, ones)\n    \n        # reset stats\n        with pytorch_op_timer():\n            module.reset_running_stats()\n        self.assertEqual(module.running_mean, zeros)\n        self.assertEqual(module.running_var, ones)\n    \n        # 3rd (combined) pass\n        res3 = module(data1)\n        res4 = module(data2)\n        self.assertEqual(res3, res1)\n        self.assertEqual(res4, res2)\n>       self.assertEqual(module.running_mean,\n                         (running_mean1 + running_mean2) / 2)\nE       AssertionError: Tensor-likes are not close!\nE       \nE       Mismatched elements: 3 / 3 (100.0%)\nE       Greatest absolute difference: 0.07063984870910645 at index (0,) (up to 1e-05 allowed)\nE       Greatest relative difference: 0.1745309978723526 at index (0,) (up to 1.3e-06 allowed)\n\nsrc/pytorch_tests_reduced/reset_running_stats_test.py:117: AssertionError"
            },
            "teardown": {
                "duration": 0.00035002900040126406,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/round_test.py::TestRoundCPU::test_rounding_cpu",
            "lineno": 65,
            "outcome": "passed",
            "setup": {
                "duration": 0.000401659999624826,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.05635837500085472,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017574100002093473,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/round_test.py::TestRoundXLA::test_rounding_xla",
            "lineno": 65,
            "outcome": "passed",
            "setup": {
                "duration": 0.002169759000025806,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.025007436000123562,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014991599982749904,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseCPU::test_saddmm_cpu_complex128",
            "lineno": 108,
            "outcome": "passed",
            "setup": {
                "duration": 0.00039837199983594473,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.09310219100007089,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00024525000026187627,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseCPU::test_saddmm_cpu_float64",
            "lineno": 108,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004886930000793654,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.059950404000119306,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00026668000009522075,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseXLA::test_saddmm_xla_complex128",
            "lineno": 108,
            "outcome": "failed",
            "setup": {
                "duration": 0.0020990920002077473,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.1915148810003302,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                    "lineno": 2104,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/saddmm_test.py",
                        "lineno": 133,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/saddmm_test.py",
                        "lineno": 114,
                        "message": "in test_shape"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/saddmm_test.py",
                        "lineno": 86,
                        "message": "in _gen_sparse"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2104,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.saddmm_test.TestSparseXLA testMethod=test_saddmm_xla_complex128>, device = 'xla:1', dtype = torch.complex128\ncoalesced = True\n\n    @coalescedonoff\n    # @onlyAcceleratedDeviceTypes\n    @dtypes(torch.double, torch.cdouble)\n    def test_saddmm(self, device, dtype, coalesced):\n        def test_shape(di, dj, dk, nnz):\n            x = self._gen_sparse(2, nnz, [di, dj], dtype, device, coalesced)[0]\n            t = self._gen_sparse(2, nnz, [di, dk], dtype, device, coalesced)[0]\n            y = torch.randn(dj, dk, dtype=dtype, device=device)\n            alpha = random.random()\n            beta = random.random()\n    \n            with pytorch_op_timer():\n                res = torch.saddmm(t, x, y, beta=beta, alpha=alpha)\n            expected = torch.addmm(self.safeToDense(t), self.safeToDense(x), y, beta=beta, alpha=alpha)\n            self.assertEqual(self.safeToDense(res), expected)\n            with pytorch_op_timer():\n                res = torch.saddmm(t, x, y)\n            expected = torch.addmm(self.safeToDense(t), self.safeToDense(x), y)\n            self.assertEqual(self.safeToDense(res), expected)\n    \n            res = torch.smm(x, y)\n            expected = torch.mm(self.safeToDense(x), y)\n            self.assertEqual(self.safeToDense(res), expected)\n    \n>       test_shape(7, 5, 3, 20)\n\nsrc/pytorch_tests_reduced/saddmm_test.py:133: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/saddmm_test.py:114: in test_shape\n    x = self._gen_sparse(2, nnz, [di, dj], dtype, device, coalesced)[0]\nsrc/pytorch_tests_reduced/saddmm_test.py:86: in _gen_sparse\n    x, i, v = self.genSparseTensor(with_size, sparse_dim, nnz, not coalesced, dtype=dtype, device=device)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.pytorch_tests_reduced.saddmm_test.TestSparseXLA testMethod=test_saddmm_xla_complex128>, size = [7, 5], sparse_dim = 2, nnz = 20\nis_uncoalesced = False, device = 'xla:1', dtype = torch.complex128\n\n    def genSparseTensor(self, size, sparse_dim, nnz, is_uncoalesced, device, dtype):\n        # Assert not given impossible combination, where the sparse dims have\n        # empty numel, but nnz > 0 makes the indices containing values.\n        assert all(size[d] > 0 for d in range(sparse_dim)) or nnz == 0, 'invalid arguments'\n    \n        v_size = [nnz] + list(size[sparse_dim:])\n        v = make_tensor(v_size, device=device, dtype=dtype, low=-1, high=1)\n        i = torch.rand(sparse_dim, nnz, device=device)\n        i.mul_(torch.tensor(size[:sparse_dim]).unsqueeze(1).to(i))\n        i = i.to(torch.long)\n        if is_uncoalesced:\n            i1 = i[:, :(nnz // 2), ...]\n            i2 = i[:, :((nnz + 1) // 2), ...]\n            i = torch.cat([i1, i2], 1)\n>       x = torch.sparse_coo_tensor(i, v, torch.Size(size), dtype=dtype, device=device)\nE       NotImplementedError: Unsupported device type for sparse layout: xla\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2104: NotImplementedError"
            },
            "teardown": {
                "duration": 0.0002634110005601542,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/saddmm_test.py::TestSparseXLA::test_saddmm_xla_float64",
            "lineno": 108,
            "outcome": "failed",
            "setup": {
                "duration": 0.0004229639998811763,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.1490500449999672,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                    "lineno": 2104,
                    "message": "NotImplementedError: Unsupported device type for sparse layout: xla"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/saddmm_test.py",
                        "lineno": 133,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/saddmm_test.py",
                        "lineno": 114,
                        "message": "in test_shape"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/saddmm_test.py",
                        "lineno": 86,
                        "message": "in _gen_sparse"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 2104,
                        "message": "NotImplementedError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.saddmm_test.TestSparseXLA testMethod=test_saddmm_xla_float64>, device = 'xla:1', dtype = torch.float64\ncoalesced = True\n\n    @coalescedonoff\n    # @onlyAcceleratedDeviceTypes\n    @dtypes(torch.double, torch.cdouble)\n    def test_saddmm(self, device, dtype, coalesced):\n        def test_shape(di, dj, dk, nnz):\n            x = self._gen_sparse(2, nnz, [di, dj], dtype, device, coalesced)[0]\n            t = self._gen_sparse(2, nnz, [di, dk], dtype, device, coalesced)[0]\n            y = torch.randn(dj, dk, dtype=dtype, device=device)\n            alpha = random.random()\n            beta = random.random()\n    \n            with pytorch_op_timer():\n                res = torch.saddmm(t, x, y, beta=beta, alpha=alpha)\n            expected = torch.addmm(self.safeToDense(t), self.safeToDense(x), y, beta=beta, alpha=alpha)\n            self.assertEqual(self.safeToDense(res), expected)\n            with pytorch_op_timer():\n                res = torch.saddmm(t, x, y)\n            expected = torch.addmm(self.safeToDense(t), self.safeToDense(x), y)\n            self.assertEqual(self.safeToDense(res), expected)\n    \n            res = torch.smm(x, y)\n            expected = torch.mm(self.safeToDense(x), y)\n            self.assertEqual(self.safeToDense(res), expected)\n    \n>       test_shape(7, 5, 3, 20)\n\nsrc/pytorch_tests_reduced/saddmm_test.py:133: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/saddmm_test.py:114: in test_shape\n    x = self._gen_sparse(2, nnz, [di, dj], dtype, device, coalesced)[0]\nsrc/pytorch_tests_reduced/saddmm_test.py:86: in _gen_sparse\n    x, i, v = self.genSparseTensor(with_size, sparse_dim, nnz, not coalesced, dtype=dtype, device=device)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.pytorch_tests_reduced.saddmm_test.TestSparseXLA testMethod=test_saddmm_xla_float64>, size = [7, 5], sparse_dim = 2, nnz = 20\nis_uncoalesced = False, device = 'xla:1', dtype = torch.float64\n\n    def genSparseTensor(self, size, sparse_dim, nnz, is_uncoalesced, device, dtype):\n        # Assert not given impossible combination, where the sparse dims have\n        # empty numel, but nnz > 0 makes the indices containing values.\n        assert all(size[d] > 0 for d in range(sparse_dim)) or nnz == 0, 'invalid arguments'\n    \n        v_size = [nnz] + list(size[sparse_dim:])\n        v = make_tensor(v_size, device=device, dtype=dtype, low=-1, high=1)\n        i = torch.rand(sparse_dim, nnz, device=device)\n        i.mul_(torch.tensor(size[:sparse_dim]).unsqueeze(1).to(i))\n        i = i.to(torch.long)\n        if is_uncoalesced:\n            i1 = i[:, :(nnz // 2), ...]\n            i2 = i[:, :((nnz + 1) // 2), ...]\n            i = torch.cat([i1, i2], 1)\n>       x = torch.sparse_coo_tensor(i, v, torch.Size(size), dtype=dtype, device=device)\nE       NotImplementedError: Unsupported device type for sparse layout: xla\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:2104: NotImplementedError"
            },
            "teardown": {
                "duration": 0.0003376200002094265,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_complex128",
            "lineno": 43,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004795459999513696,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.9957268830003159,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002424849999442813,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_complex64",
            "lineno": 43,
            "outcome": "passed",
            "setup": {
                "duration": 0.00046097200083750067,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.8163473779995911,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002553139993324294,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_float32",
            "lineno": 43,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005133710001246072,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.7900422040002013,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00025572300000931136,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_float64",
            "lineno": 43,
            "outcome": "passed",
            "setup": {
                "duration": 0.00048007799978222465,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.7983968550006466,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002591149996078457,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_int32",
            "lineno": 43,
            "outcome": "passed",
            "setup": {
                "duration": 0.00048246300048049306,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.7947542469992186,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022190399977262132,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgCPU::test_mm_cpu_int64",
            "lineno": 43,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004386670007079374,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.7904493639998691,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000310197999169759,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_complex128",
            "lineno": 43,
            "outcome": "failed",
            "setup": {
                "duration": 0.0026709260000643553,
                "outcome": "passed"
            },
            "call": {
                "duration": 53.38979347099939,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/size_test.py",
                    "lineno": 73,
                    "message": "RuntimeError: Comparing\n\nTensorOrArrayPair(\n    id=(),\n    actual=tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n         -2.2407-0.2425j,  0.2035-0.4496j, -1.4810+6.0237j, -2.7851+5.4661j,\n          1.0553-0.2403j,  0.0873-0.8104j, -1.1095-2.7532j,  0.9891-1.2121j,\n          1.0592-1.9560j,  1.6624-1.7664j, -4.8020-1.0097j],\n        [ 0.0932-1.0632j, -0.4509-0.4323j,  2.0811+1.7304j,  0.3800-0.8042j,\n          0.3238+2.4538j,  0.8524-2.2710j,  0.0499+1.5906j, -1.5238-0.6702j,\n          0.5962+1.6630j, -0.6455+1.5747j, -2.1007-0.0765j,  1.2933-0.8246j,\n         -1.5839-1.2315j, -1.0250+1.5196j, -2.0119+0.1062j],\n        [ 2.0069+2.4952j, -1.0440-1.5923j,  0.3315-2.5119j,  1.2107-0.2472j,\n         -0.5795+5.2369j,  0.5261-1.1058j, -2.3623+1.7065j,  0.7529+2.0756j,\n         -5.2855+0.7199j, -2.7992-1.7865j,  3.3732+5.0895j,  3.1148-3.6782j,\n          3.3944-5.4787j, -1.4948+0.2726j, -3.2070-1.7407j],\n        [ 0.5631+0.3728j,  2.1828+0.7304j, -2.0065-0.9247j,  1.4199-1.5669j,\n          0.4063+1.2448j, -1.3820+3.1654j,  0.1917-0.0193j,  0.8475+0.1435j,\n         -1.5303+1.2521j, -1.4238+1.2681j,  0.3012+0.2479j, -0.5574-2.3543j,\n         -0.7846-1.3666j, -0.7856-0.3939j, -0.8274-0.1194j],\n        [ 0.0324-1.3909j, -0.1203-1.1888j,  0.2025-1.7234j,  0.7651+1.5668j,\n          1.6860-1.7981j, -2.2573+2.3233j, -0.1032-3.9325j, -0.2306+1.4186j,\n          1.0236-1.4330j,  0.1143+2.3022j, -3.2337-0.2989j, -1.5082+1.2465j,\n         -2.0147+2.8854j,  0.8310-1.0295j,  0.3954-0.6050j],\n        [ 0.6654+0.4144j,  1.7644-1.9366j,  2.3693-4.0231j, -0.5994-2.1161j,\n          1.0038-0.3162j,  2.5332-1.7920j,  2.7542+3.4991j,  1.6866+0.3422j,\n         -1.1227-3.1932j, -4.7747+0.5699j,  3.6253+3.3171j, -0.2686-1.8045j,\n          1.7770-3.1219j, -2.4701-0.3974j, -3.6862+3.8656j],\n        [-1.5845-4.1079j, -2.6810+1.0145j, -1.7226-2.2840j, -0.0131+0.5237j,\n         -1.1743-3.0424j, -1.1473-2.5228j,  4.2845+0.4488j,  0.3502-1.9410j,\n          0.9076-1.7757j, -2.4120+2.7608j, -0.6351-4.5906j, -0.2074+2.3495j,\n         -4.5655-0.2951j, -2.8301+1.4477j,  1.7459+4.2101j],\n        [ 2.0080+3.6980j,  1.8509+1.4753j,  0.9734+0.0503j,  1.6844-2.3884j,\n         -0.5182+1.8652j,  2.3675-3.0549j,  2.0761+0.7240j,  0.3014-0.5526j,\n         -2.8698-2.8279j, -0.4730+1.2654j,  0.6873+4.0866j,  0.4653-0.3643j,\n          3.9563+0.4844j,  0.9985+0.5925j, -1.1891+0.5809j],\n        [ 2.1716-3.8304j, -1.2221+1.8169j, -0.0692-0.6350j, -0.3843-0.8243j,\n          1.8068-2.3342j, -2.0383+4.2771j, -2.7129+0.1469j, -1.3979+5.2980j,\n          6.3524+0.5113j, -1.9399-2.2576j,  1.7695+0.4793j, -2.7231-2.0197j,\n         -3.0427+1.3365j,  1.5296+0.9722j, -3.2803-3.0723j],\n        [-2.2514-4.2055j,  2.1707+2.7620j, -0.1860+3.6809j,  0.5694-0.4102j,\n          0.5374+0.0499j, -1.9568+0.5323j, -0.9677-4.2970j, -1.5126-5.5865j,\n          0.8056-0.9773j, -1.2527+0.4486j, -3.0336-1.3061j,  2.9663+4.4681j,\n         -2.9028+1.7681j, -2.1636+0.9880j,  3.9667-0.4236j],\n        [ 1.0943-0.3210j,  2.6839-2.1928j, -0.8744+2.2169j,  0.4063+0.3018j,\n          1.3178-0.3794j,  3.1111+2.7784j,  0.4673-2.7608j,  0.7912-3.3635j,\n          2.3200-2.4908j, -4.9645+0.2920j, -1.1168-0.5327j, -1.9378+0.3959j,\n         -1.2669-0.1073j, -3.2050-1.0744j,  0.7029-1.3618j],\n        [-2.8384-2.6264j, -2.4609-0.8443j,  1.0664-0.9961j, -1.5841+2.1933j,\n         -3.0556-2.1011j,  1.0991-1.2765j, -1.3713+0.7826j, -1.6404+3.2083j,\n         -1.1352-6.0049j, -2.4649+2.8572j,  0.9221-2.8091j, -0.6556+1.9814j,\n         -1.0916+1.8894j,  0.9140+3.0368j, -1.4458-0.8892j],\n        [ 0.1730+0.1588j, -2.7033-0.0564j, -0.6712-2.7233j, -1.2555+0.6728j,\n          0.9580-0.2642j,  1.8653-1.6652j,  3.1011+3.9994j,  3.4555+1.8861j,\n         -2.9312-2.5952j, -1.9216-1.9427j,  4.8479-1.2849j, -3.8279+1.0860j,\n         -0.1752-2.4063j, -0.1576+0.0716j, -1.7031+3.0306j],\n        [ 1.8441-2.8727j, -1.9806-1.7925j, -2.0465-0.8138j, -0.0922+0.5836j,\n         -0.4304+1.5124j, -1.3604+0.6704j,  1.3084-2.5652j, -1.7110+1.1774j,\n          2.2672+3.0424j, -1.1253-0.6787j, -2.9825-1.3689j,  2.2006-0.3375j,\n         -3.7993-1.1757j, -1.8144+0.5795j,  1.2954-1.5418j],\n        [ 1.1885+2.6278j, -2.8391+1.5064j, -3.1722-3.6139j,  0.9402+0.3427j,\n         -5.2045+0.6148j,  0.2228-2.8052j,  3.6311+1.3205j,  1.7382+0.7886j,\n         -1.7540-3.9592j,  0.5841-0.9690j,  1.9703+0.9599j, -0.4767-0.1140j,\n          2.6081-1.5638j, -0.6958+0.5202j,  1.9002+2.3517j],\n        [-4.3929+2.3776j, -0.6929+1.6441j, -3.0393-1.8704j,  3.2515+1.3118j,\n         -4.7102+0.4514j,  1.6267+5.5787j,  1.6652+2.4810j,  0.5355+1.1179j,\n          2.0685+0.4092j, -3.1097+0.4923j, -6.3087-1.1432j,  2.3676-0.8362j,\n         -3.0167+2.2700j, -2.6130+1.5180j, -0.0586-0.5221j],\n        [ 0.7065+0.9403j, -2.6223-0.2074j, -4.0726-1.4891j,  2.2851+2.1597j,\n         -3.1355+3.9426j, -0.3742+0.0146j,  0.1524-1.9545j,  4.4762+1.0231j,\n         -5.0257-0.0337j,  0.5652+2.8865j, -1.8792-0.4799j, -0.3099+0.5276j,\n          0.6804-1.6629j, -0.1956-1.0923j, -0.5373+0.9113j],\n        [-3.6113+1.1066j, -0.0454+1.5766j, -3.6155+0.1328j,  1.2423+1.8670j,\n         -2.5789+0.9074j,  1.1183+3.1183j,  0.5903-2.3002j,  1.3157-0.3202j,\n         -3.3627-2.7827j, -4.1682+0.0735j, -2.0040-0.8566j,  1.8727+2.0009j,\n         -1.0795+2.0094j, -1.3459+1.7733j,  2.1572-2.0668j],\n        [-0.5685-2.6583j, -1.2080+0.2056j, -0.2720-0.9445j, -1.4900-0.4247j,\n         -1.2382-1.9509j, -1.0963-1.5625j,  2.9038-3.2079j, -0.5822+0.2845j,\n          0.9791-3.9528j,  0.0905-1.4081j, -1.3682+1.1152j, -0.6271+2.6934j,\n         -0.3897+1.5245j, -1.5524+0.6851j,  2.3462+0.9499j],\n        [-0.3757+1.5211j, -0.0766-0.7497j, -0.9088-4.4242j,  0.7485-2.5050j,\n          3.4670+1.7022j, -0.2359+2.4059j,  6.1804+3.4211j,  1.5493+4.0911j,\n          3.8011+1.7283j,  0.9623-1.0593j, -2.8899+3.5935j, -1.5462-6.1322j,\n         -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\n       dtype=torch.complex128),\n    expected=tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n         -2.2407-0.2425j,  0.2035-0.4496j, -1.4810+6.0237j, -2.7851+5.4661j,\n          1.0553-0.2403j,  0.0873-0.8104j, -1.1095-2.7532j,  0.9891-1.2121j,\n          1.0592-1.9560j,  1.6624-1.7664j, -4.8020-1.0097j],\n        [ 0.0932-1.0632j, -0.4509-0.4323j,  2.0811+1.7304j,  0.3800-0.8042j,\n          0.3238+2.4538j,  0.8524-2.2710j,  0.0499+1.5906j, -1.5238-0.6702j,\n          0.5962+1.6630j, -0.6455+1.5747j, -2.1007-0.0765j,  1.2933-0.8246j,\n         -1.5839-1.2315j, -1.0250+1.5196j, -2.0119+0.1062j],\n        [ 2.0069+2.4952j, -1.0440-1.5923j,  0.3315-2.5119j,  1.2107-0.2472j,\n         -0.5795+5.2369j,  0.5261-1.1058j, -2.3623+1.7065j,  0.7529+2.0756j,\n         -5.2855+0.7199j, -2.7992-1.7865j,  3.3732+5.0895j,  3.1148-3.6782j,\n          3.3944-5.4787j, -1.4948+0.2726j, -3.2070-1.7407j],\n        [ 0.5631+0.3728j,  2.1828+0.7304j, -2.0065-0.9247j,  1.4199-1.5669j,\n          0.4063+1.2448j, -1.3820+3.1654j,  0.1917-0.0193j,  0.8475+0.1435j,\n         -1.5303+1.2521j, -1.4238+1.2681j,  0.3012+0.2479j, -0.5574-2.3543j,\n         -0.7846-1.3666j, -0.7856-0.3939j, -0.8274-0.1194j],\n        [ 0.0324-1.3909j, -0.1203-1.1888j,  0.2025-1.7234j,  0.7651+1.5668j,\n          1.6860-1.7981j, -2.2573+2.3233j, -0.1032-3.9325j, -0.2306+1.4186j,\n          1.0236-1.4330j,  0.1143+2.3022j, -3.2337-0.2989j, -1.5082+1.2465j,\n         -2.0147+2.8854j,  0.8310-1.0295j,  0.3954-0.6050j],\n        [ 0.6654+0.4144j,  1.7644-1.9366j,  2.3693-4.0231j, -0.5994-2.1161j,\n          1.0038-0.3162j,  2.5332-1.7920j,  2.7542+3.4991j,  1.6866+0.3422j,\n         -1.1227-3.1932j, -4.7747+0.5699j,  3.6253+3.3171j, -0.2686-1.8045j,\n          1.7770-3.1219j, -2.4701-0.3974j, -3.6862+3.8656j],\n        [-1.5845-4.1079j, -2.6810+1.0145j, -1.7226-2.2840j, -0.0131+0.5237j,\n         -1.1743-3.0424j, -1.1473-2.5228j,  4.2845+0.4488j,  0.3502-1.9410j,\n          0.9076-1.7757j, -2.4120+2.7608j, -0.6351-4.5906j, -0.2074+2.3495j,\n         -4.5655-0.2951j, -2.8301+1.4477j,  1.7459+4.2101j],\n        [ 2.0080+3.6980j,  1.8509+1.4753j,  0.9734+0.0503j,  1.6844-2.3884j,\n         -0.5182+1.8652j,  2.3675-3.0549j,  2.0761+0.7240j,  0.3014-0.5526j,\n         -2.8698-2.8279j, -0.4730+1.2654j,  0.6873+4.0866j,  0.4653-0.3643j,\n          3.9563+0.4844j,  0.9985+0.5925j, -1.1891+0.5809j],\n        [ 2.1716-3.8304j, -1.2221+1.8169j, -0.0692-0.6350j, -0.3843-0.8243j,\n          1.8068-2.3342j, -2.0383+4.2771j, -2.7129+0.1469j, -1.3979+5.2980j,\n          6.3524+0.5113j, -1.9399-2.2576j,  1.7695+0.4793j, -2.7231-2.0197j,\n         -3.0427+1.3365j,  1.5296+0.9722j, -3.2803-3.0723j],\n        [-2.2514-4.2055j,  2.1707+2.7620j, -0.1860+3.6809j,  0.5694-0.4102j,\n          0.5374+0.0499j, -1.9568+0.5323j, -0.9677-4.2970j, -1.5126-5.5865j,\n          0.8056-0.9773j, -1.2527+0.4486j, -3.0336-1.3061j,  2.9663+4.4681j,\n         -2.9028+1.7681j, -2.1636+0.9880j,  3.9667-0.4236j],\n        [ 1.0943-0.3210j,  2.6839-2.1928j, -0.8744+2.2169j,  0.4063+0.3018j,\n          1.3178-0.3794j,  3.1111+2.7784j,  0.4673-2.7608j,  0.7912-3.3635j,\n          2.3200-2.4908j, -4.9645+0.2920j, -1.1168-0.5327j, -1.9378+0.3959j,\n         -1.2669-0.1073j, -3.2050-1.0744j,  0.7029-1.3618j],\n        [-2.8384-2.6264j, -2.4609-0.8443j,  1.0664-0.9961j, -1.5841+2.1933j,\n         -3.0556-2.1011j,  1.0991-1.2765j, -1.3713+0.7826j, -1.6404+3.2083j,\n         -1.1352-6.0049j, -2.4649+2.8572j,  0.9221-2.8091j, -0.6556+1.9814j,\n         -1.0916+1.8894j,  0.9140+3.0368j, -1.4458-0.8892j],\n        [ 0.1730+0.1588j, -2.7033-0.0564j, -0.6712-2.7233j, -1.2555+0.6728j,\n          0.9580-0.2642j,  1.8653-1.6652j,  3.1011+3.9994j,  3.4555+1.8861j,\n         -2.9312-2.5952j, -1.9216-1.9427j,  4.8479-1.2849j, -3.8279+1.0860j,\n         -0.1752-2.4063j, -0.1576+0.0716j, -1.7031+3.0306j],\n        [ 1.8441-2.8727j, -1.9806-1.7925j, -2.0465-0.8138j, -0.0922+0.5836j,\n         -0.4304+1.5124j, -1.3604+0.6704j,  1.3084-2.5652j, -1.7110+1.1774j,\n          2.2672+3.0424j, -1.1253-0.6787j, -2.9825-1.3689j,  2.2006-0.3375j,\n         -3.7993-1.1757j, -1.8144+0.5795j,  1.2954-1.5418j],\n        [ 1.1885+2.6278j, -2.8391+1.5064j, -3.1722-3.6139j,  0.9402+0.3427j,\n         -5.2045+0.6148j,  0.2228-2.8052j,  3.6311+1.3205j,  1.7382+0.7886j,\n         -1.7540-3.9592j,  0.5841-0.9690j,  1.9703+0.9599j, -0.4767-0.1140j,\n          2.6081-1.5638j, -0.6958+0.5202j,  1.9002+2.3517j],\n        [-4.3929+2.3776j, -0.6929+1.6441j, -3.0393-1.8704j,  3.2515+1.3118j,\n         -4.7102+0.4514j,  1.6267+5.5787j,  1.6652+2.4810j,  0.5355+1.1179j,\n          2.0685+0.4092j, -3.1097+0.4923j, -6.3087-1.1432j,  2.3676-0.8362j,\n         -3.0167+2.2700j, -2.6130+1.5180j, -0.0586-0.5221j],\n        [ 0.7065+0.9403j, -2.6223-0.2074j, -4.0726-1.4891j,  2.2851+2.1597j,\n         -3.1355+3.9426j, -0.3742+0.0146j,  0.1524-1.9545j,  4.4762+1.0231j,\n         -5.0257-0.0337j,  0.5652+2.8865j, -1.8792-0.4799j, -0.3099+0.5276j,\n          0.6804-1.6629j, -0.1956-1.0923j, -0.5373+0.9113j],\n        [-3.6113+1.1066j, -0.0454+1.5766j, -3.6155+0.1328j,  1.2423+1.8670j,\n         -2.5789+0.9074j,  1.1183+3.1183j,  0.5903-2.3002j,  1.3157-0.3202j,\n         -3.3627-2.7827j, -4.1682+0.0735j, -2.0040-0.8566j,  1.8727+2.0009j,\n         -1.0795+2.0094j, -1.3459+1.7733j,  2.1572-2.0668j],\n        [-0.5685-2.6583j, -1.2080+0.2056j, -0.2720-0.9445j, -1.4900-0.4247j,\n         -1.2382-1.9509j, -1.0963-1.5625j,  2.9038-3.2079j, -0.5822+0.2845j,\n          0.9791-3.9528j,  0.0905-1.4081j, -1.3682+1.1152j, -0.6271+2.6934j,\n         -0.3897+1.5245j, -1.5524+0.6851j,  2.3462+0.9499j],\n        [-0.3757+1.5211j, -0.0766-0.7497j, -0.9088-4.4242j,  0.7485-2.5050j,\n          3.4670+1.7022j, -0.2359+2.4059j,  6.1804+3.4211j,  1.5493+4.0911j,\n          3.8011+1.7283j,  0.9623-1.0593j, -2.8899+3.5935j, -1.5462-6.1322j,\n         -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\n       dtype=torch.complex128),\n    rtol=1e-07,\n    atol=1e-07,\n    equal_nan=True,\n    check_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\nresulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 143,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 73,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "actual = tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n         -2.2407-0.2425j,  0.2035-0.4496j...2-6.1322j,\n         -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\n       dtype=torch.complex128)\nexpected = tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n         -2.2407-0.2425j,  0.2035-0.4496j...2-6.1322j,\n         -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\n       dtype=torch.complex128)\npair_types = (<class 'torch.testing._comparison.NonePair'>, <class 'torch.testing._internal.common_utils.RelaxedBooleanPair'>, <cla...<class 'torch.testing._internal.common_utils.StringPair'>, <class 'torch.testing._internal.common_utils.SetPair'>, ...)\nsequence_types = (<class 'collections.abc.Sequence'>, <class 'torch.storage._TypedStorage'>, <class 'torch.nn.modules.container.Sequent...nn.modules.container.ModuleList'>, <class 'torch.nn.modules.container.ParameterList'>, <class 'torch.ScriptList'>, ...)\nmapping_types = (<class 'collections.abc.Mapping'>, <class 'torch.nn.modules.container.ModuleDict'>, <class 'torch.nn.modules.container.ParameterDict'>, <class 'torch.ScriptDict'>)\nmsg = None, options = {'atol': None, 'atol_override': 0, 'check_device': False, 'check_dtype': True, ...}, __tracebackhide__ = True\npairs = [TensorOrArrayPair(\n    id=(),\n    actual=tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,...ck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)]\n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n>               pair.compare()\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1075: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\n    def compare(self) -> None:\n        actual, expected = self.actual, self.expected\n    \n        self._compare_attributes(actual, expected)\n        if any(input.device.type == \"meta\" for input in (actual, expected)):\n            return\n    \n        actual, expected = self._equalize_attributes(actual, expected)\n>       self._compare_values(actual, expected)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:620: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n         -2.2407-0.2425j,  0.2035-0.4496j...2-6.1322j,\n         -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\n       dtype=torch.complex128)\nexpected = tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n         -2.2407-0.2425j,  0.2035-0.4496j...2-6.1322j,\n         -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\n       dtype=torch.complex128)\n\n    def _compare_values(self, actual: torch.Tensor, expected: torch.Tensor) -> None:\n        if actual.is_quantized:\n            compare_fn = self._compare_quantized_values\n        elif actual.is_sparse:\n            compare_fn = self._compare_sparse_coo_values\n        elif actual.layout in {torch.sparse_csr, torch.sparse_csc, torch.sparse_bsr, torch.sparse_bsc}:\n            compare_fn = self._compare_sparse_compressed_values\n        else:\n            compare_fn = self._compare_regular_values_close\n    \n>       compare_fn(actual, expected, rtol=self.rtol, atol=self.atol, equal_nan=self.equal_nan)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:714: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n...eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n         -2.2407-0.2425j,  0.2035-0.4496j...2-6.1322j,\n         -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\n       dtype=torch.complex128)\nexpected = tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\n         -2.2407-0.2425j,  0.2035-0.4496j...2-6.1322j,\n         -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\n       dtype=torch.complex128)\n\n    def _compare_regular_values_close(\n        self,\n        actual: torch.Tensor,\n        expected: torch.Tensor,\n        *,\n        rtol: float,\n        atol: float,\n        equal_nan: bool,\n        identifier: Optional[Union[str, Callable[[str], str]]] = None,\n    ) -> None:\n        \"\"\"Checks if the values of two tensors are close up to a desired tolerance.\"\"\"\n        actual, expected = self._promote_for_comparison(actual, expected)\n        matches = torch.isclose(actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan)\n>       if torch.all(matches):\nE       RuntimeError: Error while lowering: [] aten::isnan\nE       XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE       Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:847: RuntimeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <src.pytorch_tests_reduced.size_test.TestLinalgXLA testMethod=test_mm_xla_complex128>, device = 'xla:1', dtype = torch.complex128\n\n    @dtypes(torch.float32, torch.float64, torch.int32, torch.int64, torch.cfloat, torch.cdouble)\n    @dtypesIfCUDA(torch.float32, torch.float64, torch.cfloat, torch.cdouble)\n    @tf32_on_and_off(0.01)\n    @onlyNativeDeviceTypes\n    def test_mm(self, device, dtype):\n    \n        def _test_mm(n, m, p, dtype, genf):\n            # helper function\n            def matrixmultiply(mat1, mat2):\n    \n                print(\"*** test size 1\")\n                with pytorch_op_timer():\n                    n = mat1.size(0)\n                print(\"*** test size 2\")\n                with pytorch_op_timer():\n                    m = mat1.size(1)\n                with pytorch_op_timer():\n                    p = mat2.size(1)\n                res = torch.zeros(n, p, dtype=dtype, device=device)\n                for i, j in iter_indices(res):\n                    res[i, j] = sum(mat1[i, k] * mat2[k, j] for k in range(m))\n                return res\n    \n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 1\n            mat1 = genf(n, m)\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 2\n            mat1 = genf(m, n).t()\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # test with zero stride\n            mat1 = genf(n, m)\n            mat2 = genf(m, 1).expand(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n        def genf_int(x, y):\n            return torch.randint(0, 100, (x, y), dtype=dtype, device=device)\n    \n        def genf_bfloat(x, y):\n            return torch.randn(x, y, dtype=torch.float32, device=device).to(dtype) * 0.1\n    \n        def genf_float(x, y):\n            return torch.randn(x, y, dtype=dtype, device=device)\n    \n        for (n, m, p) in [(20, 10, 15), (15, 20, 10), (25, 18, 10)]:\n            if (dtype == torch.int32) or (dtype == torch.int64):\n                genf = genf_int\n            elif (dtype == torch.bfloat16):\n                genf = genf_bfloat\n            else:\n                genf = genf_float\n    \n>           _test_mm(n, m, p, dtype, genf)\n\nsrc/pytorch_tests_reduced/size_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nn = 20, m = 10, p = 15, dtype = torch.complex128, genf = <function TestLinalg.test_mm.<locals>.genf_float at 0x7fcddb86bee0>\n\n    def _test_mm(n, m, p, dtype, genf):\n        # helper function\n        def matrixmultiply(mat1, mat2):\n    \n            print(\"*** test size 1\")\n            with pytorch_op_timer():\n                n = mat1.size(0)\n            print(\"*** test size 2\")\n            with pytorch_op_timer():\n                m = mat1.size(1)\n            with pytorch_op_timer():\n                p = mat2.size(1)\n            res = torch.zeros(n, p, dtype=dtype, device=device)\n            for i, j in iter_indices(res):\n                res[i, j] = sum(mat1[i, k] * mat2[k, j] for k in range(m))\n            return res\n    \n        # contiguous case\n        mat1 = genf(n, m)\n        mat2 = genf(m, p)\n        res = torch.mm(mat1, mat2)\n    \n        res2 = matrixmultiply(mat1, mat2)\n>       self.assertEqual(res, res2)\nE       RuntimeError: Comparing\nE       \nE       TensorOrArrayPair(\nE           id=(),\nE           actual=tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\nE                -2.2407-0.2425j,  0.2035-0.4496j, -1.4810+6.0237j, -2.7851+5.4661j,\nE                 1.0553-0.2403j,  0.0873-0.8104j, -1.1095-2.7532j,  0.9891-1.2121j,\nE                 1.0592-1.9560j,  1.6624-1.7664j, -4.8020-1.0097j],\nE               [ 0.0932-1.0632j, -0.4509-0.4323j,  2.0811+1.7304j,  0.3800-0.8042j,\nE                 0.3238+2.4538j,  0.8524-2.2710j,  0.0499+1.5906j, -1.5238-0.6702j,\nE                 0.5962+1.6630j, -0.6455+1.5747j, -2.1007-0.0765j,  1.2933-0.8246j,\nE                -1.5839-1.2315j, -1.0250+1.5196j, -2.0119+0.1062j],\nE               [ 2.0069+2.4952j, -1.0440-1.5923j,  0.3315-2.5119j,  1.2107-0.2472j,\nE                -0.5795+5.2369j,  0.5261-1.1058j, -2.3623+1.7065j,  0.7529+2.0756j,\nE                -5.2855+0.7199j, -2.7992-1.7865j,  3.3732+5.0895j,  3.1148-3.6782j,\nE                 3.3944-5.4787j, -1.4948+0.2726j, -3.2070-1.7407j],\nE               [ 0.5631+0.3728j,  2.1828+0.7304j, -2.0065-0.9247j,  1.4199-1.5669j,\nE                 0.4063+1.2448j, -1.3820+3.1654j,  0.1917-0.0193j,  0.8475+0.1435j,\nE                -1.5303+1.2521j, -1.4238+1.2681j,  0.3012+0.2479j, -0.5574-2.3543j,\nE                -0.7846-1.3666j, -0.7856-0.3939j, -0.8274-0.1194j],\nE               [ 0.0324-1.3909j, -0.1203-1.1888j,  0.2025-1.7234j,  0.7651+1.5668j,\nE                 1.6860-1.7981j, -2.2573+2.3233j, -0.1032-3.9325j, -0.2306+1.4186j,\nE                 1.0236-1.4330j,  0.1143+2.3022j, -3.2337-0.2989j, -1.5082+1.2465j,\nE                -2.0147+2.8854j,  0.8310-1.0295j,  0.3954-0.6050j],\nE               [ 0.6654+0.4144j,  1.7644-1.9366j,  2.3693-4.0231j, -0.5994-2.1161j,\nE                 1.0038-0.3162j,  2.5332-1.7920j,  2.7542+3.4991j,  1.6866+0.3422j,\nE                -1.1227-3.1932j, -4.7747+0.5699j,  3.6253+3.3171j, -0.2686-1.8045j,\nE                 1.7770-3.1219j, -2.4701-0.3974j, -3.6862+3.8656j],\nE               [-1.5845-4.1079j, -2.6810+1.0145j, -1.7226-2.2840j, -0.0131+0.5237j,\nE                -1.1743-3.0424j, -1.1473-2.5228j,  4.2845+0.4488j,  0.3502-1.9410j,\nE                 0.9076-1.7757j, -2.4120+2.7608j, -0.6351-4.5906j, -0.2074+2.3495j,\nE                -4.5655-0.2951j, -2.8301+1.4477j,  1.7459+4.2101j],\nE               [ 2.0080+3.6980j,  1.8509+1.4753j,  0.9734+0.0503j,  1.6844-2.3884j,\nE                -0.5182+1.8652j,  2.3675-3.0549j,  2.0761+0.7240j,  0.3014-0.5526j,\nE                -2.8698-2.8279j, -0.4730+1.2654j,  0.6873+4.0866j,  0.4653-0.3643j,\nE                 3.9563+0.4844j,  0.9985+0.5925j, -1.1891+0.5809j],\nE               [ 2.1716-3.8304j, -1.2221+1.8169j, -0.0692-0.6350j, -0.3843-0.8243j,\nE                 1.8068-2.3342j, -2.0383+4.2771j, -2.7129+0.1469j, -1.3979+5.2980j,\nE                 6.3524+0.5113j, -1.9399-2.2576j,  1.7695+0.4793j, -2.7231-2.0197j,\nE                -3.0427+1.3365j,  1.5296+0.9722j, -3.2803-3.0723j],\nE               [-2.2514-4.2055j,  2.1707+2.7620j, -0.1860+3.6809j,  0.5694-0.4102j,\nE                 0.5374+0.0499j, -1.9568+0.5323j, -0.9677-4.2970j, -1.5126-5.5865j,\nE                 0.8056-0.9773j, -1.2527+0.4486j, -3.0336-1.3061j,  2.9663+4.4681j,\nE                -2.9028+1.7681j, -2.1636+0.9880j,  3.9667-0.4236j],\nE               [ 1.0943-0.3210j,  2.6839-2.1928j, -0.8744+2.2169j,  0.4063+0.3018j,\nE                 1.3178-0.3794j,  3.1111+2.7784j,  0.4673-2.7608j,  0.7912-3.3635j,\nE                 2.3200-2.4908j, -4.9645+0.2920j, -1.1168-0.5327j, -1.9378+0.3959j,\nE                -1.2669-0.1073j, -3.2050-1.0744j,  0.7029-1.3618j],\nE               [-2.8384-2.6264j, -2.4609-0.8443j,  1.0664-0.9961j, -1.5841+2.1933j,\nE                -3.0556-2.1011j,  1.0991-1.2765j, -1.3713+0.7826j, -1.6404+3.2083j,\nE                -1.1352-6.0049j, -2.4649+2.8572j,  0.9221-2.8091j, -0.6556+1.9814j,\nE                -1.0916+1.8894j,  0.9140+3.0368j, -1.4458-0.8892j],\nE               [ 0.1730+0.1588j, -2.7033-0.0564j, -0.6712-2.7233j, -1.2555+0.6728j,\nE                 0.9580-0.2642j,  1.8653-1.6652j,  3.1011+3.9994j,  3.4555+1.8861j,\nE                -2.9312-2.5952j, -1.9216-1.9427j,  4.8479-1.2849j, -3.8279+1.0860j,\nE                -0.1752-2.4063j, -0.1576+0.0716j, -1.7031+3.0306j],\nE               [ 1.8441-2.8727j, -1.9806-1.7925j, -2.0465-0.8138j, -0.0922+0.5836j,\nE                -0.4304+1.5124j, -1.3604+0.6704j,  1.3084-2.5652j, -1.7110+1.1774j,\nE                 2.2672+3.0424j, -1.1253-0.6787j, -2.9825-1.3689j,  2.2006-0.3375j,\nE                -3.7993-1.1757j, -1.8144+0.5795j,  1.2954-1.5418j],\nE               [ 1.1885+2.6278j, -2.8391+1.5064j, -3.1722-3.6139j,  0.9402+0.3427j,\nE                -5.2045+0.6148j,  0.2228-2.8052j,  3.6311+1.3205j,  1.7382+0.7886j,\nE                -1.7540-3.9592j,  0.5841-0.9690j,  1.9703+0.9599j, -0.4767-0.1140j,\nE                 2.6081-1.5638j, -0.6958+0.5202j,  1.9002+2.3517j],\nE               [-4.3929+2.3776j, -0.6929+1.6441j, -3.0393-1.8704j,  3.2515+1.3118j,\nE                -4.7102+0.4514j,  1.6267+5.5787j,  1.6652+2.4810j,  0.5355+1.1179j,\nE                 2.0685+0.4092j, -3.1097+0.4923j, -6.3087-1.1432j,  2.3676-0.8362j,\nE                -3.0167+2.2700j, -2.6130+1.5180j, -0.0586-0.5221j],\nE               [ 0.7065+0.9403j, -2.6223-0.2074j, -4.0726-1.4891j,  2.2851+2.1597j,\nE                -3.1355+3.9426j, -0.3742+0.0146j,  0.1524-1.9545j,  4.4762+1.0231j,\nE                -5.0257-0.0337j,  0.5652+2.8865j, -1.8792-0.4799j, -0.3099+0.5276j,\nE                 0.6804-1.6629j, -0.1956-1.0923j, -0.5373+0.9113j],\nE               [-3.6113+1.1066j, -0.0454+1.5766j, -3.6155+0.1328j,  1.2423+1.8670j,\nE                -2.5789+0.9074j,  1.1183+3.1183j,  0.5903-2.3002j,  1.3157-0.3202j,\nE                -3.3627-2.7827j, -4.1682+0.0735j, -2.0040-0.8566j,  1.8727+2.0009j,\nE                -1.0795+2.0094j, -1.3459+1.7733j,  2.1572-2.0668j],\nE               [-0.5685-2.6583j, -1.2080+0.2056j, -0.2720-0.9445j, -1.4900-0.4247j,\nE                -1.2382-1.9509j, -1.0963-1.5625j,  2.9038-3.2079j, -0.5822+0.2845j,\nE                 0.9791-3.9528j,  0.0905-1.4081j, -1.3682+1.1152j, -0.6271+2.6934j,\nE                -0.3897+1.5245j, -1.5524+0.6851j,  2.3462+0.9499j],\nE               [-0.3757+1.5211j, -0.0766-0.7497j, -0.9088-4.4242j,  0.7485-2.5050j,\nE                 3.4670+1.7022j, -0.2359+2.4059j,  6.1804+3.4211j,  1.5493+4.0911j,\nE                 3.8011+1.7283j,  0.9623-1.0593j, -2.8899+3.5935j, -1.5462-6.1322j,\nE                -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\nE              dtype=torch.complex128),\nE           expected=tensor([[-0.2407+0.0481j, -0.2940-4.2108j,  5.8622-3.2904j, -1.2486+2.3209j,\nE                -2.2407-0.2425j,  0.2035-0.4496j, -1.4810+6.0237j, -2.7851+5.4661j,\nE                 1.0553-0.2403j,  0.0873-0.8104j, -1.1095-2.7532j,  0.9891-1.2121j,\nE                 1.0592-1.9560j,  1.6624-1.7664j, -4.8020-1.0097j],\nE               [ 0.0932-1.0632j, -0.4509-0.4323j,  2.0811+1.7304j,  0.3800-0.8042j,\nE                 0.3238+2.4538j,  0.8524-2.2710j,  0.0499+1.5906j, -1.5238-0.6702j,\nE                 0.5962+1.6630j, -0.6455+1.5747j, -2.1007-0.0765j,  1.2933-0.8246j,\nE                -1.5839-1.2315j, -1.0250+1.5196j, -2.0119+0.1062j],\nE               [ 2.0069+2.4952j, -1.0440-1.5923j,  0.3315-2.5119j,  1.2107-0.2472j,\nE                -0.5795+5.2369j,  0.5261-1.1058j, -2.3623+1.7065j,  0.7529+2.0756j,\nE                -5.2855+0.7199j, -2.7992-1.7865j,  3.3732+5.0895j,  3.1148-3.6782j,\nE                 3.3944-5.4787j, -1.4948+0.2726j, -3.2070-1.7407j],\nE               [ 0.5631+0.3728j,  2.1828+0.7304j, -2.0065-0.9247j,  1.4199-1.5669j,\nE                 0.4063+1.2448j, -1.3820+3.1654j,  0.1917-0.0193j,  0.8475+0.1435j,\nE                -1.5303+1.2521j, -1.4238+1.2681j,  0.3012+0.2479j, -0.5574-2.3543j,\nE                -0.7846-1.3666j, -0.7856-0.3939j, -0.8274-0.1194j],\nE               [ 0.0324-1.3909j, -0.1203-1.1888j,  0.2025-1.7234j,  0.7651+1.5668j,\nE                 1.6860-1.7981j, -2.2573+2.3233j, -0.1032-3.9325j, -0.2306+1.4186j,\nE                 1.0236-1.4330j,  0.1143+2.3022j, -3.2337-0.2989j, -1.5082+1.2465j,\nE                -2.0147+2.8854j,  0.8310-1.0295j,  0.3954-0.6050j],\nE               [ 0.6654+0.4144j,  1.7644-1.9366j,  2.3693-4.0231j, -0.5994-2.1161j,\nE                 1.0038-0.3162j,  2.5332-1.7920j,  2.7542+3.4991j,  1.6866+0.3422j,\nE                -1.1227-3.1932j, -4.7747+0.5699j,  3.6253+3.3171j, -0.2686-1.8045j,\nE                 1.7770-3.1219j, -2.4701-0.3974j, -3.6862+3.8656j],\nE               [-1.5845-4.1079j, -2.6810+1.0145j, -1.7226-2.2840j, -0.0131+0.5237j,\nE                -1.1743-3.0424j, -1.1473-2.5228j,  4.2845+0.4488j,  0.3502-1.9410j,\nE                 0.9076-1.7757j, -2.4120+2.7608j, -0.6351-4.5906j, -0.2074+2.3495j,\nE                -4.5655-0.2951j, -2.8301+1.4477j,  1.7459+4.2101j],\nE               [ 2.0080+3.6980j,  1.8509+1.4753j,  0.9734+0.0503j,  1.6844-2.3884j,\nE                -0.5182+1.8652j,  2.3675-3.0549j,  2.0761+0.7240j,  0.3014-0.5526j,\nE                -2.8698-2.8279j, -0.4730+1.2654j,  0.6873+4.0866j,  0.4653-0.3643j,\nE                 3.9563+0.4844j,  0.9985+0.5925j, -1.1891+0.5809j],\nE               [ 2.1716-3.8304j, -1.2221+1.8169j, -0.0692-0.6350j, -0.3843-0.8243j,\nE                 1.8068-2.3342j, -2.0383+4.2771j, -2.7129+0.1469j, -1.3979+5.2980j,\nE                 6.3524+0.5113j, -1.9399-2.2576j,  1.7695+0.4793j, -2.7231-2.0197j,\nE                -3.0427+1.3365j,  1.5296+0.9722j, -3.2803-3.0723j],\nE               [-2.2514-4.2055j,  2.1707+2.7620j, -0.1860+3.6809j,  0.5694-0.4102j,\nE                 0.5374+0.0499j, -1.9568+0.5323j, -0.9677-4.2970j, -1.5126-5.5865j,\nE                 0.8056-0.9773j, -1.2527+0.4486j, -3.0336-1.3061j,  2.9663+4.4681j,\nE                -2.9028+1.7681j, -2.1636+0.9880j,  3.9667-0.4236j],\nE               [ 1.0943-0.3210j,  2.6839-2.1928j, -0.8744+2.2169j,  0.4063+0.3018j,\nE                 1.3178-0.3794j,  3.1111+2.7784j,  0.4673-2.7608j,  0.7912-3.3635j,\nE                 2.3200-2.4908j, -4.9645+0.2920j, -1.1168-0.5327j, -1.9378+0.3959j,\nE                -1.2669-0.1073j, -3.2050-1.0744j,  0.7029-1.3618j],\nE               [-2.8384-2.6264j, -2.4609-0.8443j,  1.0664-0.9961j, -1.5841+2.1933j,\nE                -3.0556-2.1011j,  1.0991-1.2765j, -1.3713+0.7826j, -1.6404+3.2083j,\nE                -1.1352-6.0049j, -2.4649+2.8572j,  0.9221-2.8091j, -0.6556+1.9814j,\nE                -1.0916+1.8894j,  0.9140+3.0368j, -1.4458-0.8892j],\nE               [ 0.1730+0.1588j, -2.7033-0.0564j, -0.6712-2.7233j, -1.2555+0.6728j,\nE                 0.9580-0.2642j,  1.8653-1.6652j,  3.1011+3.9994j,  3.4555+1.8861j,\nE                -2.9312-2.5952j, -1.9216-1.9427j,  4.8479-1.2849j, -3.8279+1.0860j,\nE                -0.1752-2.4063j, -0.1576+0.0716j, -1.7031+3.0306j],\nE               [ 1.8441-2.8727j, -1.9806-1.7925j, -2.0465-0.8138j, -0.0922+0.5836j,\nE                -0.4304+1.5124j, -1.3604+0.6704j,  1.3084-2.5652j, -1.7110+1.1774j,\nE                 2.2672+3.0424j, -1.1253-0.6787j, -2.9825-1.3689j,  2.2006-0.3375j,\nE                -3.7993-1.1757j, -1.8144+0.5795j,  1.2954-1.5418j],\nE               [ 1.1885+2.6278j, -2.8391+1.5064j, -3.1722-3.6139j,  0.9402+0.3427j,\nE                -5.2045+0.6148j,  0.2228-2.8052j,  3.6311+1.3205j,  1.7382+0.7886j,\nE                -1.7540-3.9592j,  0.5841-0.9690j,  1.9703+0.9599j, -0.4767-0.1140j,\nE                 2.6081-1.5638j, -0.6958+0.5202j,  1.9002+2.3517j],\nE               [-4.3929+2.3776j, -0.6929+1.6441j, -3.0393-1.8704j,  3.2515+1.3118j,\nE                -4.7102+0.4514j,  1.6267+5.5787j,  1.6652+2.4810j,  0.5355+1.1179j,\nE                 2.0685+0.4092j, -3.1097+0.4923j, -6.3087-1.1432j,  2.3676-0.8362j,\nE                -3.0167+2.2700j, -2.6130+1.5180j, -0.0586-0.5221j],\nE               [ 0.7065+0.9403j, -2.6223-0.2074j, -4.0726-1.4891j,  2.2851+2.1597j,\nE                -3.1355+3.9426j, -0.3742+0.0146j,  0.1524-1.9545j,  4.4762+1.0231j,\nE                -5.0257-0.0337j,  0.5652+2.8865j, -1.8792-0.4799j, -0.3099+0.5276j,\nE                 0.6804-1.6629j, -0.1956-1.0923j, -0.5373+0.9113j],\nE               [-3.6113+1.1066j, -0.0454+1.5766j, -3.6155+0.1328j,  1.2423+1.8670j,\nE                -2.5789+0.9074j,  1.1183+3.1183j,  0.5903-2.3002j,  1.3157-0.3202j,\nE                -3.3627-2.7827j, -4.1682+0.0735j, -2.0040-0.8566j,  1.8727+2.0009j,\nE                -1.0795+2.0094j, -1.3459+1.7733j,  2.1572-2.0668j],\nE               [-0.5685-2.6583j, -1.2080+0.2056j, -0.2720-0.9445j, -1.4900-0.4247j,\nE                -1.2382-1.9509j, -1.0963-1.5625j,  2.9038-3.2079j, -0.5822+0.2845j,\nE                 0.9791-3.9528j,  0.0905-1.4081j, -1.3682+1.1152j, -0.6271+2.6934j,\nE                -0.3897+1.5245j, -1.5524+0.6851j,  2.3462+0.9499j],\nE               [-0.3757+1.5211j, -0.0766-0.7497j, -0.9088-4.4242j,  0.7485-2.5050j,\nE                 3.4670+1.7022j, -0.2359+2.4059j,  6.1804+3.4211j,  1.5493+4.0911j,\nE                 3.8011+1.7283j,  0.9623-1.0593j, -2.8899+3.5935j, -1.5462-6.1322j,\nE                -2.4087+0.6607j, -0.5551-0.8951j, -1.8146+3.2426j]], device='xla:1',\nE              dtype=torch.complex128),\nE           rtol=1e-07,\nE           atol=1e-07,\nE           equal_nan=True,\nE           check_device=False,\nE           check_dtype=True,\nE           check_layout=False,\nE           check_stride=False,\nE           check_is_coalesced=False,\nE       )\nE       \nE       resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.\n\nsrc/pytorch_tests_reduced/size_test.py:73: RuntimeError"
            },
            "teardown": {
                "duration": 0.00040697300028114114,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_complex64",
            "lineno": 43,
            "outcome": "failed",
            "setup": {
                "duration": 0.0005764369998360053,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.24574618299993745,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 143,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 72,
                        "message": "in _test_mm"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 56,
                        "message": "in matrixmultiply"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.size_test.TestLinalgXLA testMethod=test_mm_xla_complex64>, device = 'xla:1', dtype = torch.complex64\n\n    @dtypes(torch.float32, torch.float64, torch.int32, torch.int64, torch.cfloat, torch.cdouble)\n    @dtypesIfCUDA(torch.float32, torch.float64, torch.cfloat, torch.cdouble)\n    @tf32_on_and_off(0.01)\n    @onlyNativeDeviceTypes\n    def test_mm(self, device, dtype):\n    \n        def _test_mm(n, m, p, dtype, genf):\n            # helper function\n            def matrixmultiply(mat1, mat2):\n    \n                print(\"*** test size 1\")\n                with pytorch_op_timer():\n                    n = mat1.size(0)\n                print(\"*** test size 2\")\n                with pytorch_op_timer():\n                    m = mat1.size(1)\n                with pytorch_op_timer():\n                    p = mat2.size(1)\n                res = torch.zeros(n, p, dtype=dtype, device=device)\n                for i, j in iter_indices(res):\n                    res[i, j] = sum(mat1[i, k] * mat2[k, j] for k in range(m))\n                return res\n    \n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 1\n            mat1 = genf(n, m)\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 2\n            mat1 = genf(m, n).t()\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # test with zero stride\n            mat1 = genf(n, m)\n            mat2 = genf(m, 1).expand(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n        def genf_int(x, y):\n            return torch.randint(0, 100, (x, y), dtype=dtype, device=device)\n    \n        def genf_bfloat(x, y):\n            return torch.randn(x, y, dtype=torch.float32, device=device).to(dtype) * 0.1\n    \n        def genf_float(x, y):\n            return torch.randn(x, y, dtype=dtype, device=device)\n    \n        for (n, m, p) in [(20, 10, 15), (15, 20, 10), (25, 18, 10)]:\n            if (dtype == torch.int32) or (dtype == torch.int64):\n                genf = genf_int\n            elif (dtype == torch.bfloat16):\n                genf = genf_bfloat\n            else:\n                genf = genf_float\n    \n>           _test_mm(n, m, p, dtype, genf)\n\nsrc/pytorch_tests_reduced/size_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/size_test.py:72: in _test_mm\n    res2 = matrixmultiply(mat1, mat2)\nsrc/pytorch_tests_reduced/size_test.py:56: in matrixmultiply\n    n = mat1.size(0)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00019070500002271729,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_float32",
            "lineno": 43,
            "outcome": "failed",
            "setup": {
                "duration": 0.00038607999977102736,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.21039101499991375,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 143,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 72,
                        "message": "in _test_mm"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 56,
                        "message": "in matrixmultiply"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.size_test.TestLinalgXLA testMethod=test_mm_xla_float32>, device = 'xla:1', dtype = torch.float32\n\n    @dtypes(torch.float32, torch.float64, torch.int32, torch.int64, torch.cfloat, torch.cdouble)\n    @dtypesIfCUDA(torch.float32, torch.float64, torch.cfloat, torch.cdouble)\n    @tf32_on_and_off(0.01)\n    @onlyNativeDeviceTypes\n    def test_mm(self, device, dtype):\n    \n        def _test_mm(n, m, p, dtype, genf):\n            # helper function\n            def matrixmultiply(mat1, mat2):\n    \n                print(\"*** test size 1\")\n                with pytorch_op_timer():\n                    n = mat1.size(0)\n                print(\"*** test size 2\")\n                with pytorch_op_timer():\n                    m = mat1.size(1)\n                with pytorch_op_timer():\n                    p = mat2.size(1)\n                res = torch.zeros(n, p, dtype=dtype, device=device)\n                for i, j in iter_indices(res):\n                    res[i, j] = sum(mat1[i, k] * mat2[k, j] for k in range(m))\n                return res\n    \n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 1\n            mat1 = genf(n, m)\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 2\n            mat1 = genf(m, n).t()\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # test with zero stride\n            mat1 = genf(n, m)\n            mat2 = genf(m, 1).expand(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n        def genf_int(x, y):\n            return torch.randint(0, 100, (x, y), dtype=dtype, device=device)\n    \n        def genf_bfloat(x, y):\n            return torch.randn(x, y, dtype=torch.float32, device=device).to(dtype) * 0.1\n    \n        def genf_float(x, y):\n            return torch.randn(x, y, dtype=dtype, device=device)\n    \n        for (n, m, p) in [(20, 10, 15), (15, 20, 10), (25, 18, 10)]:\n            if (dtype == torch.int32) or (dtype == torch.int64):\n                genf = genf_int\n            elif (dtype == torch.bfloat16):\n                genf = genf_bfloat\n            else:\n                genf = genf_float\n    \n>           _test_mm(n, m, p, dtype, genf)\n\nsrc/pytorch_tests_reduced/size_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/size_test.py:72: in _test_mm\n    res2 = matrixmultiply(mat1, mat2)\nsrc/pytorch_tests_reduced/size_test.py:56: in matrixmultiply\n    n = mat1.size(0)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00023646299996471498,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_float64",
            "lineno": 43,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003963489998568548,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.19982459000038943,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 143,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 72,
                        "message": "in _test_mm"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 56,
                        "message": "in matrixmultiply"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.size_test.TestLinalgXLA testMethod=test_mm_xla_float64>, device = 'xla:1', dtype = torch.float64\n\n    @dtypes(torch.float32, torch.float64, torch.int32, torch.int64, torch.cfloat, torch.cdouble)\n    @dtypesIfCUDA(torch.float32, torch.float64, torch.cfloat, torch.cdouble)\n    @tf32_on_and_off(0.01)\n    @onlyNativeDeviceTypes\n    def test_mm(self, device, dtype):\n    \n        def _test_mm(n, m, p, dtype, genf):\n            # helper function\n            def matrixmultiply(mat1, mat2):\n    \n                print(\"*** test size 1\")\n                with pytorch_op_timer():\n                    n = mat1.size(0)\n                print(\"*** test size 2\")\n                with pytorch_op_timer():\n                    m = mat1.size(1)\n                with pytorch_op_timer():\n                    p = mat2.size(1)\n                res = torch.zeros(n, p, dtype=dtype, device=device)\n                for i, j in iter_indices(res):\n                    res[i, j] = sum(mat1[i, k] * mat2[k, j] for k in range(m))\n                return res\n    \n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 1\n            mat1 = genf(n, m)\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 2\n            mat1 = genf(m, n).t()\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # test with zero stride\n            mat1 = genf(n, m)\n            mat2 = genf(m, 1).expand(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n        def genf_int(x, y):\n            return torch.randint(0, 100, (x, y), dtype=dtype, device=device)\n    \n        def genf_bfloat(x, y):\n            return torch.randn(x, y, dtype=torch.float32, device=device).to(dtype) * 0.1\n    \n        def genf_float(x, y):\n            return torch.randn(x, y, dtype=dtype, device=device)\n    \n        for (n, m, p) in [(20, 10, 15), (15, 20, 10), (25, 18, 10)]:\n            if (dtype == torch.int32) or (dtype == torch.int64):\n                genf = genf_int\n            elif (dtype == torch.bfloat16):\n                genf = genf_bfloat\n            else:\n                genf = genf_float\n    \n>           _test_mm(n, m, p, dtype, genf)\n\nsrc/pytorch_tests_reduced/size_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/size_test.py:72: in _test_mm\n    res2 = matrixmultiply(mat1, mat2)\nsrc/pytorch_tests_reduced/size_test.py:56: in matrixmultiply\n    n = mat1.size(0)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00020407900046848226,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_int32",
            "lineno": 43,
            "outcome": "failed",
            "setup": {
                "duration": 0.000363338000170188,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.8909403369998472,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 143,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 72,
                        "message": "in _test_mm"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 56,
                        "message": "in matrixmultiply"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.size_test.TestLinalgXLA testMethod=test_mm_xla_int32>, device = 'xla:1', dtype = torch.int32\n\n    @dtypes(torch.float32, torch.float64, torch.int32, torch.int64, torch.cfloat, torch.cdouble)\n    @dtypesIfCUDA(torch.float32, torch.float64, torch.cfloat, torch.cdouble)\n    @tf32_on_and_off(0.01)\n    @onlyNativeDeviceTypes\n    def test_mm(self, device, dtype):\n    \n        def _test_mm(n, m, p, dtype, genf):\n            # helper function\n            def matrixmultiply(mat1, mat2):\n    \n                print(\"*** test size 1\")\n                with pytorch_op_timer():\n                    n = mat1.size(0)\n                print(\"*** test size 2\")\n                with pytorch_op_timer():\n                    m = mat1.size(1)\n                with pytorch_op_timer():\n                    p = mat2.size(1)\n                res = torch.zeros(n, p, dtype=dtype, device=device)\n                for i, j in iter_indices(res):\n                    res[i, j] = sum(mat1[i, k] * mat2[k, j] for k in range(m))\n                return res\n    \n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 1\n            mat1 = genf(n, m)\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 2\n            mat1 = genf(m, n).t()\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # test with zero stride\n            mat1 = genf(n, m)\n            mat2 = genf(m, 1).expand(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n        def genf_int(x, y):\n            return torch.randint(0, 100, (x, y), dtype=dtype, device=device)\n    \n        def genf_bfloat(x, y):\n            return torch.randn(x, y, dtype=torch.float32, device=device).to(dtype) * 0.1\n    \n        def genf_float(x, y):\n            return torch.randn(x, y, dtype=dtype, device=device)\n    \n        for (n, m, p) in [(20, 10, 15), (15, 20, 10), (25, 18, 10)]:\n            if (dtype == torch.int32) or (dtype == torch.int64):\n                genf = genf_int\n            elif (dtype == torch.bfloat16):\n                genf = genf_bfloat\n            else:\n                genf = genf_float\n    \n>           _test_mm(n, m, p, dtype, genf)\n\nsrc/pytorch_tests_reduced/size_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/size_test.py:72: in _test_mm\n    res2 = matrixmultiply(mat1, mat2)\nsrc/pytorch_tests_reduced/size_test.py:56: in matrixmultiply\n    n = mat1.size(0)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.0002043900003627641,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/size_test.py::TestLinalgXLA::test_mm_xla_int64",
            "lineno": 43,
            "outcome": "failed",
            "setup": {
                "duration": 0.00040313200042874087,
                "outcome": "passed"
            },
            "call": {
                "duration": 4.432059173000198,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 143,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 72,
                        "message": "in _test_mm"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/size_test.py",
                        "lineno": 56,
                        "message": "in matrixmultiply"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.size_test.TestLinalgXLA testMethod=test_mm_xla_int64>, device = 'xla:1', dtype = torch.int64\n\n    @dtypes(torch.float32, torch.float64, torch.int32, torch.int64, torch.cfloat, torch.cdouble)\n    @dtypesIfCUDA(torch.float32, torch.float64, torch.cfloat, torch.cdouble)\n    @tf32_on_and_off(0.01)\n    @onlyNativeDeviceTypes\n    def test_mm(self, device, dtype):\n    \n        def _test_mm(n, m, p, dtype, genf):\n            # helper function\n            def matrixmultiply(mat1, mat2):\n    \n                print(\"*** test size 1\")\n                with pytorch_op_timer():\n                    n = mat1.size(0)\n                print(\"*** test size 2\")\n                with pytorch_op_timer():\n                    m = mat1.size(1)\n                with pytorch_op_timer():\n                    p = mat2.size(1)\n                res = torch.zeros(n, p, dtype=dtype, device=device)\n                for i, j in iter_indices(res):\n                    res[i, j] = sum(mat1[i, k] * mat2[k, j] for k in range(m))\n                return res\n    \n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 1\n            mat1 = genf(n, m)\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 2\n            mat1 = genf(m, n).t()\n            mat2 = genf(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # test with zero stride\n            mat1 = genf(n, m)\n            mat2 = genf(m, 1).expand(m, p)\n            res = torch.mm(mat1, mat2)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # contiguous case\n            mat1 = genf(n, m)\n            mat2 = genf(m, p)\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n    \n            # explicitly exercise the _out variant in torch.mm().\n            # non contiguous case 3\n            mat1 = genf(m, n).t()\n            mat2 = genf(p, m).t()\n            res = genf(n, p)\n            torch.mm(mat1, mat2, out=res)\n    \n            res2 = matrixmultiply(mat1, mat2)\n            self.assertEqual(res, res2)\n        def genf_int(x, y):\n            return torch.randint(0, 100, (x, y), dtype=dtype, device=device)\n    \n        def genf_bfloat(x, y):\n            return torch.randn(x, y, dtype=torch.float32, device=device).to(dtype) * 0.1\n    \n        def genf_float(x, y):\n            return torch.randn(x, y, dtype=dtype, device=device)\n    \n        for (n, m, p) in [(20, 10, 15), (15, 20, 10), (25, 18, 10)]:\n            if (dtype == torch.int32) or (dtype == torch.int64):\n                genf = genf_int\n            elif (dtype == torch.bfloat16):\n                genf = genf_bfloat\n            else:\n                genf = genf_float\n    \n>           _test_mm(n, m, p, dtype, genf)\n\nsrc/pytorch_tests_reduced/size_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/size_test.py:72: in _test_mm\n    res2 = matrixmultiply(mat1, mat2)\nsrc/pytorch_tests_reduced/size_test.py:56: in matrixmultiply\n    n = mat1.size(0)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00029233700024633436,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeCPU::test_nn_scalars_reductions_cpu",
            "lineno": 87,
            "outcome": "failed",
            "setup": {
                "duration": 0.0004477889997360762,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.2004310259999329,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 110,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.smoothl1loss_test.TestNNDeviceTypeCPU testMethod=test_nn_scalars_reductions_cpu>, device = 'cpu'\n\n    def test_nn_scalars_reductions(self, device):\n        torch.set_default_dtype(torch.double)\n        # One off tests to ensure scalars from nn.yaml are properly applied\n        def verify_reduction_scalars(input, reduction, output):\n            if reduction != 'none' or input.dim() == 0:\n                self.assertEqual((), output.shape)\n            else:\n                self.assertNotEqual((), output.shape)\n            output.sum().backward()\n            self.assertEqual(input.shape, input.grad.shape)\n    \n        for input_shape in [(5, 6), ()]:\n            for reduction in ['none', 'mean', 'sum']:\n                for module in [torch.nn.SmoothL1Loss]:\n                    input = torch.randn(\n                        input_shape, device=device, requires_grad=True)\n                    target = torch.empty(input_shape, device=device).random_(2)\n                    sigmoid = nn.Sigmoid()\n    \n                    input = torch.randn(\n                        input_shape, device=device, requires_grad=True)\n                    with pytorch_op_timer():\n>                       m = module(reduction=reduction)\n\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:110: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00019793299998127623,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeCPU::test_smooth_l1_loss_bfloat16_cpu",
            "lineno": 188,
            "outcome": "failed",
            "setup": {
                "duration": 0.00035206099983042805,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.19963538800038805,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 213,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 207,
                        "message": "in func"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.smoothl1loss_test.TestNNDeviceTypeCPU testMethod=test_smooth_l1_loss_bfloat16_cpu>, device = 'cpu'\n\n    def test_smooth_l1_loss_bfloat16(self, device):\n        torch.set_default_dtype(torch.double)\n        def test_dtype(fn, input, target, dtype):\n            input = input.detach().clone().to(dtype=dtype).requires_grad_(True)\n            input2 = input.detach().clone().float().requires_grad_(True)\n            target = target.detach().clone().to(dtype=dtype)\n            target2 = target.detach().clone().float()\n            out = fn(input, target)\n            out.sum().backward()\n            out2 = fn(input2, target2)\n            out2.sum().backward()\n            self.assertEqual(out.dtype, dtype)\n            self.assertEqual(input.grad.dtype, dtype)\n            self.assertEqual(out, out2, exact_dtype=False)\n            self.assertEqual(input.grad, input2.grad, exact_dtype=False)\n    \n        def func(device):\n            with pytorch_op_timer():\n                return nn.SmoothL1Loss().to(device=device)\n    \n        shapes = [[1, 3, 1, 6], [1, 3, 1, 128], [1, 3, 128, 128]]\n        for shape in shapes:\n            x = torch.randn(shape, device=device, requires_grad=True)\n            t = torch.randn(shape, device=device)\n>           test_dtype(func(device), x, t, torch.bfloat16)\n\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/smoothl1loss_test.py:207: in func\n    return nn.SmoothL1Loss().to(device=device)\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00020266200044716243,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeCPU::test_smooth_l1_loss_vs_huber_loss_cpu",
            "lineno": 114,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003476069996395381,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.19840326000030473,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 183,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 172,
                        "message": "in test_equal_when_beta_is_one"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 150,
                        "message": "in _test_smooth_l1_loss_vs_huber_loss_multi_input_helper"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 133,
                        "message": "in _test_smooth_l1_loss_vs_huber_loss_helper"
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.smoothl1loss_test.TestNNDeviceTypeCPU testMethod=test_smooth_l1_loss_vs_huber_loss_cpu>, device = 'cpu'\n\n    @onlyNativeDeviceTypes\n    def test_smooth_l1_loss_vs_huber_loss(self, device):\n        torch.set_default_dtype(torch.double)\n        def _make_test_tensor(shape, contiguous=True):\n            if contiguous:\n                test_tensor = torch.randn(shape, device=device)\n            else:\n                # Select every other element in the innermost dimension to\n                # make it non-contiguous.\n                doubled_shape = list(shape)\n                doubled_shape[-1] *= 2\n                test_tensor = torch.randn(doubled_shape, device=device)\n                test_tensor = test_tensor[..., ::2]\n            return test_tensor\n    \n        def _test_smooth_l1_loss_vs_huber_loss_helper(input, target, beta, require_equal):\n            for reduction in ['mean', 'sum', 'none']:\n                with pytorch_op_timer():\n                    smooth_l1 = torch.nn.SmoothL1Loss(\n                    beta=beta, reduction=reduction)\n                # beta hyper-parameter is called delta for Huber\n                huber = torch.nn.HuberLoss(delta=beta, reduction=reduction)\n                smooth_l1_loss = smooth_l1(input, target)\n                huber_loss = huber(input, target)\n    \n                if require_equal:\n    \n                    self.assertEqual(smooth_l1_loss, huber_loss)\n                else:\n                    # Huber loss should be larger than smooth L1 loss by a factor of beta.\n                    self.assertEqual(smooth_l1_loss * beta, huber_loss)\n    \n        def _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(beta, require_equal):\n            # Test the non-vectorized case.\n            shape = (2, 2)\n            _test_smooth_l1_loss_vs_huber_loss_helper(input=_make_test_tensor(shape),\n                                                      target=_make_test_tensor(\n                                                          shape),\n                                                      beta=beta,\n                                                      require_equal=require_equal)\n    \n            # Test the vectorized case (innermost dim > 32).\n            shape = (64, 64)\n            _test_smooth_l1_loss_vs_huber_loss_helper(input=_make_test_tensor(shape),\n                                                      target=_make_test_tensor(\n                                                          shape),\n                                                      beta=beta,\n                                                      require_equal=require_equal)\n    \n            # Test the non-contiguous case.\n            _test_smooth_l1_loss_vs_huber_loss_helper(input=_make_test_tensor(shape, contiguous=False),\n                                                      target=_make_test_tensor(\n                                                          shape, contiguous=False),\n                                                      beta=beta,\n                                                      require_equal=require_equal)\n    \n        def test_equal_when_beta_is_one():\n            _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(\n                beta=1.0, require_equal=True)\n    \n        def test_unequal_when_beta_is_less_than_one():\n            _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(\n                beta=0.5, require_equal=False)\n    \n        def test_unequal_when_beta_is_greater_than_one():\n            _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(\n                beta=1.5, require_equal=False)\n    \n>       test_equal_when_beta_is_one()\n\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:183: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/smoothl1loss_test.py:172: in test_equal_when_beta_is_one\n    _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:150: in _test_smooth_l1_loss_vs_huber_loss_multi_input_helper\n    _test_smooth_l1_loss_vs_huber_loss_helper(input=_make_test_tensor(shape),\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:133: in _test_smooth_l1_loss_vs_huber_loss_helper\n    smooth_l1 = torch.nn.SmoothL1Loss(\n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00025871100024232874,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeXLA::test_nn_scalars_reductions_xla",
            "lineno": 87,
            "outcome": "failed",
            "setup": {
                "duration": 0.0024504029997842736,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.2057924370001274,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] aten::isnan\nXLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 110,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.smoothl1loss_test.TestNNDeviceTypeXLA testMethod=test_nn_scalars_reductions_xla>, device = 'xla:1'\n\n    def test_nn_scalars_reductions(self, device):\n        torch.set_default_dtype(torch.double)\n        # One off tests to ensure scalars from nn.yaml are properly applied\n        def verify_reduction_scalars(input, reduction, output):\n            if reduction != 'none' or input.dim() == 0:\n                self.assertEqual((), output.shape)\n            else:\n                self.assertNotEqual((), output.shape)\n            output.sum().backward()\n            self.assertEqual(input.shape, input.grad.shape)\n    \n        for input_shape in [(5, 6), ()]:\n            for reduction in ['none', 'mean', 'sum']:\n                for module in [torch.nn.SmoothL1Loss]:\n                    input = torch.randn(\n                        input_shape, device=device, requires_grad=True)\n                    target = torch.empty(input_shape, device=device).random_(2)\n                    sigmoid = nn.Sigmoid()\n    \n                    input = torch.randn(\n                        input_shape, device=device, requires_grad=True)\n                    with pytorch_op_timer():\n>                       m = module(reduction=reduction)\n\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:110: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] aten::isnan\nE     XLA builder error: INVALID_ARGUMENT: Operands to IsNan must be real-valued floating-point, but got C64: \nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.00022126700059743598,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeXLA::test_smooth_l1_loss_bfloat16_xla",
            "lineno": 188,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004324530000303639,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.6396713600006478,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00021935299992037471,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/smoothl1loss_test.py::TestNNDeviceTypeXLA::test_smooth_l1_loss_vs_huber_loss_xla",
            "lineno": 114,
            "outcome": "failed",
            "setup": {
                "duration": 0.0004274749999240157,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.1561822020003092,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/smoothl1loss_test.py",
                    "lineno": 142,
                    "message": "AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 183,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 172,
                        "message": "in test_equal_when_beta_is_one"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 150,
                        "message": "in _test_smooth_l1_loss_vs_huber_loss_multi_input_helper"
                    },
                    {
                        "path": "src/pytorch_tests_reduced/smoothl1loss_test.py",
                        "lineno": 142,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.smoothl1loss_test.TestNNDeviceTypeXLA testMethod=test_smooth_l1_loss_vs_huber_loss_xla>, device = 'xla:1'\n\n    @onlyNativeDeviceTypes\n    def test_smooth_l1_loss_vs_huber_loss(self, device):\n        torch.set_default_dtype(torch.double)\n        def _make_test_tensor(shape, contiguous=True):\n            if contiguous:\n                test_tensor = torch.randn(shape, device=device)\n            else:\n                # Select every other element in the innermost dimension to\n                # make it non-contiguous.\n                doubled_shape = list(shape)\n                doubled_shape[-1] *= 2\n                test_tensor = torch.randn(doubled_shape, device=device)\n                test_tensor = test_tensor[..., ::2]\n            return test_tensor\n    \n        def _test_smooth_l1_loss_vs_huber_loss_helper(input, target, beta, require_equal):\n            for reduction in ['mean', 'sum', 'none']:\n                with pytorch_op_timer():\n                    smooth_l1 = torch.nn.SmoothL1Loss(\n                    beta=beta, reduction=reduction)\n                # beta hyper-parameter is called delta for Huber\n                huber = torch.nn.HuberLoss(delta=beta, reduction=reduction)\n                smooth_l1_loss = smooth_l1(input, target)\n                huber_loss = huber(input, target)\n    \n                if require_equal:\n    \n                    self.assertEqual(smooth_l1_loss, huber_loss)\n                else:\n                    # Huber loss should be larger than smooth L1 loss by a factor of beta.\n                    self.assertEqual(smooth_l1_loss * beta, huber_loss)\n    \n        def _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(beta, require_equal):\n            # Test the non-vectorized case.\n            shape = (2, 2)\n            _test_smooth_l1_loss_vs_huber_loss_helper(input=_make_test_tensor(shape),\n                                                      target=_make_test_tensor(\n                                                          shape),\n                                                      beta=beta,\n                                                      require_equal=require_equal)\n    \n            # Test the vectorized case (innermost dim > 32).\n            shape = (64, 64)\n            _test_smooth_l1_loss_vs_huber_loss_helper(input=_make_test_tensor(shape),\n                                                      target=_make_test_tensor(\n                                                          shape),\n                                                      beta=beta,\n                                                      require_equal=require_equal)\n    \n            # Test the non-contiguous case.\n            _test_smooth_l1_loss_vs_huber_loss_helper(input=_make_test_tensor(shape, contiguous=False),\n                                                      target=_make_test_tensor(\n                                                          shape, contiguous=False),\n                                                      beta=beta,\n                                                      require_equal=require_equal)\n    \n        def test_equal_when_beta_is_one():\n            _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(\n                beta=1.0, require_equal=True)\n    \n        def test_unequal_when_beta_is_less_than_one():\n            _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(\n                beta=0.5, require_equal=False)\n    \n        def test_unequal_when_beta_is_greater_than_one():\n            _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(\n                beta=1.5, require_equal=False)\n    \n>       test_equal_when_beta_is_one()\n\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:183: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/pytorch_tests_reduced/smoothl1loss_test.py:172: in test_equal_when_beta_is_one\n    _test_smooth_l1_loss_vs_huber_loss_multi_input_helper(\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:150: in _test_smooth_l1_loss_vs_huber_loss_multi_input_helper\n    _test_smooth_l1_loss_vs_huber_loss_helper(input=_make_test_tensor(shape),\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ninput = tensor([[-0.9401, -1.5591],\n        [ 0.0103, -0.8474]], device='xla:1')\ntarget = tensor([[ 0.2184, -1.0644],\n        [ 0.4854,  0.8265]], device='xla:1'), beta = 1.0, require_equal = True\n\n    def _test_smooth_l1_loss_vs_huber_loss_helper(input, target, beta, require_equal):\n        for reduction in ['mean', 'sum', 'none']:\n            with pytorch_op_timer():\n                smooth_l1 = torch.nn.SmoothL1Loss(\n                beta=beta, reduction=reduction)\n            # beta hyper-parameter is called delta for Huber\n            huber = torch.nn.HuberLoss(delta=beta, reduction=reduction)\n            smooth_l1_loss = smooth_l1(input, target)\n            huber_loss = huber(input, target)\n    \n            if require_equal:\n    \n>               self.assertEqual(smooth_l1_loss, huber_loss)\nE               AssertionError: The values for attribute 'dtype' do not match: torch.float32 != torch.float64.\n\nsrc/pytorch_tests_reduced/smoothl1loss_test.py:142: AssertionError"
            },
            "teardown": {
                "duration": 0.00022977400021773065,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestNNCPU::test_state_dict_cpu",
            "lineno": 88,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004617099993993179,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01882170099997893,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015812399942660704,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestNNXLA::test_state_dict_xla",
            "lineno": 88,
            "outcome": "passed",
            "setup": {
                "duration": 0.0020782490000783582,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.28188887600026646,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0002341720000913483,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU::test_load_state_dict_module_pre_hook_cpu",
            "lineno": 195,
            "outcome": "passed",
            "setup": {
                "duration": 0.00043774200003099395,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0018342420007684268,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014392899993254105,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU::test_load_state_dict_post_hook_backward_compatibility_cpu",
            "lineno": 329,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002988940004797769,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.005293416999847977,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012644700018427102,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU::test_load_state_dict_post_hook_cpu",
            "lineno": 264,
            "outcome": "passed",
            "setup": {
                "duration": 0.00031737399967823876,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0020810599999094848,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011672700020426419,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksCPU::test_load_state_dict_pre_hook_cpu",
            "lineno": 162,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002706080003918032,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002057351999610546,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00017400500018993625,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA::test_load_state_dict_module_pre_hook_xla",
            "lineno": 195,
            "outcome": "passed",
            "setup": {
                "duration": 0.0021328370003175223,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06663780100006989,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015682199955335818,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA::test_load_state_dict_post_hook_backward_compatibility_xla",
            "lineno": 329,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033052700018743053,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0044896170002175495,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013466400014294777,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA::test_load_state_dict_post_hook_xla",
            "lineno": 264,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036418499985302333,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00789287199950195,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013216400020610308,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/state_dict_test.py::TestStateDictHooksXLA::test_load_state_dict_pre_hook_xla",
            "lineno": 162,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003337660000397591,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.16962779400000727,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000237768000260985,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestSumCPU::test_sum_cpu",
            "lineno": 32,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004630250004993286,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.013258680000035383,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00016445800065412186,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/sum_test.py::TestSumXLA::test_sum_xla",
            "lineno": 32,
            "outcome": "passed",
            "setup": {
                "duration": 0.001987212999665644,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.030288765000477724,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015993099987099413,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/synchronize_test.py::TestCuda::test_copy_streams",
            "lineno": 117,
            "outcome": "failed",
            "setup": {
                "duration": 0.00036077299955650233,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.00339632499981235,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py",
                    "lineno": 217,
                    "message": "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/synchronize_test.py",
                        "lineno": 120,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py",
                        "lineno": 217,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.synchronize_test.TestCuda testMethod=test_copy_streams>\n\n    def test_copy_streams(self):\n        d0 = torch.device('cuda:0')\n>       x0 = torch.zeros(5, 5, device=d0)\n\nsrc/pytorch_tests_reduced/synchronize_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def _lazy_init():\n        global _initialized, _queued_calls\n        if is_initialized() or hasattr(_tls, 'is_initializing'):\n            return\n        with _initialization_lock:\n            # We be double-checked locking, boys!  This is OK because\n            # the above test was GIL protected anyway.  The inner test\n            # is for when a thread blocked on some other thread which was\n            # doing the initialization; when they get the lock, they will\n            # find there is nothing left to do.\n            if is_initialized():\n                return\n            # It is important to prevent other threads from entering _lazy_init\n            # immediately, while we are still guaranteed to have the GIL, because some\n            # of the C calls we make below will release the GIL\n            if _is_in_bad_fork():\n                raise RuntimeError(\n                    \"Cannot re-initialize CUDA in forked subprocess. To use CUDA with \"\n                    \"multiprocessing, you must use the 'spawn' start method\")\n            if not hasattr(torch._C, '_cuda_getDeviceCount'):\n                raise AssertionError(\"Torch not compiled with CUDA enabled\")\n            if _cudart is None:\n                raise AssertionError(\n                    \"libcudart functions unavailable. It looks like you have a broken build?\")\n            # This function throws if there's a driver initialization error, no GPUs\n            # are found or any other error occurs\n>           torch._C._cuda_init()\nE           RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n\n/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:217: RuntimeError"
            },
            "teardown": {
                "duration": 0.00016351300018868642,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestTorchCPU::test_tensor_set_cpu",
            "lineno": 66,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003432419998716796,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0019932169998355675,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013558399950852618,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/tensor_test.py::TestTorchXLA::test_tensor_set_xla",
            "lineno": 66,
            "outcome": "failed",
            "setup": {
                "duration": 0.0018971059998875717,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.04158861599989905,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py",
                    "lineno": 205,
                    "message": "RuntimeError: torch_xla/csrc/tensor_impl.cpp:163 : XLA tensors do not have storage"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/tensor_test.py",
                        "lineno": 72,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py",
                        "lineno": 205,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.tensor_test.TestTorchXLA testMethod=test_tensor_set_xla>, device = 'xla:1'\n\n    def test_tensor_set(self, device):\n        with pytorch_op_timer():\n            t1 = torch.tensor([], device=device)\n        t2 = torch.empty(3, 4, 9, 10).uniform_().to(device)\n        t1.set_(t2)\n>       self.assertEqual(t1.storage()._cdata, t2.storage()._cdata)\n\nsrc/pytorch_tests_reduced/tensor_test.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = tensor([[[[0.0290, 0.4019, 0.2598,  ..., 0.4681, 0.6738, 0.3315],\n          [0.7837, 0.5631, 0.7749,  ..., 0.6567, 0.2...., 0.0355, 0.9298, 0.9584],\n          [0.7606, 0.4745, 0.9847,  ..., 0.4567, 0.5488, 0.3049]]]],\n       device='xla:1')\n\n    def storage(self):\n        r\"\"\"\n        storage() -> torch.Storage\n    \n        Returns the underlying storage.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.storage, (self,), self)\n    \n>       return torch._TypedStorage(wrap_storage=self._storage(), dtype=self.dtype)\nE       RuntimeError: torch_xla/csrc/tensor_impl.cpp:163 : XLA tensors do not have storage\n\n/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:205: RuntimeError"
            },
            "teardown": {
                "duration": 0.00021252900023682741,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/to_test.py::TestNNCPU::test_to_cpu_float32",
            "lineno": 75,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004935130000376375,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.007283969000127399,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013846199999534292,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/to_test.py::TestNNXLA::test_to_xla_float32",
            "lineno": 75,
            "outcome": "passed",
            "setup": {
                "duration": 0.0018094140004905057,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.028885499999887543,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022313200042844983,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU::test_triangular_solve_cpu_complex128",
            "lineno": 81,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004021400000056019,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.022600293999857968,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020307400063757086,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU::test_triangular_solve_cpu_complex64",
            "lineno": 81,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004314879997764365,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.020859337999354466,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014717700014443835,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU::test_triangular_solve_cpu_float32",
            "lineno": 81,
            "outcome": "passed",
            "setup": {
                "duration": 0.00036358199940877967,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.019903637999959756,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014552700031345012,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgCPU::test_triangular_solve_cpu_float64",
            "lineno": 81,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003178429997205967,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01925821300028474,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00020119399960094597,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA::test_triangular_solve_xla_complex128",
            "lineno": 81,
            "outcome": "failed",
            "setup": {
                "duration": 0.001655505000599078,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.8709079459995337,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/triangular_solve_test.py",
                    "lineno": 98,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 3 / 5 (60.0%)\nGreatest absolute difference: 2.551330261460757e-05 at index (4, 0) (up to 1e-07 allowed)\nGreatest relative difference: 3.5983723955604894e-05 at index (4, 0) (up to 1e-07 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/triangular_solve_test.py",
                        "lineno": 98,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.triangular_solve_test.TestLinalgXLA testMethod=test_triangular_solve_xla_complex128>, device = 'xla:1'\ndtype = torch.complex128\n\n    @skipCUDAIfNoMagma\n    @skipCPUIfNoLapack\n    @dtypes(*floating_and_complex_types())\n    @precisionOverride({torch.float32: 1e-3, torch.complex64: 1e-3,\n                        torch.float64: 1e-8, torch.complex128: 1e-8})\n    def test_triangular_solve(self, device, dtype):\n        ks = [0, 1, 3]\n        ns = [0, 5]\n        for k, n, (upper, unitriangular, transpose) in itertools.product(ks, ns,\n                                                                         itertools.product([True, False], repeat=3)):\n            b, A = self.triangular_solve_test_helper((n, n), (n, k), upper,\n                                                     unitriangular, device, dtype)\n            with pytorch_op_timer():\n                x = torch.triangular_solve(\n                    b, A, upper=upper, unitriangular=unitriangular, transpose=transpose)[0]\n            if transpose:\n>               self.assertEqual(b, np.matmul(A.t().cpu(), x.cpu()))\nE               AssertionError: Tensor-likes are not close!\nE               \nE               Mismatched elements: 3 / 5 (60.0%)\nE               Greatest absolute difference: 2.551330261460757e-05 at index (4, 0) (up to 1e-07 allowed)\nE               Greatest relative difference: 3.5983723955604894e-05 at index (4, 0) (up to 1e-07 allowed)\n\nsrc/pytorch_tests_reduced/triangular_solve_test.py:98: AssertionError"
            },
            "teardown": {
                "duration": 0.00022963399987929733,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA::test_triangular_solve_xla_complex64",
            "lineno": 81,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004051949999848148,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.8919718280003508,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00024185199981729966,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA::test_triangular_solve_xla_float32",
            "lineno": 81,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004866520002906327,
                "outcome": "passed"
            },
            "call": {
                "duration": 2.223687329000313,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022590600019611884,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/triangular_solve_test.py::TestLinalgXLA::test_triangular_solve_xla_float64",
            "lineno": 81,
            "outcome": "failed",
            "setup": {
                "duration": 0.0004782960004376946,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.1340342020002936,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/triangular_solve_test.py",
                    "lineno": 98,
                    "message": "AssertionError: Tensor-likes are not close!\n\nMismatched elements: 2 / 5 (40.0%)\nGreatest absolute difference: 1.859249096014537e-06 at index (4, 0) (up to 1e-07 allowed)\nGreatest relative difference: 1.935049993342445e-06 at index (4, 0) (up to 1e-07 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/triangular_solve_test.py",
                        "lineno": 98,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.triangular_solve_test.TestLinalgXLA testMethod=test_triangular_solve_xla_float64>, device = 'xla:1'\ndtype = torch.float64\n\n    @skipCUDAIfNoMagma\n    @skipCPUIfNoLapack\n    @dtypes(*floating_and_complex_types())\n    @precisionOverride({torch.float32: 1e-3, torch.complex64: 1e-3,\n                        torch.float64: 1e-8, torch.complex128: 1e-8})\n    def test_triangular_solve(self, device, dtype):\n        ks = [0, 1, 3]\n        ns = [0, 5]\n        for k, n, (upper, unitriangular, transpose) in itertools.product(ks, ns,\n                                                                         itertools.product([True, False], repeat=3)):\n            b, A = self.triangular_solve_test_helper((n, n), (n, k), upper,\n                                                     unitriangular, device, dtype)\n            with pytorch_op_timer():\n                x = torch.triangular_solve(\n                    b, A, upper=upper, unitriangular=unitriangular, transpose=transpose)[0]\n            if transpose:\n>               self.assertEqual(b, np.matmul(A.t().cpu(), x.cpu()))\nE               AssertionError: Tensor-likes are not close!\nE               \nE               Mismatched elements: 2 / 5 (40.0%)\nE               Greatest absolute difference: 1.859249096014537e-06 at index (4, 0) (up to 1e-07 allowed)\nE               Greatest relative difference: 1.935049993342445e-06 at index (4, 0) (up to 1e-07 allowed)\n\nsrc/pytorch_tests_reduced/triangular_solve_test.py:98: AssertionError"
            },
            "teardown": {
                "duration": 0.0002972350002892199,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestViewOpsCPU::test_unbind_cpu",
            "lineno": 31,
            "outcome": "passed",
            "setup": {
                "duration": 0.00044911899931321386,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.009044001999427564,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014946299961593468,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unbind_test.py::TestViewOpsXLA::test_unbind_xla",
            "lineno": 31,
            "outcome": "failed",
            "setup": {
                "duration": 0.0018373079992670682,
                "outcome": "passed"
            },
            "call": {
                "duration": 35.98649804700017,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                    "lineno": 1280,
                    "message": "torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor(0.4213, device='xla:1', dtype=torch.float64)\nanalytical:tensor(0.4571, device='xla:1', dtype=torch.float64)\n\nThe above quantities relating the numerical and analytical jacobians are computed \nin fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nabout fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\n\nNumerical:\n tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n        ...,\n        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n       device='xla:1', dtype=torch.float64)\nAnalytical:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='xla:1', dtype=torch.float64)\n\nThe max per-element difference (slow mode) is: 7.253885269165039e-05.\nFast gradcheck failed but element-wise differences are small. This means that the\ntest might've passed in slow_mode!\n\nIf you are adding a new operator, please file an issue and then use one of the\nworkarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:\n\nIf the test\n- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck\n  with `fast_mode=False` as a keyword argument.\n- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test\n  to have `gradcheck_fast_mode=False`\n- is a Module test (e.g., in common_nn.py), then modify the corresponding\n  module_test entry to have `gradcheck_fast_mode=False`"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/unbind_test.py",
                        "lineno": 55,
                        "message": ""
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py",
                        "lineno": 3019,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1414,
                        "message": "in gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1428,
                        "message": "in _gradcheck_helper"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1075,
                        "message": "in _gradcheck_real_imag"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1307,
                        "message": "in _fast_gradcheck"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
                        "lineno": 1280,
                        "message": "GradcheckError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.unbind_test.TestViewOpsXLA testMethod=test_unbind_xla>, device = 'xla:1'\n\n    def test_unbind(self, device):\n        stacked = torch.randn(3, 10, 10, requires_grad=True, device=device)\n    \n        with pytorch_op_timer():\n            x, y, z = stacked.unbind()\n        grad = torch.randn(3, 10, 10, device=device)\n    \n        torch.autograd.backward([x, y, z], grad.unbind())\n        self.assertEqual(stacked.grad, grad)\n        # check that it works with only one gradient provided (#9977)\n        for i in range(3):\n            stacked = torch.randn(3, 10, 10, requires_grad=True, device=device)\n            with pytorch_op_timer():\n                outs = stacked.unbind()\n            with pytorch_op_timer():\n                gi = grad.unbind()[i]\n            g, = torch.autograd.grad(outs[i], stacked, gi)\n            g_expected = torch.stack([gi if j == i else torch.zeros_like(gi, device=device)\n                                      for j in range(3)], dim=0)\n            self.assertEqual(g, g_expected)\n        # Check with gradcheck\n        stacked = torch.randn(\n            3, 10, 10, dtype=torch.double, requires_grad=True, device=device)\n>       gradcheck(lambda x: x.unbind(), (stacked,), check_forward_ad=True)\n\nsrc/pytorch_tests_reduced/unbind_test.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_utils.py:3019: in gradcheck\n    return torch.autograd.gradcheck(fn, inputs, **kwargs)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1414: in gradcheck\n    return _gradcheck_helper(**args)\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1428: in _gradcheck_helper\n    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1075: in _gradcheck_real_imag\n    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1307: in _fast_gradcheck\n    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nall_analytical = [[tensor(0.4571, device='xla:1', dtype=torch.float64)], [tensor(0.4252, device='xla:1', dtype=torch.float64)], [tensor(0.3943, device='xla:1', dtype=torch.float64)]]\nall_numerical = [[tensor(0.4213, device='xla:1', dtype=torch.float64), tensor(0.3699, device='xla:1', dtype=torch.float64), tensor(0.3215, device='xla:1', dtype=torch.float64)]]\ncomplex_indices = None\ntupled_inputs = (tensor([[[ 1.2634e+00,  5.0129e-01, -1.5554e+00,  1.9125e+00,  4.5969e-01,\n          -1.7412e+00,  1.8617e+00, -1.647...6.1451e-01, -3.4139e-01, -1.9396e-01,  1.0938e+00]]],\n       device='xla:1', dtype=torch.float64, requires_grad=True),)\noutputs = (tensor([[ 1.2634,  0.5013, -1.5554,  1.9125,  0.4597, -1.7412,  1.8617, -1.6472,\n         -0.7124, -0.8961],\n        ... -0.6145, -0.3414,\n         -0.1940,  1.0938]], device='xla:1', dtype=torch.float64,\n       grad_fn=<UnbindBackward0>))\nfunc = <function TestViewOps.test_unbind.<locals>.<lambda> at 0x7fcddb8043a0>\nall_v = [tensor([0.0236, 0.1210, 0.1583, 0.1499, 0.1152, 0.0498, 0.1116, 0.1461, 0.0800,\n        0.0031, 0.0973, 0.1582, 0.107... 0.0301, 0.1070, 0.1188, 0.0936, 0.0894, 0.1089, 0.0405, 0.0065,\n        0.1263], device='xla:1', dtype=torch.float64)]\nall_u = [tensor([0.0272, 0.0889, 0.0341, 0.0410, 0.0802, 0.0466, 0.0073, 0.0989, 0.0728,\n        0.0435, 0.0086, 0.0500, 0.016... 0.0618, 0.0938, 0.0104, 0.0956, 0.0145, 0.0377,\n        0.0036, 0.0894, 0.0849], device='xla:1', dtype=torch.float64)]\nrtol = 0.001, atol = 1e-05, test_imag = False\n\n    def _check_analytical_numerical_equal(all_analytical, all_numerical, complex_indices, tupled_inputs, outputs,\n                                          func, all_v, all_u, rtol, atol, test_imag, *, is_forward_ad=False):\n        for i, all_numerical_for_input_i in enumerate(all_numerical):\n            for j, n in enumerate(all_numerical_for_input_i):\n                # Forward AD generates the transpose of what this function expects\n                if is_forward_ad:\n                    a = all_analytical[i][j]\n                else:\n                    a = all_analytical[j][i]\n                n = n.to(device=a.device)\n                updated_atol = _adjusted_atol(atol, all_u[i], all_v[j] if all_v else None)\n                if not _allclose_with_type_promotion(a, n.to(a.device), rtol, updated_atol):\n                    jacobians_str = _run_slow_mode_and_get_error(func, tupled_inputs, outputs, i, j, rtol, atol, is_forward_ad)\n>                   raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)\nE                   torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,\nE                   numerical:tensor(0.4213, device='xla:1', dtype=torch.float64)\nE                   analytical:tensor(0.4571, device='xla:1', dtype=torch.float64)\nE                   \nE                   The above quantities relating the numerical and analytical jacobians are computed \nE                   in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background \nE                   about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:\nE                   \nE                   Numerical:\nE                    tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\nE                           [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\nE                           [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\nE                           ...,\nE                           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\nE                           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\nE                           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\nE                          device='xla:1', dtype=torch.float64)\nE                   Analytical:\nE                   tensor([[1., 0., 0.,  ..., 0., 0., 0.],\nE                           [0., 1., 0.,  ..., 0., 0., 0.],\nE                           [0., 0., 1.,  ..., 0., 0., 0.],\nE                           ...,\nE                           [0., 0., 0.,  ..., 0., 0., 0.],\nE                           [0., 0., 0.,  ..., 0., 0., 0.],\nE                           [0., 0., 0.,  ..., 0., 0., 0.]], device='xla:1', dtype=torch.float64)\nE                   \nE                   The max per-element difference (slow mode) is: 7.253885269165039e-05.\nE                   Fast gradcheck failed but element-wise differences are small. This means that the\nE                   test might've passed in slow_mode!\nE                   \nE                   If you are adding a new operator, please file an issue and then use one of the\nE                   workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:\nE                   \nE                   If the test\nE                   - manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck\nE                     with `fast_mode=False` as a keyword argument.\nE                   - is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test\nE                     to have `gradcheck_fast_mode=False`\nE                   - is a Module test (e.g., in common_nn.py), then modify the corresponding\nE                     module_test entry to have `gradcheck_fast_mode=False`\n\n/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py:1280: GradcheckError"
            },
            "teardown": {
                "duration": 0.0005756379996455507,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestViewOpsCPU::test_unsqueeze_view_cpu",
            "lineno": 40,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005627730006381171,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01668204399993556,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00019426200015004724,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/unsqueeze_test.py::TestViewOpsXLA::test_unsqueeze_view_xla",
            "lineno": 40,
            "outcome": "failed",
            "setup": {
                "duration": 0.0036595989995475975,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.08609032100048353,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/unsqueeze_test.py",
                    "lineno": 48,
                    "message": "AssertionError: Scalars are not close!\n\nAbsolute difference: 1.0 (up to 1e-05 allowed)\nRelative difference: inf (up to 1.3e-06 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/unsqueeze_test.py",
                        "lineno": 48,
                        "message": "AssertionError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.unsqueeze_test.TestViewOpsXLA testMethod=test_unsqueeze_view_xla>, device = 'xla:1'\n\n    def test_unsqueeze_view(self, device):\n        t = torch.ones(5, 5, device=device)\n        with pytorch_op_timer():\n            v = torch.unsqueeze(t, 1)\n        self.assertTrue(self.is_view_of(t, v))\n    \n        v[0, 0, 1] = 0\n>       self.assertEqual(t[0, 1], v[0, 0, 1])\nE       AssertionError: Scalars are not close!\nE       \nE       Absolute difference: 1.0 (up to 1e-05 allowed)\nE       Relative difference: inf (up to 1.3e-06 allowed)\n\nsrc/pytorch_tests_reduced/unsqueeze_test.py:48: AssertionError"
            },
            "teardown": {
                "duration": 0.00025551999988238094,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_indexing_cpu",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.0012691069987340597,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.022807688001194037,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_indexing_cpu>\n"
            },
            "teardown": {
                "duration": 0.00028166400079499,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_indexing_duplicates_cpu",
            "lineno": 152,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004343230011727428,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0026902929985226365,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_indexing_duplicates_cpu>\n"
            },
            "teardown": {
                "duration": 0.00018026199904852547,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_inplace_cpu",
            "lineno": 199,
            "outcome": "passed",
            "setup": {
                "duration": 0.00034887999936472625,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.028919886999574373,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_inplace_cpu>\n"
            },
            "teardown": {
                "duration": 0.0001794399995560525,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_pyscalar_conversions_cpu",
            "lineno": 351,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003487409994704649,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0018841340006474638,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_pyscalar_conversions_cpu>\n"
            },
            "teardown": {
                "duration": 0.00017638200006331317,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_reentrant_priority_cpu",
            "lineno": 407,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003480949999357108,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.002777014999082894,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_reentrant_priority_cpu>\n"
            },
            "teardown": {
                "duration": 0.00020559299991873559,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradCPU::test_simple_reentrant_cpu",
            "lineno": 325,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004012400004285155,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0011882650014740648,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_simple_reentrant_cpu>\n"
            },
            "teardown": {
                "duration": 0.00026342199998907745,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_indexing_duplicates_xla",
            "lineno": 152,
            "outcome": "passed",
            "setup": {
                "duration": 0.011936378999962471,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.43370804199912527,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_indexing_duplicates_xla>\n"
            },
            "teardown": {
                "duration": 0.0002891410003940109,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_indexing_xla",
            "lineno": 68,
            "outcome": "passed",
            "setup": {
                "duration": 0.000523028000316117,
                "outcome": "passed"
            },
            "call": {
                "duration": 1.0584976210011519,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_indexing_xla>\n"
            },
            "teardown": {
                "duration": 0.00034535700069682207,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_inplace_xla",
            "lineno": 199,
            "outcome": "passed",
            "setup": {
                "duration": 0.0006202269996720133,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.18552773100054765,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_inplace_xla>\n"
            },
            "teardown": {
                "duration": 0.0002670560006663436,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_pyscalar_conversions_xla",
            "lineno": 351,
            "outcome": "failed",
            "setup": {
                "duration": 0.0004975620013283333,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.03269533099955879,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/variable_test.py",
                    "lineno": 367,
                    "message": "AssertionError: Scalars are not close!\n\nAbsolute difference: 12345.146130463481 (up to 1e-05 allowed)\nRelative difference: 1.0000037367427952 (up to 1.3e-06 allowed)"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/variable_test.py",
                        "lineno": 406,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/variable_test.py",
                        "lineno": 367,
                        "message": "AssertionError"
                    }
                ],
                "stdout": "ITEM <TestCaseFunction test_pyscalar_conversions_xla>\n",
                "longrepr": "self = <src.pytorch_tests_reduced.variable_test.TestAutogradXLA testMethod=test_pyscalar_conversions_xla>, device = 'xla:1'\n\n    @skipIfMps  # the test doesn't work on MPS as double types are not supported\n    def test_pyscalar_conversions(self, device):\n        def _test_pyscalar_conversions(t, integral_conv):\n            # integral -> integral\n            l = t(torch.zeros(1, 1, 1, dtype=torch.long, device=device))\n            pyscalar = -12345\n            l[0] = pyscalar\n            self.assertEqual(integral_conv(l), pyscalar)\n    \n            # floating point -> floating point\n            with pytorch_op_timer():\n                f = Variable(\n                    t(torch.randn(1, 1, dtype=torch.double))).to(device)\n            pyscalar = -12345.1\n            f[0] = pyscalar\n            self.assertEqual(float(f), pyscalar)\n            f[0] = nan\n            self.assertTrue(math.isnan(float(f)))\n            f[0] = inf\n            self.assertEqual(float(f), inf)\n            f[0] = -inf\n            self.assertEqual(float(f), -inf)\n    \n            # integral -> floating point\n            # check we can convert something that loses precision\n            pyscalar = 1234567890123456789\n            self.assertNotEqual(pyscalar, integral_conv(float(pyscalar)))\n            l[0] = pyscalar\n            self.assertEqual(float(l), float(pyscalar))\n    \n            # floating point -> integral\n            f[0] = nan\n            self.assertRaises(ValueError, lambda: integral_conv(f[0]))\n            f[0] = inf\n            self.assertRaises(OverflowError, lambda: integral_conv(f[0]))\n            f[0] = -inf\n            self.assertRaises(OverflowError, lambda: integral_conv(f[0]))\n            f[0] = sys.float_info.max\n            self.assertEqual(integral_conv(f), sys.float_info.max)\n    \n            # bool, nonzero\n            def test_nonzero(tensor, value, expected):\n                tensor[0] = value\n                self.assertEqual(expected, bool(tensor))\n                self.assertEqual(expected, True if tensor else False)\n    \n            test_nonzero(l, 0, False)\n            test_nonzero(l, -2, True)\n            test_nonzero(f, 0.0, False)\n            test_nonzero(f, sys.float_info.min, True)\n            test_nonzero(f, nan, bool(nan))\n            test_nonzero(f, inf, bool(inf))\n            test_nonzero(f, -inf, bool(-inf))\n    \n>       _test_pyscalar_conversions(lambda x: x.to(device), lambda x: int(x))\n\nsrc/pytorch_tests_reduced/variable_test.py:406: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nt = <function TestAutograd.test_pyscalar_conversions.<locals>.<lambda> at 0x7f22acda04c0>\nintegral_conv = <function TestAutograd.test_pyscalar_conversions.<locals>.<lambda> at 0x7f22acda0940>\n\n    def _test_pyscalar_conversions(t, integral_conv):\n        # integral -> integral\n        l = t(torch.zeros(1, 1, 1, dtype=torch.long, device=device))\n        pyscalar = -12345\n        l[0] = pyscalar\n        self.assertEqual(integral_conv(l), pyscalar)\n    \n        # floating point -> floating point\n        with pytorch_op_timer():\n            f = Variable(\n                t(torch.randn(1, 1, dtype=torch.double))).to(device)\n        pyscalar = -12345.1\n        f[0] = pyscalar\n>       self.assertEqual(float(f), pyscalar)\nE       AssertionError: Scalars are not close!\nE       \nE       Absolute difference: 12345.146130463481 (up to 1e-05 allowed)\nE       Relative difference: 1.0000037367427952 (up to 1.3e-06 allowed)\n\nsrc/pytorch_tests_reduced/variable_test.py:367: AssertionError"
            },
            "teardown": {
                "duration": 0.0003151620003336575,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_reentrant_priority_xla",
            "lineno": 407,
            "outcome": "passed",
            "setup": {
                "duration": 0.00043608499981928617,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.08097071100019093,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_reentrant_priority_xla>\n"
            },
            "teardown": {
                "duration": 0.0002577480008767452,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/variable_test.py::TestAutogradXLA::test_simple_reentrant_xla",
            "lineno": 325,
            "outcome": "passed",
            "setup": {
                "duration": 0.0005129870005475823,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06900620200030971,
                "outcome": "passed",
                "stdout": "ITEM <TestCaseFunction test_simple_reentrant_xla>\n"
            },
            "teardown": {
                "duration": 0.001392942000165931,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesCPU::test_vonmises_shape_scalar_params_cpu",
            "lineno": 109,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003892189997714013,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0023830220006857417,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012060500012012199,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesCPU::test_vonmises_shape_tensor_params_cpu",
            "lineno": 99,
            "outcome": "passed",
            "setup": {
                "duration": 0.00028482600009738235,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0024573720002081245,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000198818000171741,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesXLA::test_vonmises_shape_scalar_params_xla",
            "lineno": 109,
            "outcome": "passed",
            "setup": {
                "duration": 0.0017201609998664935,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0018602119998831768,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012108100054319948,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/vonmises_test.py::TestDistributionShapesXLA::test_vonmises_shape_tensor_params_xla",
            "lineno": 99,
            "outcome": "passed",
            "setup": {
                "duration": 0.00030412700016313465,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.38331596499938314,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0003160920005029766,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitCPU::test_xavier_uniform_cpu",
            "lineno": 111,
            "outcome": "failed",
            "setup": {
                "duration": 0.0005252410001048702,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0012381750002532499,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/xavier_uniform_test.py",
                    "lineno": 94,
                    "message": "NameError: name 'stats' is not defined"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/xavier_uniform_test.py",
                        "lineno": 136,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/xavier_uniform_test.py",
                        "lineno": 94,
                        "message": "NameError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.xavier_uniform_test.TestNNInitCPU testMethod=test_xavier_uniform_cpu>, device = 'cpu'\n\n    def test_xavier_uniform(self, device):\n        torch.set_default_dtype(torch.double)\n        for use_gain in [True, False]:\n            for dims in [2, 4]:\n                input_tensor = self._create_random_nd_tensor(dims, size_min=20, size_max=25)\n                input_tensor = input_tensor.to(device)\n                gain = 1\n    \n                if use_gain:\n                    gain = self._random_float(0.1, 2)\n                    with pytorch_op_timer():\n                        init.xavier_uniform_(input_tensor, gain=gain)\n                else:\n                    with pytorch_op_timer():\n                        init.xavier_uniform_(input_tensor)\n    \n                fan_in = input_tensor.size(1)\n                fan_out = input_tensor.size(0)\n                if input_tensor.dim() > 2:\n                    fan_in *= input_tensor[0, 0].numel()\n                    fan_out *= input_tensor[0, 0].numel()\n    \n                expected_std = gain * math.sqrt(2.0 / (fan_in + fan_out))\n                bounds = expected_std * math.sqrt(3)\n>               assert self._is_uniform(input_tensor, -bounds, bounds)\n\nsrc/pytorch_tests_reduced/xavier_uniform_test.py:136: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.pytorch_tests_reduced.xavier_uniform_test.TestNNInitCPU testMethod=test_xavier_uniform_cpu>\ntensor = tensor([[-0.0229, -0.0360, -0.0029, -0.0073, -0.0093, -0.0197, -0.0257, -0.0227,\n         -0.0197,  0.0350,  0.0264, -... -0.0312,  0.0379, -0.0100,  0.0402, -0.0387, -0.0374,  0.0345, -0.0102,\n          0.0419,  0.0064, -0.0197,  0.0180]])\na = -0.04267131189539713, b = 0.04267131189539713\n\n    def _is_uniform(self, tensor, a, b):\n        samples = tensor.view(-1).tolist()\n>       p_value = stats.kstest(samples, 'uniform', args=(a, (b - a)))[1]\nE       NameError: name 'stats' is not defined\n\nsrc/pytorch_tests_reduced/xavier_uniform_test.py:94: NameError"
            },
            "teardown": {
                "duration": 0.00016879200029507047,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitCPU::test_xavier_uniform_errors_on_inputs_smaller_than_2d_cpu",
            "lineno": 100,
            "outcome": "passed",
            "setup": {
                "duration": 0.00031513500016444596,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006631409996771254,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000149593000060122,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitXLA::test_xavier_uniform_errors_on_inputs_smaller_than_2d_xla",
            "lineno": 100,
            "outcome": "passed",
            "setup": {
                "duration": 0.0016959310005404404,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006177579998620786,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.000113293000140402,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/xavier_uniform_test.py::TestNNInitXLA::test_xavier_uniform_xla",
            "lineno": 111,
            "outcome": "failed",
            "setup": {
                "duration": 0.00027511099960975116,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.07460743400042702,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/xavier_uniform_test.py",
                    "lineno": 94,
                    "message": "NameError: name 'stats' is not defined"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/xavier_uniform_test.py",
                        "lineno": 136,
                        "message": ""
                    },
                    {
                        "path": "src/pytorch_tests_reduced/xavier_uniform_test.py",
                        "lineno": 94,
                        "message": "NameError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.xavier_uniform_test.TestNNInitXLA testMethod=test_xavier_uniform_xla>, device = 'xla:1'\n\n    def test_xavier_uniform(self, device):\n        torch.set_default_dtype(torch.double)\n        for use_gain in [True, False]:\n            for dims in [2, 4]:\n                input_tensor = self._create_random_nd_tensor(dims, size_min=20, size_max=25)\n                input_tensor = input_tensor.to(device)\n                gain = 1\n    \n                if use_gain:\n                    gain = self._random_float(0.1, 2)\n                    with pytorch_op_timer():\n                        init.xavier_uniform_(input_tensor, gain=gain)\n                else:\n                    with pytorch_op_timer():\n                        init.xavier_uniform_(input_tensor)\n    \n                fan_in = input_tensor.size(1)\n                fan_out = input_tensor.size(0)\n                if input_tensor.dim() > 2:\n                    fan_in *= input_tensor[0, 0].numel()\n                    fan_out *= input_tensor[0, 0].numel()\n    \n                expected_std = gain * math.sqrt(2.0 / (fan_in + fan_out))\n                bounds = expected_std * math.sqrt(3)\n>               assert self._is_uniform(input_tensor, -bounds, bounds)\n\nsrc/pytorch_tests_reduced/xavier_uniform_test.py:136: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.pytorch_tests_reduced.xavier_uniform_test.TestNNInitXLA testMethod=test_xavier_uniform_xla>\ntensor = tensor([[ 3.7667e-02,  3.2879e-02,  9.2706e-03,  2.0262e-02,  2.1881e-02,\n         -1.6393e-02, -4.0015e-03,  3.2502e-...98e-02, -2.4608e-02,\n         -1.4645e-02, -2.2106e-02,  2.8521e-02,  4.1012e-02,  1.9134e-03]],\n       device='xla:1')\na = -0.04267131189539713, b = 0.04267131189539713\n\n    def _is_uniform(self, tensor, a, b):\n        samples = tensor.view(-1).tolist()\n>       p_value = stats.kstest(samples, 'uniform', args=(a, (b - a)))[1]\nE       NameError: name 'stats' is not defined\n\nsrc/pytorch_tests_reduced/xavier_uniform_test.py:94: NameError"
            },
            "teardown": {
                "duration": 0.00023330299973167712,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestNNCPU::test_zero_grad_cpu",
            "lineno": 91,
            "outcome": "passed",
            "setup": {
                "duration": 0.0004256920001353137,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0032549859997743624,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014219100012269337,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zero_grad_test.py::TestNNXLA::test_zero_grad_xla",
            "lineno": 91,
            "outcome": "passed",
            "setup": {
                "duration": 0.0020065059998159995,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.23244476199943165,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00023766600043018116,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_cpu",
            "lineno": 97,
            "outcome": "passed",
            "setup": {
                "duration": 0.00046440599999186816,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0035475790000418783,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012239200077601708,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_bool",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.00027507600043463754,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.000781730000198877,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011342899961164221,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_complex64",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002672689997780253,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0008370809991902206,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013139800012140768,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_float16",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003169629999320023,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.000832394000099157,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011280300077487482,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_float32",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026119899939658353,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006943919997866033,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001222119999511051,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_int16",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026737299958767835,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007032009998511057,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011225900016142987,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_int64",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002710759999899892,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0007098919995769393,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011348400039423723,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_dtype_layout_device_match_cpu_uint8",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.00025893800011544954,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006995419998929719,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001131389999500243,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationCPU::test_zeros_out_cpu",
            "lineno": 134,
            "outcome": "passed",
            "setup": {
                "duration": 0.00026622999939718284,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.006837668000116537,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00022707199968863279,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_bool",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0020755039995492552,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.012040923999848019,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013010700058657676,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_complex64",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002847139994628378,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.013547374999689055,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00015622299997630762,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_float16",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002950529997178819,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.013282634000461258,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00013617100012197625,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_float32",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.00033240999982808717,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01367714000025444,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00014977400041971123,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_int16",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0003050360000997898,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.012303421999604325,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011676900066959206,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_int64",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002868649999072659,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01286370599973452,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00012761200014210772,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_dtype_layout_device_match_xla_uint8",
            "lineno": 87,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002902809992519906,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.01202213299984578,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.00011929499942198163,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_out_xla",
            "lineno": 134,
            "outcome": "passed",
            "setup": {
                "duration": 0.0002855000002455199,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.06040397899960226,
                "outcome": "passed"
            },
            "teardown": {
                "duration": 0.0001250060004167608,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestTensorCreationXLA::test_zeros_xla",
            "lineno": 97,
            "outcome": "failed",
            "setup": {
                "duration": 0.0003092849992754054,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.16181185099958384,
                "outcome": "failed",
                "crash": {
                    "path": "/home/frasermince/portability/src/pytorch_tests_reduced/zeros_test.py",
                    "lineno": 117,
                    "message": "RuntimeError: Comparing\n\nTensorOrArrayPair(\n    id=(),\n    actual=tensor([[0.]], device='xla:1', dtype=torch.float16),\n    expected=tensor([[0.]], device='xla:1', dtype=torch.float16),\n    rtol=0.001,\n    atol=1e-05,\n    equal_nan=True,\n    check_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\nresulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead."
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/zeros_test.py",
                        "lineno": 117,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "actual = tensor([[0.]], device='xla:1', dtype=torch.float16), expected = tensor([[0.]], device='xla:1', dtype=torch.float16)\npair_types = (<class 'torch.testing._comparison.NonePair'>, <class 'torch.testing._internal.common_utils.RelaxedBooleanPair'>, <cla...<class 'torch.testing._internal.common_utils.StringPair'>, <class 'torch.testing._internal.common_utils.SetPair'>, ...)\nsequence_types = (<class 'collections.abc.Sequence'>, <class 'torch.storage._TypedStorage'>, <class 'torch.nn.modules.container.Sequent...nn.modules.container.ModuleList'>, <class 'torch.nn.modules.container.ParameterList'>, <class 'torch.ScriptList'>, ...)\nmapping_types = (<class 'collections.abc.Mapping'>, <class 'torch.nn.modules.container.ModuleDict'>, <class 'torch.nn.modules.container.ParameterDict'>, <class 'torch.ScriptDict'>)\nmsg = None, options = {'atol': None, 'atol_override': 0, 'check_device': False, 'check_dtype': True, ...}, __tracebackhide__ = True\npairs = [TensorOrArrayPair(\n    id=(),\n    actual=tensor([[0.]], device='xla:1', dtype=torch.float16),\n    expected=tensor([[0...ck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)]\n\n    def assert_equal(\n        actual: Any,\n        expected: Any,\n        *,\n        pair_types: Sequence[Type[Pair]] = (ObjectPair,),\n        sequence_types: Tuple[Type, ...] = (collections.abc.Sequence,),\n        mapping_types: Tuple[Type, ...] = (collections.abc.Mapping,),\n        msg: Optional[Union[str, Callable[[str], str]]] = None,\n        **options: Any,\n    ) -> None:\n        \"\"\"Asserts that inputs are equal.\n    \n        ``actual`` and ``expected`` can be possibly nested :class:`~collections.abc.Sequence`'s or\n        :class:`~collections.abc.Mapping`'s. In this case the comparison happens elementwise by recursing through them.\n    \n        Args:\n            actual (Any): Actual input.\n            expected (Any): Expected input.\n            pair_types (Sequence[Type[Pair]]): Sequence of :class:`Pair` types that will be tried to construct with the\n                inputs. First successful pair will be used. Defaults to only using :class:`ObjectPair`.\n            sequence_types (Tuple[Type, ...]): Optional types treated as sequences that will be checked elementwise.\n            mapping_types (Tuple[Type, ...]): Optional types treated as mappings that will be checked elementwise.\n            **options (Any): Options passed to each pair during construction.\n        \"\"\"\n        # Hide this function from `pytest`'s traceback\n        __tracebackhide__ = True\n    \n        # TODO: the Tensor compare uses bunch of operations which is currently not\n        # supported by MPS. We will remove this move to CPU after all the\n        # support is added. https://github.com/pytorch/pytorch/issues/77144\n        if isinstance(actual, torch.Tensor) and (actual.is_mps):\n            actual = actual.to('cpu')\n    \n        if isinstance(expected, torch.Tensor) and (expected.is_mps):\n            expected = expected.to('cpu')\n    \n        try:\n            pairs = originate_pairs(\n                actual,\n                expected,\n                pair_types=pair_types,\n                sequence_types=sequence_types,\n                mapping_types=mapping_types,\n                **options,\n            )\n        except ErrorMeta as error_meta:\n            # Explicitly raising from None to hide the internal traceback\n            raise error_meta.to_error() from None\n    \n        error_metas: List[ErrorMeta] = []\n        for pair in pairs:\n            try:\n>               pair.compare()\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:1075: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[0.]], device='xla:1', dtype=torch.float16),\n    expected=tensor([[0....eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\n\n    def compare(self) -> None:\n        actual, expected = self.actual, self.expected\n    \n        self._compare_attributes(actual, expected)\n        if any(input.device.type == \"meta\" for input in (actual, expected)):\n            return\n    \n        actual, expected = self._equalize_attributes(actual, expected)\n>       self._compare_values(actual, expected)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:620: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[0.]], device='xla:1', dtype=torch.float16),\n    expected=tensor([[0....eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = tensor([[0.]], device='xla:1', dtype=torch.float16), expected = tensor([[0.]], device='xla:1', dtype=torch.float16)\n\n    def _compare_values(self, actual: torch.Tensor, expected: torch.Tensor) -> None:\n        if actual.is_quantized:\n            compare_fn = self._compare_quantized_values\n        elif actual.is_sparse:\n            compare_fn = self._compare_sparse_coo_values\n        elif actual.layout in {torch.sparse_csr, torch.sparse_csc, torch.sparse_bsr, torch.sparse_bsc}:\n            compare_fn = self._compare_sparse_compressed_values\n        else:\n            compare_fn = self._compare_regular_values_close\n    \n>       compare_fn(actual, expected, rtol=self.rtol, atol=self.atol, equal_nan=self.equal_nan)\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:714: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorOrArrayPair(\n    id=(),\n    actual=tensor([[0.]], device='xla:1', dtype=torch.float16),\n    expected=tensor([[0....eck_device=False,\n    check_dtype=True,\n    check_layout=False,\n    check_stride=False,\n    check_is_coalesced=False,\n)\nactual = <[RuntimeError('Error while lowering: [] xla::cast, type=f32, dtype=Double, stype=Half\\nError: torch_xla/csrc/convert_ops.cpp:86 : Unsupported XLA type 10\\nFrames:\\n') raised in repr()] Tensor object at 0x7fcdd38e6b80>\nexpected = <[RuntimeError('Error while lowering: [] xla::cast, type=f32, dtype=Double, stype=Half\\nError: torch_xla/csrc/convert_ops.cpp:86 : Unsupported XLA type 10\\nFrames:\\n') raised in repr()] Tensor object at 0x7fcdd38de950>\n\n    def _compare_regular_values_close(\n        self,\n        actual: torch.Tensor,\n        expected: torch.Tensor,\n        *,\n        rtol: float,\n        atol: float,\n        equal_nan: bool,\n        identifier: Optional[Union[str, Callable[[str], str]]] = None,\n    ) -> None:\n        \"\"\"Checks if the values of two tensors are close up to a desired tolerance.\"\"\"\n        actual, expected = self._promote_for_comparison(actual, expected)\n        matches = torch.isclose(actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan)\n>       if torch.all(matches):\nE       RuntimeError: Error while lowering: [] xla::cast, type=f32, dtype=Double, stype=Half\nE       Error: torch_xla/csrc/convert_ops.cpp:86 : Unsupported XLA type 10\nE       Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch/testing/_comparison.py:847: RuntimeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <src.pytorch_tests_reduced.zeros_test.TestTensorCreationXLA testMethod=test_zeros_xla>, device = 'xla:1'\n\n    def test_zeros(self, device):\n        with pytorch_op_timer():\n            res1 = torch.zeros(100, 100, device=device)\n        with pytorch_op_timer():\n            res2 = torch.tensor((), device=device)\n        with pytorch_op_timer():\n            torch.zeros(100, 100, device=device, out=res2)\n    \n        self.assertEqual(res1, res2)\n    \n        with pytorch_op_timer():\n            boolTensor = torch.zeros(2, 2, device=device, dtype=torch.bool)\n        expected = torch.tensor([[False, False], [False, False]],\n                                device=device, dtype=torch.bool)\n        self.assertEqual(boolTensor, expected)\n    \n        with pytorch_op_timer():\n              halfTensor = torch.zeros(1, 1, device=device, dtype=torch.half)\n        expected = torch.tensor([[0.]], device=device, dtype=torch.float16)\n>       self.assertEqual(halfTensor, expected)\nE       RuntimeError: Comparing\nE       \nE       TensorOrArrayPair(\nE           id=(),\nE           actual=tensor([[0.]], device='xla:1', dtype=torch.float16),\nE           expected=tensor([[0.]], device='xla:1', dtype=torch.float16),\nE           rtol=0.001,\nE           atol=1e-05,\nE           equal_nan=True,\nE           check_device=False,\nE           check_dtype=True,\nE           check_layout=False,\nE           check_stride=False,\nE           check_is_coalesced=False,\nE       )\nE       \nE       resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.\n\nsrc/pytorch_tests_reduced/zeros_test.py:117: RuntimeError"
            },
            "teardown": {
                "duration": 0.0003206249994036625,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationCPU::test_zeros_like_cpu",
            "lineno": 175,
            "outcome": "failed",
            "setup": {
                "duration": 0.00041236900051444536,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0014104020001468598,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] xla::cast, type=f32, dtype=Double, stype=Half\nError: torch_xla/csrc/convert_ops.cpp:86 : Unsupported XLA type 10\nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/zeros_test.py",
                        "lineno": 178,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.zeros_test.TestLikeTensorCreationCPU testMethod=test_zeros_like_cpu>, device = 'cpu'\n\n    def test_zeros_like(self, device):\n        with pytorch_op_timer():\n>           expected = torch.zeros((100, 100,), device=device)\n\nsrc/pytorch_tests_reduced/zeros_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] xla::cast, type=f32, dtype=Double, stype=Half\nE     Error: torch_xla/csrc/convert_ops.cpp:86 : Unsupported XLA type 10\nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.0001563949999763281,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationCPU::test_zeros_like_multiple_device_cpu",
            "lineno": 182,
            "outcome": "skipped",
            "setup": {
                "duration": 0.00032145600016519893,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0006885470002089278,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/zeros_test.py', 183, 'Skipped: fewer than 2 devices detected')"
            },
            "teardown": {
                "duration": 0.00018755100063572172,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationXLA::test_zeros_like_multiple_device_xla",
            "lineno": 182,
            "outcome": "skipped",
            "setup": {
                "duration": 0.0016497609994985396,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.0005627330001516384,
                "outcome": "skipped",
                "longrepr": "('/home/frasermince/portability/src/pytorch_tests_reduced/zeros_test.py', 183, 'Skipped: fewer than 2 devices detected')"
            },
            "teardown": {
                "duration": 0.00012898900058644358,
                "outcome": "passed"
            }
        },
        {
            "nodeid": "src/pytorch_tests_reduced/zeros_test.py::TestLikeTensorCreationXLA::test_zeros_like_xla",
            "lineno": 175,
            "outcome": "failed",
            "setup": {
                "duration": 0.0002827099997375626,
                "outcome": "passed"
            },
            "call": {
                "duration": 0.001223362000018824,
                "outcome": "failed",
                "crash": {
                    "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                    "lineno": 898,
                    "message": "RuntimeError: Error while lowering: [] xla::cast, type=f32, dtype=Double, stype=Half\nError: torch_xla/csrc/convert_ops.cpp:86 : Unsupported XLA type 10\nFrames:"
                },
                "traceback": [
                    {
                        "path": "src/pytorch_tests_reduced/zeros_test.py",
                        "lineno": 178,
                        "message": ""
                    },
                    {
                        "path": "/usr/lib/python3.8/contextlib.py",
                        "lineno": 120,
                        "message": "in __exit__"
                    },
                    {
                        "path": "src/utils/timer_wrapper.py",
                        "lineno": 78,
                        "message": "in pytorch_op_timer"
                    },
                    {
                        "path": "/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py",
                        "lineno": 898,
                        "message": "RuntimeError"
                    }
                ],
                "longrepr": "self = <src.pytorch_tests_reduced.zeros_test.TestLikeTensorCreationXLA testMethod=test_zeros_like_xla>, device = 'xla:1'\n\n    def test_zeros_like(self, device):\n        with pytorch_op_timer():\n>           expected = torch.zeros((100, 100,), device=device)\n\nsrc/pytorch_tests_reduced/zeros_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.8/contextlib.py:120: in __exit__\n    next(self.gen)\nsrc/utils/timer_wrapper.py:78: in pytorch_op_timer\n    xm.mark_step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def mark_step():\n      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):\n        print(\n            'torch_xla.core.xla_model::mark_step\\n',\n            end='',\n            file=sys.stderr,\n            flush=True)\n>     torch_xla._XLAC._xla_step_marker(\n          torch_xla._XLAC._xla_get_default_device(), [],\n          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\nE     RuntimeError: Error while lowering: [] xla::cast, type=f32, dtype=Double, stype=Half\nE     Error: torch_xla/csrc/convert_ops.cpp:86 : Unsupported XLA type 10\nE     Frames:\n\n/usr/local/lib/python3.8/dist-packages/torch_xla/core/xla_model.py:898: RuntimeError"
            },
            "teardown": {
                "duration": 0.03229033499974321,
                "outcome": "passed"
            }
        }
    ],
    "warnings": [
        {
            "message": "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/dtypes.py",
            "lineno": 205
        },
        {
            "message": "the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/flatbuffers/compat.py",
            "lineno": 19
        },
        {
            "message": "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py",
            "lineno": 326
        },
        {
            "message": "NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py",
            "lineno": 36
        },
        {
            "message": "BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py",
            "lineno": 37
        },
        {
            "message": "BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py",
            "lineno": 38
        },
        {
            "message": "HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py",
            "lineno": 39
        },
        {
            "message": "BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py",
            "lineno": 40
        },
        {
            "message": "LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py",
            "lineno": 41
        },
        {
            "message": "distutils Version classes are deprecated. Use packaging.version instead.",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/testing/_internal/common_cuda.py",
            "lineno": 19
        },
        {
            "message": "distutils Version classes are deprecated. Use packaging.version instead.",
            "category": "DeprecationWarning",
            "when": "config",
            "filename": "/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/version.py",
            "lineno": 346
        },
        {
            "message": "Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:883.)",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/home/frasermince/portability/src/pytorch_tests_reduced/Conv3d_test.py",
            "lineno": 67
        },
        {
            "message": "Initializing zero-element tensors is a no-op",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py",
            "lineno": 405
        },
        {
            "message": "Initializing zero-element tensors is a no-op",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py",
            "lineno": 405
        },
        {
            "message": "Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml if a complex module does not work as expected.",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py",
            "lineno": 915
        },
        {
            "message": "Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml if a complex module does not work as expected.",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py",
            "lineno": 915
        },
        {
            "message": "Initializing zero-element tensors is a no-op",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py",
            "lineno": 405
        },
        {
            "message": "0The operator aten::view_as_real appears to be a view operator, but it has no implementation for the backend \"xla:1\". View operators don't support falling back to run on the CPU, since the tensor's storage cannot be shared across devices. (Triggered internally at  ../aten/src/ATen/native/CPUFallback.cpp:175.)",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py",
            "lineno": 602
        },
        {
            "message": "0The operator aten::view_as_real appears to be a view operator, but it has no implementation for the backend \"xla:1\". View operators don't support falling back to run on the CPU, since the tensor's storage cannot be shared across devices. (Triggered internally at  ../aten/src/ATen/native/CPUFallback.cpp:175.)",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py",
            "lineno": 173
        },
        {
            "message": "0The operator aten::view_as_complex appears to be a view operator, but it has no implementation for the backend \"xla:1\". View operators don't support falling back to run on the CPU, since the tensor's storage cannot be shared across devices. (Triggered internally at  ../aten/src/ATen/native/CPUFallback.cpp:175.)",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py",
            "lineno": 173
        },
        {
            "message": "Initializing zero-element tensors is a no-op",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py",
            "lineno": 405
        },
        {
            "message": "Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml if a complex module does not work as expected.",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py",
            "lineno": 915
        },
        {
            "message": "Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml if a complex module does not work as expected.",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py",
            "lineno": 915
        },
        {
            "message": "pin memory device is set and pin_memory flag is not used then device pinned memory won't be usedplease set pin_memory to true, if you need to use the device pin memory",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py",
            "lineno": 616
        },
        {
            "message": "pin memory device is set and pin_memory flag is not used then device pinned memory won't be usedplease set pin_memory to true, if you need to use the device pin memory",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py",
            "lineno": 616
        },
        {
            "message": "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py",
            "lineno": 131
        },
        {
            "message": "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py",
            "lineno": 131
        },
        {
            "message": "ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at  ../aten/src/ATen/EmptyTensor.cpp:32.)",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/home/frasermince/portability/src/pytorch_tests_reduced/cat_test.py",
            "lineno": 31
        },
        {
            "message": "Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at  ../aten/src/ATen/SparseCsrTensorImpl.cpp:68.)",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/home/frasermince/portability/src/pytorch_tests_reduced/data_ptr_test.py",
            "lineno": 105
        },
        {
            "message": "torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\nThe boolean parameter 'some' has been replaced with a string parameter 'mode'.\nQ, R = torch.qr(A, some)\nshould be replaced with\nQ, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2497.)",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/home/frasermince/portability/src/pytorch_tests_reduced/logdet_test.py",
            "lineno": 119
        },
        {
            "message": "Input #0 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. ",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/usr/local/lib/python3.8/dist-packages/torch/autograd/gradcheck.py",
            "lineno": 652
        },
        {
            "message": "torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\ntorch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\nX = torch.triangular_solve(B, A).solution\nshould be replaced with\nX = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2189.)",
            "category": "UserWarning",
            "when": "runtest",
            "filename": "/home/frasermince/portability/src/pytorch_tests_reduced/triangular_solve_test.py",
            "lineno": 95
        }
    ]
}